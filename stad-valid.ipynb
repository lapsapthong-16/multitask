{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0cb828",
   "metadata": {},
   "source": [
    "# Seed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e3244b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "‚úÖ Libraries imported and setup complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    RobertaTokenizer, RobertaForSequenceClassification,\n",
    "    AutoTokenizer, AutoModel, AutoConfig,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import random\n",
    "from collections import Counter\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"./random_seed_analysis_results\", exist_ok=True)\n",
    "os.makedirs(\"./trained_models_seeds\", exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Libraries imported and setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c953f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Utility functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Utility Functions for Memory Management\n",
    "def set_random_seed(seed: int):\n",
    "    \"\"\"Set random seed for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def print_memory_usage():\n",
    "    \"\"\"Print current GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f} GB, Cached: {cached:.2f} GB\")\n",
    "\n",
    "print(\"‚úÖ Utility functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecd0621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loading functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Data Loading and Preprocessing Functions\n",
    "def load_external_datasets() -> Tuple[Dict, Dict]:\n",
    "    \"\"\"Load SST-2 and GoEmotions datasets\"\"\"\n",
    "    print(\"Loading external datasets...\")\n",
    "    \n",
    "    # Load SST-2 for sentiment\n",
    "    try:\n",
    "        sst2_dataset = load_dataset(\"sst2\")\n",
    "        sentiment_data = {\n",
    "            'train': sst2_dataset['train'],\n",
    "            'validation': sst2_dataset['validation']\n",
    "        }\n",
    "        print(f\"‚úÖ SST-2 dataset loaded: {len(sentiment_data['train'])} train samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not load SST-2: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Load GoEmotions for emotion\n",
    "    try:\n",
    "        emotions_dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "        emotion_data = {\n",
    "            'train': emotions_dataset['train'],\n",
    "            'validation': emotions_dataset['validation']\n",
    "        }\n",
    "        print(f\"‚úÖ GoEmotions dataset loaded: {len(emotion_data['train'])} train samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not load GoEmotions: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return sentiment_data, emotion_data\n",
    "\n",
    "def prepare_reddit_evaluation_data(reddit_data_path: str) -> Dict:\n",
    "    \"\"\"Load and prepare Reddit data for evaluation\"\"\"\n",
    "    print(f\"Loading Reddit evaluation data from {reddit_data_path}...\")\n",
    "    \n",
    "    df = pd.read_csv(reddit_data_path)\n",
    "    \n",
    "    # Create label encoders that match your existing models\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    \n",
    "    # Fit encoders\n",
    "    sentiment_encoder.fit(df['sentiment'].tolist())\n",
    "    emotion_encoder.fit(df['emotion'].tolist())\n",
    "    \n",
    "    reddit_data = {\n",
    "        'texts': df['text_content'].tolist(),\n",
    "        'sentiment_labels_text': df['sentiment'].tolist(),\n",
    "        'emotion_labels_text': df['emotion'].tolist(),\n",
    "        'sentiment_labels': sentiment_encoder.transform(df['sentiment'].tolist()),\n",
    "        'emotion_labels': emotion_encoder.transform(df['emotion'].tolist()),\n",
    "        'sentiment_encoder': sentiment_encoder,\n",
    "        'emotion_encoder': emotion_encoder\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Reddit data prepared: {len(reddit_data['texts'])} samples\")\n",
    "    print(f\"   Sentiment classes: {list(sentiment_encoder.classes_)}\")\n",
    "    print(f\"   Emotion classes: {list(emotion_encoder.classes_)}\")\n",
    "    \n",
    "    return reddit_data\n",
    "\n",
    "print(\"‚úÖ Data loading functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486bda7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset classes defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Dataset Classes\n",
    "class RobertaDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer, max_length: int = 512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], sentiment_labels: List[int], \n",
    "                 emotion_labels: List[int], tokenizer, max_length: int = 128):\n",
    "        self.texts = texts\n",
    "        self.sentiment_labels = sentiment_labels\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        sentiment_label = self.sentiment_labels[idx]\n",
    "        emotion_label = self.emotion_labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'sentiment_labels': torch.tensor(sentiment_label, dtype=torch.long),\n",
    "            'emotion_labels': torch.tensor(emotion_label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Dataset classes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96f021c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multitask model architecture defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Multitask Model Architecture (Same as your stad-valid.ipynb)\n",
    "class MultiTaskTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"microsoft/deberta-base\",\n",
    "        sentiment_num_classes: int = 3,\n",
    "        emotion_num_classes: int = 6,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super(MultiTaskTransformer, self).__init__()\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.sentiment_num_classes = sentiment_num_classes\n",
    "        self.emotion_num_classes = emotion_num_classes\n",
    "        \n",
    "        # Load configuration and adjust dropout\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        # Shared transformer encoder\n",
    "        self.shared_encoder = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            config=config,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        hidden_size = self.shared_encoder.config.hidden_size\n",
    "        \n",
    "        # Task-specific attention layers\n",
    "        self.sentiment_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.emotion_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Shared attention for common features\n",
    "        self.shared_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.sentiment_norm = nn.LayerNorm(hidden_size)\n",
    "        self.emotion_norm = nn.LayerNorm(hidden_size)\n",
    "        self.shared_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.sentiment_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.emotion_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.shared_dropout = nn.Dropout(classifier_dropout)\n",
    "        \n",
    "        # Classification heads\n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, sentiment_num_classes)\n",
    "        )\n",
    "        \n",
    "        self.emotion_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, emotion_num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in [self.sentiment_classifier, self.emotion_classifier]:\n",
    "            for layer in module:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor, \n",
    "                task: Optional[str] = None) -> Dict[str, torch.Tensor]:\n",
    "        # Shared encoder\n",
    "        encoder_outputs = self.shared_encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        sequence_output = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply shared attention\n",
    "        shared_attended, _ = self.shared_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        shared_attended = self.shared_norm(shared_attended + sequence_output)\n",
    "        shared_attended = self.shared_dropout(shared_attended)\n",
    "        shared_pooled = shared_attended[:, 0, :]\n",
    "        \n",
    "        outputs = {}\n",
    "        \n",
    "        # Sentiment branch\n",
    "        if task is None or task == \"sentiment\":\n",
    "            sentiment_attended, sentiment_weights = self.sentiment_attention(\n",
    "                sequence_output, sequence_output, sequence_output,\n",
    "                key_padding_mask=~attention_mask.bool()\n",
    "            )\n",
    "            sentiment_attended = self.sentiment_norm(sentiment_attended + sequence_output)\n",
    "            sentiment_attended = self.sentiment_dropout(sentiment_attended)\n",
    "            sentiment_pooled = sentiment_attended[:, 0, :]\n",
    "            sentiment_features = torch.cat([shared_pooled, sentiment_pooled], dim=-1)\n",
    "            sentiment_logits = self.sentiment_classifier(sentiment_features)\n",
    "            outputs[\"sentiment_logits\"] = sentiment_logits\n",
    "        \n",
    "        # Emotion branch\n",
    "        if task is None or task == \"emotion\":\n",
    "            emotion_attended, emotion_weights = self.emotion_attention(\n",
    "                sequence_output, sequence_output, sequence_output,\n",
    "                key_padding_mask=~attention_mask.bool()\n",
    "            )\n",
    "            emotion_attended = self.emotion_norm(emotion_attended + sequence_output)\n",
    "            emotion_attended = self.emotion_dropout(emotion_attended)\n",
    "            emotion_pooled = emotion_attended[:, 0, :]\n",
    "            emotion_features = torch.cat([shared_pooled, emotion_pooled], dim=-1)\n",
    "            emotion_logits = self.emotion_classifier(emotion_features)\n",
    "            outputs[\"emotion_logits\"] = emotion_logits\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "print(\"‚úÖ Multitask model architecture defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd732720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Single-task training functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Training Functions for Single-Task Models\n",
    "def train_roberta_single_task(\n",
    "    task_type: str,  # 'sentiment' or 'emotion'\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    sentiment_data: Dict = None,\n",
    "    emotion_data: Dict = None,\n",
    "    max_samples: int = 10000\n",
    ") -> Tuple[any, LabelEncoder]:\n",
    "    \"\"\"Train a single-task RoBERTa model\"\"\"\n",
    "    \n",
    "    print(f\"üöÄ Training RoBERTa {task_type} model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Load appropriate dataset\n",
    "    if task_type == 'sentiment':\n",
    "        raw_data = sentiment_data\n",
    "        text_col = 'sentence'\n",
    "        label_col = 'label'\n",
    "    else:  # emotion\n",
    "        raw_data = emotion_data\n",
    "        text_col = 'text'\n",
    "        label_col = 'labels'\n",
    "    \n",
    "    # Prepare data\n",
    "    train_texts = raw_data['train'][text_col][:max_samples]\n",
    "    train_labels_raw = raw_data['train'][label_col][:max_samples]\n",
    "    \n",
    "    # Handle emotion multi-label to single-label conversion\n",
    "    if task_type == 'emotion':\n",
    "        # Filter to first 6 classes only and convert multi-label to single-label\n",
    "        train_labels = []\n",
    "        filtered_texts = []\n",
    "        for i, label in enumerate(train_labels_raw):\n",
    "            if isinstance(label, list):\n",
    "                if label and label[0] in range(6):\n",
    "                    train_labels.append(label[0])\n",
    "                    filtered_texts.append(train_texts[i])\n",
    "            else:\n",
    "                if label in range(6):\n",
    "                    train_labels.append(label)\n",
    "                    filtered_texts.append(train_texts[i])\n",
    "        train_texts = filtered_texts\n",
    "    else:\n",
    "        train_labels = train_labels_raw\n",
    "    \n",
    "    # Create label encoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    if task_type == 'sentiment':\n",
    "        # Map SST-2 to 3 classes: 0->Negative, 1->Positive, add some Neutral\n",
    "        label_names = ['Negative', 'Neutral', 'Positive']\n",
    "        converted_labels = []\n",
    "        for label in train_labels:\n",
    "            if label == 0:  # Negative\n",
    "                converted_labels.append(0)\n",
    "            elif label == 1:  # Positive\n",
    "                # Add some neutral examples\n",
    "                if np.random.random() < 0.1:\n",
    "                    converted_labels.append(1)  # Neutral\n",
    "                else:\n",
    "                    converted_labels.append(2)  # Positive\n",
    "        \n",
    "        # Ensure we have all classes\n",
    "        if 1 not in converted_labels:\n",
    "            neutral_indices = np.random.choice(len(converted_labels), size=50, replace=False)\n",
    "            for idx in neutral_indices:\n",
    "                converted_labels[idx] = 1\n",
    "        \n",
    "        train_labels = converted_labels\n",
    "        label_encoder.classes_ = np.array(label_names)\n",
    "    else:  # emotion\n",
    "        label_names = ['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise']\n",
    "        label_encoder.classes_ = np.array(label_names)\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        'roberta-base',\n",
    "        num_labels=len(label_encoder.classes_),\n",
    "        hidden_dropout_prob=best_params['dropout_rate'],\n",
    "        attention_probs_dropout_prob=best_params['dropout_rate']\n",
    "    )\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = RobertaDataset(train_texts, train_labels, tokenizer, max_length=512)\n",
    "    \n",
    "    # Training arguments\n",
    "    output_dir = f\"./trained_models_seeds/roberta_{task_type}_seed_{seed}\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=best_params['num_epochs'],\n",
    "        per_device_train_batch_size=best_params['batch_size'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay'],\n",
    "        warmup_ratio=best_params['warmup_ratio'],\n",
    "        logging_steps=100,\n",
    "        save_strategy=\"no\",  # Don't save during training\n",
    "        dataloader_num_workers=0,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save model and encoder\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(label_encoder, os.path.join(output_dir, f'{task_type}_encoder.pkl'))\n",
    "    \n",
    "    print(f\"‚úÖ RoBERTa {task_type} model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, label_encoder\n",
    "\n",
    "print(\"‚úÖ Single-task training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ac655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multitask training functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Training Functions for Multitask Models\n",
    "def prepare_multitask_data(sentiment_data: Dict, emotion_data: Dict, max_samples: int = 5000):\n",
    "    \"\"\"Prepare combined data for multitask training\"\"\"\n",
    "    \n",
    "    # Get sentiment data (SST-2)\n",
    "    sentiment_texts = sentiment_data['train']['sentence'][:max_samples]\n",
    "    sentiment_labels_raw = sentiment_data['train']['label'][:max_samples]\n",
    "    \n",
    "    # Get emotion data (GoEmotions, first 6 classes only)\n",
    "    emotion_texts_all = emotion_data['train']['text']\n",
    "    emotion_labels_all = emotion_data['train']['labels']\n",
    "    \n",
    "    # Filter emotion data to first 6 classes\n",
    "    emotion_texts = []\n",
    "    emotion_labels = []\n",
    "    count = 0\n",
    "    for i, label in enumerate(emotion_labels_all):\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "        if isinstance(label, list):\n",
    "            if label and label[0] in range(6):\n",
    "                emotion_texts.append(emotion_texts_all[i])\n",
    "                emotion_labels.append(label[0])\n",
    "                count += 1\n",
    "        else:\n",
    "            if label in range(6):\n",
    "                emotion_texts.append(emotion_texts_all[i])\n",
    "                emotion_labels.append(label)\n",
    "                count += 1\n",
    "    \n",
    "    # Convert sentiment labels: 0->Negative(0), 1->Positive(2), add Neutral(1)\n",
    "    converted_sentiment_labels = []\n",
    "    for label in sentiment_labels_raw:\n",
    "        if label == 0:  # Negative\n",
    "            converted_sentiment_labels.append(0)\n",
    "        elif label == 1:  # Positive\n",
    "            if np.random.random() < 0.1:\n",
    "                converted_sentiment_labels.append(1)  # Neutral\n",
    "            else:\n",
    "                converted_sentiment_labels.append(2)  # Positive\n",
    "    \n",
    "    # Ensure neutral class exists\n",
    "    if 1 not in converted_sentiment_labels:\n",
    "        neutral_indices = np.random.choice(len(converted_sentiment_labels), size=50, replace=False)\n",
    "        for idx in neutral_indices:\n",
    "            converted_sentiment_labels[idx] = 1\n",
    "    \n",
    "    # Use minimum length to balance datasets\n",
    "    min_length = min(len(sentiment_texts), len(emotion_texts))\n",
    "    \n",
    "    combined_texts = sentiment_texts[:min_length]\n",
    "    combined_sentiment_labels = converted_sentiment_labels[:min_length]\n",
    "    combined_emotion_labels = emotion_labels[:min_length]\n",
    "    \n",
    "    # Create encoders\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    sentiment_encoder.classes_ = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "    emotion_encoder.classes_ = np.array(['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise'])\n",
    "    \n",
    "    return {\n",
    "        'texts': combined_texts,\n",
    "        'sentiment_labels': combined_sentiment_labels,\n",
    "        'emotion_labels': combined_emotion_labels,\n",
    "        'sentiment_encoder': sentiment_encoder,\n",
    "        'emotion_encoder': emotion_encoder\n",
    "    }\n",
    "\n",
    "def train_multitask_model(\n",
    "    model_name: str,  # \"microsoft/deberta-base\" or \"vinai/bertweet-base\"\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    sentiment_data: Dict,\n",
    "    emotion_data: Dict,\n",
    "    max_samples: int = 2000\n",
    ") -> Tuple[any, LabelEncoder, LabelEncoder]:\n",
    "    \"\"\"Train a multitask model\"\"\"\n",
    "    \n",
    "    model_type = \"deberta\" if \"deberta\" in model_name else \"bertweet\"\n",
    "    print(f\"üöÄ Training {model_type} multitask model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Prepare multitask data\n",
    "    data = prepare_multitask_data(sentiment_data, emotion_data, max_samples)\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = MultiTaskTransformer(\n",
    "        model_name=model_name,\n",
    "        sentiment_num_classes=3,\n",
    "        emotion_num_classes=6,\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        attention_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = MultiTaskDataset(\n",
    "        texts=data['texts'],\n",
    "        sentiment_labels=data['sentiment_labels'],\n",
    "        emotion_labels=data['emotion_labels'],\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=best_params['max_length']\n",
    "    )\n",
    "    \n",
    "    # Create data loader\n",
    "    dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    total_steps = len(dataloader) * best_params['num_epochs']\n",
    "    warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Compute class weights\n",
    "    sentiment_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(data['sentiment_labels']),\n",
    "        y=data['sentiment_labels']\n",
    "    )\n",
    "    emotion_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(data['emotion_labels']),\n",
    "        y=data['emotion_labels']\n",
    "    )\n",
    "    \n",
    "    sentiment_weights = torch.FloatTensor(sentiment_weights).to(device)\n",
    "    emotion_weights = torch.FloatTensor(emotion_weights).to(device)\n",
    "    \n",
    "    # Loss functions\n",
    "    sentiment_criterion = nn.CrossEntropyLoss(weight=sentiment_weights)\n",
    "    emotion_criterion = nn.CrossEntropyLoss(weight=emotion_weights)\n",
    "    \n",
    "    alpha = best_params['alpha']\n",
    "    \n",
    "    print(f\"Starting training for {best_params['num_epochs']} epochs...\")\n",
    "    \n",
    "    for epoch in range(best_params['num_epochs']):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            sentiment_labels = batch['sentiment_labels'].to(device)\n",
    "            emotion_labels = batch['emotion_labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Calculate losses\n",
    "            sentiment_loss = sentiment_criterion(outputs['sentiment_logits'], sentiment_labels)\n",
    "            emotion_loss = emotion_criterion(outputs['emotion_logits'], emotion_labels)\n",
    "            \n",
    "            # Combined loss\n",
    "            total_loss_batch = alpha * sentiment_loss + (1 - alpha) * emotion_loss\n",
    "            total_loss += total_loss_batch.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{best_params['num_epochs']}, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    output_dir = f\"./trained_models_seeds/{model_type}_multitask_seed_{seed}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model state dict\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "    \n",
    "    # Save config\n",
    "    config = {\n",
    "        \"model_name\": model_name,\n",
    "        \"sentiment_num_classes\": 3,\n",
    "        \"emotion_num_classes\": 6,\n",
    "        \"model_type\": \"MultiTaskTransformer\"\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"config.json\"), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save tokenizer and encoders\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(data['sentiment_encoder'], os.path.join(output_dir, 'sentiment_encoder.pkl'))\n",
    "    joblib.dump(data['emotion_encoder'], os.path.join(output_dir, 'emotion_encoder.pkl'))\n",
    "    \n",
    "    print(f\"‚úÖ {model_type} multitask model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, data['sentiment_encoder'], data['emotion_encoder']\n",
    "\n",
    "print(\"‚úÖ Multitask training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6650680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Evaluation Functions\n",
    "def evaluate_single_task_model(model, tokenizer, label_encoder, reddit_data: Dict, task_type: str) -> Dict:\n",
    "    \"\"\"Evaluate a single-task model on Reddit data\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_labels = reddit_data[f'{task_type}_labels']\n",
    "    \n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 16):  # Batch size 16\n",
    "            batch_texts = texts[i:i+16]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=512\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                pred_id = preds[j].item()\n",
    "                confidence = probs[j][pred_id].item()\n",
    "                \n",
    "                # Handle out of range predictions\n",
    "                if pred_id >= len(label_encoder.classes_):\n",
    "                    pred_id = 0\n",
    "                \n",
    "                predictions.append(pred_id)\n",
    "                confidences.append(confidence)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    macro_f1 = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'predictions': predictions,\n",
    "        'confidences': confidences,\n",
    "        'true_labels': true_labels\n",
    "    }\n",
    "\n",
    "def evaluate_multitask_model(model, tokenizer, sentiment_encoder, emotion_encoder, \n",
    "                           reddit_data: Dict, max_length: int = 128) -> Dict:\n",
    "    \"\"\"Evaluate a multitask model on Reddit data\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_sentiment_labels = reddit_data['sentiment_labels']\n",
    "    true_emotion_labels = reddit_data['emotion_labels']\n",
    "    \n",
    "    sentiment_predictions = []\n",
    "    emotion_predictions = []\n",
    "    sentiment_confidences = []\n",
    "    emotion_confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 8):  # Smaller batch size for multitask\n",
    "            batch_texts = texts[i:i+8]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=max_length\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=inputs['input_ids'], \n",
    "                          attention_mask=inputs['attention_mask'])\n",
    "            \n",
    "            # Process sentiment\n",
    "            sentiment_logits = outputs['sentiment_logits']\n",
    "            sentiment_probs = F.softmax(sentiment_logits, dim=-1)\n",
    "            sentiment_preds = torch.argmax(sentiment_logits, dim=-1)\n",
    "            \n",
    "            # Process emotion\n",
    "            emotion_logits = outputs['emotion_logits']\n",
    "            emotion_probs = F.softmax(emotion_logits, dim=-1)\n",
    "            emotion_preds = torch.argmax(emotion_logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                # Sentiment\n",
    "                sent_id = sentiment_preds[j].item()\n",
    "                sent_conf = sentiment_probs[j][sent_id].item()\n",
    "                if sent_id >= len(sentiment_encoder.classes_):\n",
    "                    sent_id = 0\n",
    "                sentiment_predictions.append(sent_id)\n",
    "                sentiment_confidences.append(sent_conf)\n",
    "                \n",
    "                # Emotion\n",
    "                emot_id = emotion_preds[j].item()\n",
    "                emot_conf = emotion_probs[j][emot_id].item()\n",
    "                if emot_id >= len(emotion_encoder.classes_):\n",
    "                    emot_id = 0\n",
    "                emotion_predictions.append(emot_id)\n",
    "                emotion_confidences.append(emot_conf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    sentiment_accuracy = accuracy_score(true_sentiment_labels, sentiment_predictions)\n",
    "    sentiment_f1 = f1_score(true_sentiment_labels, sentiment_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    emotion_accuracy = accuracy_score(true_emotion_labels, emotion_predictions)\n",
    "    emotion_f1 = f1_score(true_emotion_labels, emotion_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'sentiment': {\n",
    "            'accuracy': sentiment_accuracy,\n",
    "            'macro_f1': sentiment_f1,\n",
    "            'predictions': sentiment_predictions,\n",
    "            'confidences': sentiment_confidences\n",
    "        },\n",
    "        'emotion': {\n",
    "            'accuracy': emotion_accuracy,\n",
    "            'macro_f1': emotion_f1,\n",
    "            'predictions': emotion_predictions,\n",
    "            'confidences': emotion_confidences\n",
    "        },\n",
    "        'combined_accuracy': (sentiment_accuracy + emotion_accuracy) / 2,\n",
    "        'combined_f1': (sentiment_f1 + emotion_f1) / 2\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41769edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Random seed analysis function defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Main Random Seed Analysis Function\n",
    "def run_random_seed_analysis(\n",
    "    reddit_data_path: str = \"annotated_reddit_posts.csv\",\n",
    "    seeds: List[int] = [42, 123, 456, 789, 999],\n",
    "    max_training_samples: int = 5000\n",
    "):\n",
    "    \"\"\"Run complete random seed analysis\"\"\"\n",
    "    \n",
    "    print(\"üé≤ STARTING RANDOM SEED ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Seeds to test: {seeds}\")\n",
    "    print(f\"Max training samples per dataset: {max_training_samples}\")\n",
    "    \n",
    "    # Load external datasets\n",
    "    print(\"\\nüìÇ Loading external datasets...\")\n",
    "    sentiment_data, emotion_data = load_external_datasets()\n",
    "    \n",
    "    # Load Reddit evaluation data\n",
    "    print(\"\\nüìÇ Loading Reddit evaluation data...\")\n",
    "    reddit_data = prepare_reddit_evaluation_data(reddit_data_path)\n",
    "    \n",
    "    # Define best parameters for each model\n",
    "    best_params = {\n",
    "        'roberta_sentiment': {\n",
    "            'learning_rate': 1.289795048085554e-05,\n",
    "            'batch_size': 16,\n",
    "            'dropout_rate': 0.2218455076693483,\n",
    "            'num_epochs': 3,\n",
    "            'warmup_ratio': 0.15263495397682356,\n",
    "            'weight_decay': 0.13764422318448438\n",
    "        },\n",
    "        'roberta_emotion': {\n",
    "            'learning_rate': 0.00018843871051154592,\n",
    "            'batch_size': 32,\n",
    "            'dropout_rate': 0.15859725997693935,\n",
    "            'num_epochs': 7,\n",
    "            'warmup_ratio': 0.16826426457074994,\n",
    "            'weight_decay': 0.21559177659152684\n",
    "        },\n",
    "        'deberta_multitask': {\n",
    "            'learning_rate': 2.858051065806938e-05,\n",
    "            'batch_size': 2,\n",
    "            'alpha': 0.5369658275448169,\n",
    "            'hidden_dropout_prob': 0.061612603179999434,\n",
    "            'classifier_dropout': 0.28226345557043153,\n",
    "            'weight_decay': 0.017881888245041864,\n",
    "            'warmup_ratio': 0.05975773894779193,\n",
    "            'num_epochs': 5,\n",
    "            'max_length': 128\n",
    "        },\n",
    "        'bertweet_multitask': {\n",
    "            'learning_rate': 1.3352204399988585e-05,\n",
    "            'batch_size': 4,\n",
    "            'alpha': 0.4503170063321093,\n",
    "            'hidden_dropout_prob': 0.1361646589006065,\n",
    "            'classifier_dropout': 0.16618433315983214,\n",
    "            'weight_decay': 0.06911326050717913,\n",
    "            'warmup_ratio': 0.15511878702345422,\n",
    "            'num_epochs': 5,\n",
    "            'max_length': 128\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Store results for each seed\n",
    "    all_results = {}\n",
    "    \n",
    "    for seed in seeds:\n",
    "        print(f\"\\nüå± TRAINING AND EVALUATING WITH SEED {seed}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        seed_results = {}\n",
    "        \n",
    "        # 1. Train and evaluate RoBERTa Sentiment\n",
    "        print(f\"\\n1Ô∏è‚É£ RoBERTa Sentiment (Seed {seed})\")\n",
    "        model, encoder = train_roberta_single_task(\n",
    "            'sentiment', best_params['roberta_sentiment'], seed, \n",
    "            sentiment_data, emotion_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(f\"./trained_models_seeds/roberta_sentiment_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_single_task_model(model, tokenizer, encoder, reddit_data, 'sentiment')\n",
    "        seed_results['roberta_sentiment'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 2. Train and evaluate RoBERTa Emotion\n",
    "        print(f\"\\n2Ô∏è‚É£ RoBERTa Emotion (Seed {seed})\")\n",
    "        model, encoder = train_roberta_single_task(\n",
    "            'emotion', best_params['roberta_emotion'], seed,\n",
    "            sentiment_data, emotion_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(f\"./trained_models_seeds/roberta_emotion_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_single_task_model(model, tokenizer, encoder, reddit_data, 'emotion')\n",
    "        seed_results['roberta_emotion'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 3. Train and evaluate DeBERTa Multitask\n",
    "        print(f\"\\n3Ô∏è‚É£ DeBERTa Multitask (Seed {seed})\")\n",
    "        model, sent_enc, emot_enc = train_multitask_model(\n",
    "            \"microsoft/deberta-base\", best_params['deberta_multitask'], seed,\n",
    "            sentiment_data, emotion_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./trained_models_seeds/deberta_multitask_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_multitask_model(\n",
    "            model, tokenizer, sent_enc, emot_enc, reddit_data, \n",
    "            best_params['deberta_multitask']['max_length']\n",
    "        )\n",
    "        seed_results['deberta_multitask'] = results\n",
    "        print(f\"   Sentiment - Accuracy: {results['sentiment']['accuracy']:.4f}, F1: {results['sentiment']['macro_f1']:.4f}\")\n",
    "        print(f\"   Emotion - Accuracy: {results['emotion']['accuracy']:.4f}, F1: {results['emotion']['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 4. Train and evaluate BERTweet Multitask\n",
    "        print(f\"\\n4Ô∏è‚É£ BERTweet Multitask (Seed {seed})\")\n",
    "        model, sent_enc, emot_enc = train_multitask_model(\n",
    "            \"vinai/bertweet-base\", best_params['bertweet_multitask'], seed,\n",
    "            sentiment_data, emotion_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./trained_models_seeds/bertweet_multitask_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_multitask_model(\n",
    "            model, tokenizer, sent_enc, emot_enc, reddit_data,\n",
    "            best_params['bertweet_multitask']['max_length']\n",
    "        )\n",
    "        seed_results['bertweet_multitask'] = results\n",
    "        print(f\"   Sentiment - Accuracy: {results['sentiment']['accuracy']:.4f}, F1: {results['sentiment']['macro_f1']:.4f}\")\n",
    "        print(f\"   Emotion - Accuracy: {results['emotion']['accuracy']:.4f}, F1: {results['emotion']['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        all_results[seed] = seed_results\n",
    "        \n",
    "        print(f\"\\n‚úÖ Completed evaluation for seed {seed}\")\n",
    "    \n",
    "    # Analyze stability across seeds\n",
    "    print(f\"\\nüìä ANALYZING STABILITY ACROSS SEEDS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    stability_analysis = analyze_seed_stability(all_results, seeds)\n",
    "    \n",
    "    # Save results\n",
    "    save_results(all_results, stability_analysis, seeds)\n",
    "    \n",
    "    return all_results, stability_analysis\n",
    "\n",
    "def analyze_seed_stability(all_results: Dict, seeds: List[int]) -> Dict:\n",
    "    \"\"\"Analyze stability of models across different seeds\"\"\"\n",
    "    \n",
    "    stability_stats = {}\n",
    "    \n",
    "    # Define model-task combinations\n",
    "    evaluations = [\n",
    "        ('roberta_sentiment', 'sentiment'),\n",
    "        ('roberta_emotion', 'emotion'),\n",
    "        ('deberta_multitask', 'sentiment'),\n",
    "        ('deberta_multitask', 'emotion'),\n",
    "        ('bertweet_multitask', 'sentiment'),\n",
    "        ('bertweet_multitask', 'emotion')\n",
    "    ]\n",
    "    \n",
    "    for model_name, task in evaluations:\n",
    "        print(f\"\\nüîç {model_name.upper()} - {task.upper()}\")\n",
    "        \n",
    "        accuracies = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        for seed in seeds:\n",
    "            if model_name in all_results[seed]:\n",
    "                result = all_results[seed][model_name]\n",
    "                \n",
    "                if model_name.endswith('_multitask'):\n",
    "                    acc = result[task]['accuracy']\n",
    "                    f1 = result[task]['macro_f1']\n",
    "                else:\n",
    "                    acc = result['accuracy']\n",
    "                    f1 = result['macro_f1']\n",
    "                \n",
    "                accuracies.append(acc)\n",
    "                f1_scores.append(f1)\n",
    "        \n",
    "        if accuracies:\n",
    "            acc_mean = np.mean(accuracies)\n",
    "            acc_std = np.std(accuracies)\n",
    "            f1_mean = np.mean(f1_scores)\n",
    "            f1_std = np.std(f1_scores)\n",
    "            \n",
    "            stability_stats[f\"{model_name}_{task}\"] = {\n",
    "                'accuracy_mean': acc_mean,\n",
    "                'accuracy_std': acc_std,\n",
    "                'f1_mean': f1_mean,\n",
    "                'f1_std': f1_std,\n",
    "                'accuracy_values': accuracies,\n",
    "                'f1_values': f1_scores\n",
    "            }\n",
    "            \n",
    "            print(f\"   Accuracy: {acc_mean:.4f} ¬± {acc_std:.4f}\")\n",
    "            print(f\"   Macro F1: {f1_mean:.4f} ¬± {f1_std:.4f}\")\n",
    "    \n",
    "    return stability_stats\n",
    "\n",
    "def save_results(all_results: Dict, stability_analysis: Dict, seeds: List[int]):\n",
    "    \"\"\"Save results to files\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save raw results\n",
    "    results_file = f\"./random_seed_analysis_results/raw_results_{timestamp}.json\"\n",
    "    with open(results_file, 'w') as f:\n",
    "        # Convert numpy types to Python types for JSON serialization\n",
    "        serializable_results = {}\n",
    "        for seed, seed_results in all_results.items():\n",
    "            serializable_results[str(seed)] = {}\n",
    "            for model, results in seed_results.items():\n",
    "                if isinstance(results, dict):\n",
    "                    serializable_results[str(seed)][model] = {}\n",
    "                    for key, value in results.items():\n",
    "                        if isinstance(value, dict):\n",
    "                            serializable_results[str(seed)][model][key] = {\n",
    "                                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                                   [float(x) if isinstance(x, (np.floating, np.integer)) else x for x in v] if isinstance(v, list) else v\n",
    "                                for k, v in value.items()\n",
    "                            }\n",
    "                        else:\n",
    "                            serializable_results[str(seed)][model][key] = float(value) if isinstance(value, (np.floating, np.integer)) else value\n",
    "        \n",
    "        json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    # Save stability analysis\n",
    "    stability_file = f\"./random_seed_analysis_results/stability_analysis_{timestamp}.json\"\n",
    "    with open(stability_file, 'w') as f:\n",
    "        serializable_stability = {}\n",
    "        for key, stats in stability_analysis.items():\n",
    "            serializable_stability[key] = {\n",
    "                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                   [float(x) for x in v] if isinstance(v, list) else v\n",
    "                for k, v in stats.items()\n",
    "            }\n",
    "        json.dump(serializable_stability, f, indent=2)\n",
    "    \n",
    "    # Create summary report\n",
    "    summary_file = f\"./random_seed_analysis_results/summary_report_{timestamp}.txt\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"RANDOM SEED ANALYSIS SUMMARY REPORT\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        f.write(f\"Seeds tested: {seeds}\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"STABILITY ANALYSIS (Mean ¬± Std)\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        for key, stats in stability_analysis.items():\n",
    "            model_task = key.replace('_', ' ').title()\n",
    "            f.write(f\"\\n{model_task}:\\n\")\n",
    "            f.write(f\"  Accuracy: {stats['accuracy_mean']:.4f} ¬± {stats['accuracy_std']:.4f}\\n\")\n",
    "            f.write(f\"  Macro F1: {stats['f1_mean']:.4f} ¬± {stats['f1_std']:.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest Performers (by mean F1 score):\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        \n",
    "        # Find best performers\n",
    "        sentiment_best = max([k for k in stability_analysis.keys() if 'sentiment' in k], \n",
    "                           key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        emotion_best = max([k for k in stability_analysis.keys() if 'emotion' in k], \n",
    "                         key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        \n",
    "        f.write(f\"Sentiment: {sentiment_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[sentiment_best]['f1_mean']:.4f})\\n\")\n",
    "        f.write(f\"Emotion: {emotion_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[emotion_best]['f1_mean']:.4f})\\n\")\n",
    "    \n",
    "    print(f\"\\nüíæ Results saved:\")\n",
    "    print(f\"   Raw results: {results_file}\")\n",
    "    print(f\"   Stability analysis: {stability_file}\")\n",
    "    print(f\"   Summary report: {summary_file}\")\n",
    "\n",
    "print(\"‚úÖ Random seed analysis function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ecf20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ STARTING RANDOM SEED ANALYSIS\n",
      "============================================================\n",
      "Seeds to test: [42, 123, 456, 789, 999]\n",
      "Max training samples per dataset: 5000\n",
      "\n",
      "üìÇ Loading external datasets...\n",
      "Loading external datasets...\n",
      "‚úÖ SST-2 dataset loaded: 67349 train samples\n",
      "‚úÖ GoEmotions dataset loaded: 43410 train samples\n",
      "\n",
      "üìÇ Loading Reddit evaluation data...\n",
      "Loading Reddit evaluation data from annotated_reddit_posts.csv...\n",
      "‚úÖ Reddit data prepared: 95 samples\n",
      "   Sentiment classes: [np.str_('Negative'), np.str_('Neutral'), np.str_('Positive')]\n",
      "   Emotion classes: [np.str_('Anger'), np.str_('Fear'), np.str_('Joy'), np.str_('No Emotion'), np.str_('Sadness'), np.str_('Surprise')]\n",
      "\n",
      "üå± TRAINING AND EVALUATING WITH SEED 42\n",
      "--------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ RoBERTa Sentiment (Seed 42)\n",
      "üöÄ Training RoBERTa sentiment model with seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 11%|‚ñà         | 100/939 [01:30<10:53,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9841, 'grad_norm': 12.915605545043945, 'learning_rate': 8.95691005614968e-06, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà‚ñè       | 200/939 [02:49<09:46,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8614, 'grad_norm': 28.236406326293945, 'learning_rate': 1.1989415604216659e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 300/939 [04:08<08:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6888, 'grad_norm': 29.398061752319336, 'learning_rate': 1.0367031895932944e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 400/939 [05:28<07:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6217, 'grad_norm': 40.58501434326172, 'learning_rate': 8.744648187649227e-06, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 500/939 [06:47<05:55,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.567, 'grad_norm': 22.53042221069336, 'learning_rate': 7.122264479365512e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 600/939 [08:46<04:32,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5704, 'grad_norm': 18.175962448120117, 'learning_rate': 5.4998807710817966e-06, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 700/939 [10:06<03:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5349, 'grad_norm': 61.780189514160156, 'learning_rate': 3.877497062798081e-06, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 800/939 [11:26<01:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5016, 'grad_norm': 42.044349670410156, 'learning_rate': 2.2551133545143647e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 900/939 [12:46<00:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5033, 'grad_norm': 36.89555358886719, 'learning_rate': 6.327296462306492e-07, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 939/939 [13:17<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 797.4646, 'train_samples_per_second': 18.81, 'train_steps_per_second': 1.177, 'train_loss': 0.6437950256152656, 'epoch': 3.0}\n",
      "‚úÖ RoBERTa sentiment model trained and saved with seed 42\n",
      "   Accuracy: 0.6000, Macro F1: 0.3803\n",
      "\n",
      "2Ô∏è‚É£ RoBERTa Emotion (Seed 42)\n",
      "üöÄ Training RoBERTa emotion model with seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 29%|‚ñà‚ñà‚ñâ       | 100/343 [37:08<1:31:16, 22.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3892, 'grad_norm': 27.32234001159668, 'learning_rate': 0.00016066879527826546, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 200/343 [1:13:44<51:16, 21.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8142, 'grad_norm': 7.819638729095459, 'learning_rate': 9.454994948474058e-05, 'epoch': 4.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 300/343 [1:50:39<14:44, 20.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.439, 'grad_norm': 4.666853904724121, 'learning_rate': 2.8431103691215698e-05, 'epoch': 6.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 343/343 [2:07:13<00:00, 22.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 7633.8783, 'train_samples_per_second': 1.41, 'train_steps_per_second': 0.045, 'train_loss': 0.799997493755018, 'epoch': 7.0}\n",
      "‚úÖ RoBERTa emotion model trained and saved with seed 42\n",
      "   Accuracy: 0.1895, Macro F1: 0.0981\n",
      "\n",
      "3Ô∏è‚É£ DeBERTa Multitask (Seed 42)\n",
      "üöÄ Training deberta multitask model with seed 42\n",
      "Starting training for 5 epochs...\n",
      "Epoch 1/5, Average Loss: 1.6306\n",
      "Epoch 2/5, Average Loss: 1.4135\n",
      "Epoch 3/5, Average Loss: 1.3677\n",
      "Epoch 4/5, Average Loss: 1.3509\n",
      "Epoch 5/5, Average Loss: 1.3312\n",
      "‚úÖ deberta multitask model trained and saved with seed 42\n",
      "   Sentiment - Accuracy: 0.5368, F1: 0.2581\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.0672\n",
      "\n",
      "4Ô∏è‚É£ BERTweet Multitask (Seed 42)\n",
      "üöÄ Training bertweet multitask model with seed 42\n",
      "Starting training for 5 epochs...\n",
      "Epoch 1/5, Average Loss: 1.6388\n",
      "Epoch 2/5, Average Loss: 1.3844\n",
      "Epoch 3/5, Average Loss: 1.2976\n",
      "Epoch 4/5, Average Loss: 1.2355\n",
      "Epoch 5/5, Average Loss: 1.2086\n",
      "‚úÖ bertweet multitask model trained and saved with seed 42\n",
      "   Sentiment - Accuracy: 0.5895, F1: 0.3887\n",
      "   Emotion - Accuracy: 0.2211, F1: 0.1382\n",
      "\n",
      "‚úÖ Completed evaluation for seed 42\n",
      "\n",
      "üå± TRAINING AND EVALUATING WITH SEED 123\n",
      "--------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ RoBERTa Sentiment (Seed 123)\n",
      "üöÄ Training RoBERTa sentiment model with seed 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 11%|‚ñà         | 100/939 [01:20<11:22,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0229, 'grad_norm': 15.239418983459473, 'learning_rate': 8.95691005614968e-06, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà‚ñè       | 200/939 [02:41<09:52,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8787, 'grad_norm': 43.41193771362305, 'learning_rate': 1.1989415604216659e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 300/939 [04:01<08:36,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7277, 'grad_norm': 18.314516067504883, 'learning_rate': 1.0367031895932944e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 400/939 [05:22<07:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5896, 'grad_norm': 37.494266510009766, 'learning_rate': 8.744648187649227e-06, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 500/939 [06:42<05:56,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5877, 'grad_norm': 15.997401237487793, 'learning_rate': 7.122264479365512e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 600/939 [08:03<04:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6079, 'grad_norm': 43.19236755371094, 'learning_rate': 5.4998807710817966e-06, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 700/939 [09:23<03:12,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.536, 'grad_norm': 43.748016357421875, 'learning_rate': 3.877497062798081e-06, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 800/939 [10:43<01:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4739, 'grad_norm': 63.40861892700195, 'learning_rate': 2.2551133545143647e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 900/939 [12:04<00:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5199, 'grad_norm': 27.043224334716797, 'learning_rate': 6.327296462306492e-07, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 939/939 [12:35<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 755.8161, 'train_samples_per_second': 19.846, 'train_steps_per_second': 1.242, 'train_loss': 0.6574809447137184, 'epoch': 3.0}\n",
      "‚úÖ RoBERTa sentiment model trained and saved with seed 123\n",
      "   Accuracy: 0.5684, Macro F1: 0.3276\n",
      "\n",
      "2Ô∏è‚É£ RoBERTa Emotion (Seed 123)\n",
      "üöÄ Training RoBERTa emotion model with seed 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 29%|‚ñà‚ñà‚ñâ       | 100/343 [32:20<1:08:57, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3899, 'grad_norm': 8.82214641571045, 'learning_rate': 0.00016066879527826546, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 200/343 [1:04:57<44:33, 18.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8167, 'grad_norm': 14.668330192565918, 'learning_rate': 9.454994948474058e-05, 'epoch': 4.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 300/343 [1:37:54<14:04, 19.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4406, 'grad_norm': 6.803173542022705, 'learning_rate': 2.8431103691215698e-05, 'epoch': 6.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 343/343 [1:52:12<00:00, 19.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 6732.4131, 'train_samples_per_second': 1.599, 'train_steps_per_second': 0.051, 'train_loss': 0.7982728780184821, 'epoch': 7.0}\n",
      "‚úÖ RoBERTa emotion model trained and saved with seed 123\n",
      "   Accuracy: 0.1684, Macro F1: 0.1021\n",
      "\n",
      "3Ô∏è‚É£ DeBERTa Multitask (Seed 123)\n",
      "üöÄ Training deberta multitask model with seed 123\n",
      "Starting training for 5 epochs...\n",
      "Epoch 1/5, Average Loss: 1.4594\n",
      "Epoch 2/5, Average Loss: 1.1717\n",
      "Epoch 3/5, Average Loss: 1.0479\n",
      "Epoch 4/5, Average Loss: 1.0006\n",
      "Epoch 5/5, Average Loss: 0.9478\n",
      "‚úÖ deberta multitask model trained and saved with seed 123\n",
      "   Sentiment - Accuracy: 0.5263, F1: 0.3292\n",
      "   Emotion - Accuracy: 0.2737, F1: 0.0962\n",
      "\n",
      "4Ô∏è‚É£ BERTweet Multitask (Seed 123)\n",
      "üöÄ Training bertweet multitask model with seed 123\n",
      "Starting training for 5 epochs...\n",
      "Epoch 1/5, Average Loss: 1.7292\n",
      "Epoch 2/5, Average Loss: 1.4799\n",
      "Epoch 3/5, Average Loss: 1.3351\n",
      "Epoch 4/5, Average Loss: 1.2700\n",
      "Epoch 5/5, Average Loss: 1.2385\n",
      "‚úÖ bertweet multitask model trained and saved with seed 123\n",
      "   Sentiment - Accuracy: 0.5895, F1: 0.3968\n",
      "   Emotion - Accuracy: 0.1895, F1: 0.0619\n",
      "\n",
      "‚úÖ Completed evaluation for seed 123\n",
      "\n",
      "üå± TRAINING AND EVALUATING WITH SEED 456\n",
      "--------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ RoBERTa Sentiment (Seed 456)\n",
      "üöÄ Training RoBERTa sentiment model with seed 456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 11%|‚ñà         | 100/939 [01:20<11:09,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0138, 'grad_norm': 18.837217330932617, 'learning_rate': 8.95691005614968e-06, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà‚ñè       | 200/939 [02:41<09:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8826, 'grad_norm': 10.171393394470215, 'learning_rate': 1.1989415604216659e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 300/939 [04:02<08:30,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6923, 'grad_norm': 16.028167724609375, 'learning_rate': 1.0367031895932944e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 400/939 [05:22<07:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5811, 'grad_norm': 22.550447463989258, 'learning_rate': 8.744648187649227e-06, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 500/939 [06:43<05:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.574, 'grad_norm': 14.250685691833496, 'learning_rate': 7.122264479365512e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 600/939 [08:04<04:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5631, 'grad_norm': 103.25430297851562, 'learning_rate': 5.4998807710817966e-06, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 700/939 [09:24<03:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5268, 'grad_norm': 16.879480361938477, 'learning_rate': 3.877497062798081e-06, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 800/939 [10:45<01:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4697, 'grad_norm': 28.280550003051758, 'learning_rate': 2.2551133545143647e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 900/939 [12:05<00:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4791, 'grad_norm': 45.09437942504883, 'learning_rate': 6.327296462306492e-07, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 939/939 [12:37<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 757.1563, 'train_samples_per_second': 19.811, 'train_steps_per_second': 1.24, 'train_loss': 0.637511912499246, 'epoch': 3.0}\n",
      "‚úÖ RoBERTa sentiment model trained and saved with seed 456\n",
      "   Accuracy: 0.5789, Macro F1: 0.3567\n",
      "\n",
      "2Ô∏è‚É£ RoBERTa Emotion (Seed 456)\n",
      "üöÄ Training RoBERTa emotion model with seed 456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 29%|‚ñà‚ñà‚ñâ       | 100/343 [34:00<1:12:26, 17.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3714, 'grad_norm': 23.635284423828125, 'learning_rate': 0.00016066879527826546, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 200/343 [1:08:06<46:09, 19.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7862, 'grad_norm': 19.350830078125, 'learning_rate': 9.454994948474058e-05, 'epoch': 4.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 300/343 [1:42:15<14:27, 20.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4509, 'grad_norm': 4.450591564178467, 'learning_rate': 2.8431103691215698e-05, 'epoch': 6.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 343/343 [1:56:54<00:00, 20.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 7014.4375, 'train_samples_per_second': 1.535, 'train_steps_per_second': 0.049, 'train_loss': 0.7899891405689473, 'epoch': 7.0}\n",
      "‚úÖ RoBERTa emotion model trained and saved with seed 456\n",
      "   Accuracy: 0.1789, Macro F1: 0.1048\n",
      "\n",
      "3Ô∏è‚É£ DeBERTa Multitask (Seed 456)\n",
      "üöÄ Training deberta multitask model with seed 456\n",
      "Starting training for 5 epochs...\n",
      "Epoch 1/5, Average Loss: 1.5554\n",
      "Epoch 2/5, Average Loss: 1.4198\n",
      "Epoch 3/5, Average Loss: 1.3716\n",
      "Epoch 4/5, Average Loss: 1.3527\n",
      "Epoch 5/5, Average Loss: 1.3422\n",
      "‚úÖ deberta multitask model trained and saved with seed 456\n",
      "   Sentiment - Accuracy: 0.2316, F1: 0.1254\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.0672\n",
      "\n",
      "4Ô∏è‚É£ BERTweet Multitask (Seed 456)\n",
      "üöÄ Training bertweet multitask model with seed 456\n",
      "Starting training for 5 epochs...\n",
      "Epoch 1/5, Average Loss: 1.6248\n",
      "Epoch 2/5, Average Loss: 1.3825\n",
      "Epoch 3/5, Average Loss: 1.2860\n",
      "Epoch 4/5, Average Loss: 1.2318\n",
      "Epoch 5/5, Average Loss: 1.2009\n",
      "‚úÖ bertweet multitask model trained and saved with seed 456\n",
      "   Sentiment - Accuracy: 0.6000, F1: 0.3891\n",
      "   Emotion - Accuracy: 0.2632, F1: 0.1327\n",
      "\n",
      "‚úÖ Completed evaluation for seed 456\n",
      "\n",
      "üå± TRAINING AND EVALUATING WITH SEED 789\n",
      "--------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ RoBERTa Sentiment (Seed 789)\n",
      "üöÄ Training RoBERTa sentiment model with seed 789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 11%|‚ñà         | 100/939 [01:21<11:18,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0154, 'grad_norm': 15.875297546386719, 'learning_rate': 8.95691005614968e-06, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà‚ñè       | 200/939 [02:42<09:55,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8444, 'grad_norm': 35.6624755859375, 'learning_rate': 1.1989415604216659e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 300/939 [04:03<08:34,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6669, 'grad_norm': 15.760199546813965, 'learning_rate': 1.0367031895932944e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 400/939 [05:24<07:17,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5843, 'grad_norm': 25.121395111083984, 'learning_rate': 8.744648187649227e-06, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 500/939 [06:44<05:52,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5587, 'grad_norm': 14.257453918457031, 'learning_rate': 7.122264479365512e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 600/939 [08:06<04:36,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5203, 'grad_norm': 12.325827598571777, 'learning_rate': 5.4998807710817966e-06, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 700/939 [09:26<03:14,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.516, 'grad_norm': 15.4938325881958, 'learning_rate': 3.877497062798081e-06, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 800/939 [10:47<01:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4638, 'grad_norm': 36.731163024902344, 'learning_rate': 2.2551133545143647e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 900/939 [12:08<00:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4602, 'grad_norm': 38.608272552490234, 'learning_rate': 6.327296462306492e-07, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 939/939 [12:40<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 760.3433, 'train_samples_per_second': 19.728, 'train_steps_per_second': 1.235, 'train_loss': 0.6207813145126652, 'epoch': 3.0}\n",
      "‚úÖ RoBERTa sentiment model trained and saved with seed 789\n",
      "   Accuracy: 0.5789, Macro F1: 0.3461\n",
      "\n",
      "2Ô∏è‚É£ RoBERTa Emotion (Seed 789)\n",
      "üöÄ Training RoBERTa emotion model with seed 789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 10%|‚ñâ         | 33/343 [11:36<1:50:02, 21.30s/it]"
     ]
    }
   ],
   "source": [
    "# Cell 10: Run the Analysis\n",
    "if __name__ == \"__main__\":\n",
    "    # Run random seed analysis\n",
    "    all_results, stability_analysis = run_random_seed_analysis(\n",
    "        reddit_data_path=\"annotated_reddit_posts.csv\",\n",
    "        seeds=[42, 123, 456, 789, 999],  # 5 different seeds\n",
    "        max_training_samples=5000  # Adjust based on your compute resources\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéâ RANDOM SEED ANALYSIS COMPLETED!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Check the './random_seed_analysis_results/' directory for detailed results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead6e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6e38044",
   "metadata": {},
   "source": [
    "# Bootstrap Stability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a753a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported and setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d3649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define MultiTaskTransformer Architecture\n",
    "class MultiTaskTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"vinai/bertweet-base\",\n",
    "        sentiment_num_classes: int = 3,\n",
    "        emotion_num_classes: int = 6,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super(MultiTaskTransformer, self).__init__()\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.sentiment_num_classes = sentiment_num_classes\n",
    "        self.emotion_num_classes = emotion_num_classes\n",
    "        \n",
    "        # Load configuration and adjust dropout\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        # Shared transformer encoder\n",
    "        self.shared_encoder = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            config=config,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        hidden_size = self.shared_encoder.config.hidden_size\n",
    "        \n",
    "        # Task-specific attention layers\n",
    "        self.sentiment_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.emotion_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Shared attention for common features\n",
    "        self.shared_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.sentiment_norm = nn.LayerNorm(hidden_size)\n",
    "        self.emotion_norm = nn.LayerNorm(hidden_size)\n",
    "        self.shared_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.sentiment_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.emotion_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.shared_dropout = nn.Dropout(classifier_dropout)\n",
    "        \n",
    "        # Classification heads\n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, sentiment_num_classes)\n",
    "        )\n",
    "        \n",
    "        self.emotion_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, emotion_num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in [self.sentiment_classifier, self.emotion_classifier]:\n",
    "            for layer in module:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor, \n",
    "                task: str = None) -> Dict[str, torch.Tensor]:\n",
    "        # Shared encoder\n",
    "        encoder_outputs = self.shared_encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        sequence_output = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply shared attention\n",
    "        shared_attended, _ = self.shared_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        shared_attended = self.shared_norm(shared_attended + sequence_output)\n",
    "        shared_attended = self.shared_dropout(shared_attended)\n",
    "        shared_pooled = shared_attended[:, 0, :]\n",
    "        \n",
    "        outputs = {}\n",
    "        \n",
    "        # Sentiment branch\n",
    "        if task is None or task == \"sentiment\":\n",
    "            sentiment_attended, sentiment_weights = self.sentiment_attention(\n",
    "                sequence_output, sequence_output, sequence_output,\n",
    "                key_padding_mask=~attention_mask.bool()\n",
    "            )\n",
    "            sentiment_attended = self.sentiment_norm(sentiment_attended + sequence_output)\n",
    "            sentiment_attended = self.sentiment_dropout(sentiment_attended)\n",
    "            sentiment_pooled = sentiment_attended[:, 0, :]\n",
    "            sentiment_features = torch.cat([shared_pooled, sentiment_pooled], dim=-1)\n",
    "            sentiment_logits = self.sentiment_classifier(sentiment_features)\n",
    "            outputs[\"sentiment_logits\"] = sentiment_logits\n",
    "        \n",
    "        # Emotion branch\n",
    "        if task is None or task == \"emotion\":\n",
    "            emotion_attended, emotion_weights = self.emotion_attention(\n",
    "                sequence_output, sequence_output, sequence_output,\n",
    "                key_padding_mask=~attention_mask.bool()\n",
    "            )\n",
    "            emotion_attended = self.emotion_norm(emotion_attended + sequence_output)\n",
    "            emotion_attended = self.emotion_dropout(emotion_attended)\n",
    "            emotion_pooled = emotion_attended[:, 0, :]\n",
    "            emotion_features = torch.cat([shared_pooled, emotion_pooled], dim=-1)\n",
    "            emotion_logits = self.emotion_classifier(emotion_features)\n",
    "            outputs[\"emotion_logits\"] = emotion_logits\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "print(\"‚úÖ MultiTaskTransformer architecture defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load BERTweet Model and Data\n",
    "def load_bertweet_model(model_path: str):\n",
    "    \"\"\"Load BERTweet multitask model\"\"\"\n",
    "    print(f\"üì• Loading BERTweet model from {model_path}...\")\n",
    "    \n",
    "    # Check if model files exist\n",
    "    required_files = ['pytorch_model.bin', 'sentiment_encoder.pkl', 'emotion_encoder.pkl']\n",
    "    missing_files = [f for f in required_files if not os.path.exists(os.path.join(model_path, f))]\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"‚ùå Missing files: {missing_files}\")\n",
    "        # Look for alternative paths\n",
    "        alt_paths = [\n",
    "            os.path.join(model_path, 'final_model'),\n",
    "            os.path.join(model_path, 'best_model'),\n",
    "            model_path.replace('bertweet_model_ultra_light', 'bertweet_model_ultra_light/final_model')\n",
    "        ]\n",
    "        \n",
    "        for alt_path in alt_paths:\n",
    "            if os.path.exists(alt_path):\n",
    "                alt_missing = [f for f in required_files if not os.path.exists(os.path.join(alt_path, f))]\n",
    "                if not alt_missing:\n",
    "                    model_path = alt_path\n",
    "                    print(f\"‚úÖ Found model at: {model_path}\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"‚ùå Alternative path {alt_path} also missing: {alt_missing}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Could not find complete model at {model_path} or alternative paths\")\n",
    "    \n",
    "    try:\n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
    "        \n",
    "        # Load label encoders\n",
    "        sentiment_encoder = joblib.load(os.path.join(model_path, 'sentiment_encoder.pkl'))\n",
    "        emotion_encoder = joblib.load(os.path.join(model_path, 'emotion_encoder.pkl'))\n",
    "        \n",
    "        # Initialize model\n",
    "        model = MultiTaskTransformer(\n",
    "            model_name=\"vinai/bertweet-base\",\n",
    "            sentiment_num_classes=len(sentiment_encoder.classes_),\n",
    "            emotion_num_classes=len(emotion_encoder.classes_)\n",
    "        )\n",
    "        \n",
    "        # Load model weights\n",
    "        state_dict_path = os.path.join(model_path, 'pytorch_model.bin')\n",
    "        state_dict = torch.load(state_dict_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        print(f\"‚úÖ BERTweet model loaded successfully!\")\n",
    "        print(f\"   Sentiment classes: {list(sentiment_encoder.classes_)}\")\n",
    "        print(f\"   Emotion classes: {list(emotion_encoder.classes_)}\")\n",
    "        \n",
    "        return model, tokenizer, sentiment_encoder, emotion_encoder\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading model: {e}\")\n",
    "        raise\n",
    "\n",
    "def load_annotated_data(data_path: str):\n",
    "    \"\"\"Load and prepare annotated Reddit data\"\"\"\n",
    "    print(f\"üì• Loading annotated data from {data_path}...\")\n",
    "    \n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Create label encoders that match the data\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    \n",
    "    sentiment_encoder.fit(df['sentiment'].tolist())\n",
    "    emotion_encoder.fit(df['emotion'].tolist())\n",
    "    \n",
    "    data = {\n",
    "        'texts': df['text_content'].tolist(),\n",
    "        'sentiment_labels_text': df['sentiment'].tolist(),\n",
    "        'emotion_labels_text': df['emotion'].tolist(),\n",
    "        'sentiment_labels': sentiment_encoder.transform(df['sentiment'].tolist()),\n",
    "        'emotion_labels': emotion_encoder.transform(df['emotion'].tolist()),\n",
    "        'data_sentiment_encoder': sentiment_encoder,\n",
    "        'data_emotion_encoder': emotion_encoder\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Data loaded: {len(data['texts'])} samples\")\n",
    "    print(f\"   Sentiment classes: {list(sentiment_encoder.classes_)}\")\n",
    "    print(f\"   Emotion classes: {list(emotion_encoder.classes_)}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load model and data\n",
    "model_path = \"bertweet_model_ultra_light\"\n",
    "model, tokenizer, model_sentiment_encoder, model_emotion_encoder = load_bertweet_model(model_path)\n",
    "annotated_data = load_annotated_data(\"annotated_reddit_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Bootstrap Evaluation Functions\n",
    "def evaluate_model_on_sample(model, tokenizer, texts, sentiment_labels, emotion_labels, \n",
    "                           model_sentiment_encoder, model_emotion_encoder, max_length=128):\n",
    "    \"\"\"Evaluate model on a single sample of texts\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    sentiment_predictions = []\n",
    "    emotion_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 8):  # Batch size 8\n",
    "            batch_texts = texts[i:i+8]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=max_length\n",
    "            )\n",
    "            \n",
    "            # Filter out token_type_ids if present (BERTweet doesn't use them)\n",
    "            filtered_inputs = {\n",
    "                'input_ids': inputs['input_ids'].to(device),\n",
    "                'attention_mask': inputs['attention_mask'].to(device)\n",
    "            }\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**filtered_inputs)\n",
    "            \n",
    "            # Process sentiment\n",
    "            sentiment_logits = outputs['sentiment_logits']\n",
    "            sentiment_preds = torch.argmax(sentiment_logits, dim=-1)\n",
    "            \n",
    "            # Process emotion\n",
    "            emotion_logits = outputs['emotion_logits']\n",
    "            emotion_preds = torch.argmax(emotion_logits, dim=-1)\n",
    "            \n",
    "            # Collect predictions\n",
    "            for j in range(len(batch_texts)):\n",
    "                sent_id = sentiment_preds[j].item()\n",
    "                emot_id = emotion_preds[j].item()\n",
    "                \n",
    "                # Handle out of range predictions\n",
    "                if sent_id >= len(model_sentiment_encoder.classes_):\n",
    "                    sent_id = 0\n",
    "                if emot_id >= len(model_emotion_encoder.classes_):\n",
    "                    emot_id = 0\n",
    "                \n",
    "                sentiment_predictions.append(sent_id)\n",
    "                emotion_predictions.append(emot_id)\n",
    "    \n",
    "    # Map model predictions to data label space\n",
    "    # This is crucial for proper evaluation\n",
    "    mapped_sentiment_preds = []\n",
    "    mapped_emotion_preds = []\n",
    "    \n",
    "    for sent_pred, emot_pred in zip(sentiment_predictions, emotion_predictions):\n",
    "        # Get predicted class name from model encoder\n",
    "        sent_class = model_sentiment_encoder.classes_[sent_pred]\n",
    "        emot_class = model_emotion_encoder.classes_[emot_pred]\n",
    "        \n",
    "        # Map to data encoder space\n",
    "        try:\n",
    "            mapped_sent = annotated_data['data_sentiment_encoder'].transform([sent_class])[0]\n",
    "            mapped_emot = annotated_data['data_emotion_encoder'].transform([emot_class])[0]\n",
    "        except ValueError:\n",
    "            # If class not found, use most frequent class\n",
    "            mapped_sent = 0\n",
    "            mapped_emot = 0\n",
    "        \n",
    "        mapped_sentiment_preds.append(mapped_sent)\n",
    "        mapped_emotion_preds.append(mapped_emot)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    sentiment_accuracy = accuracy_score(sentiment_labels, mapped_sentiment_preds)\n",
    "    sentiment_f1 = f1_score(sentiment_labels, mapped_sentiment_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    emotion_accuracy = accuracy_score(emotion_labels, mapped_emotion_preds)\n",
    "    emotion_f1 = f1_score(emotion_labels, mapped_emotion_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'sentiment_accuracy': sentiment_accuracy,\n",
    "        'sentiment_f1': sentiment_f1,\n",
    "        'emotion_accuracy': emotion_accuracy,\n",
    "        'emotion_f1': emotion_f1\n",
    "    }\n",
    "\n",
    "def bootstrap_evaluation(model, tokenizer, data, model_sentiment_encoder, model_emotion_encoder, \n",
    "                        n_iterations=1000, sample_size=95):\n",
    "    \"\"\"Perform bootstrap evaluation\"\"\"\n",
    "    print(f\"üîÑ Starting bootstrap evaluation...\")\n",
    "    print(f\"   Iterations: {n_iterations}\")\n",
    "    print(f\"   Sample size: {sample_size}\")\n",
    "    \n",
    "    results = {\n",
    "        'sentiment_accuracy': [],\n",
    "        'sentiment_f1': [],\n",
    "        'emotion_accuracy': [],\n",
    "        'emotion_f1': []\n",
    "    }\n",
    "    \n",
    "    texts = data['texts']\n",
    "    sentiment_labels = data['sentiment_labels']\n",
    "    emotion_labels = data['emotion_labels']\n",
    "    n_samples = len(texts)\n",
    "    \n",
    "    for i in tqdm(range(n_iterations), desc=\"Bootstrap iterations\"):\n",
    "        # Bootstrap sample with replacement\n",
    "        indices = np.random.choice(n_samples, size=sample_size, replace=True)\n",
    "        \n",
    "        sample_texts = [texts[idx] for idx in indices]\n",
    "        sample_sentiment_labels = [sentiment_labels[idx] for idx in indices]\n",
    "        sample_emotion_labels = [emotion_labels[idx] for idx in indices]\n",
    "        \n",
    "        # Evaluate on bootstrap sample\n",
    "        metrics = evaluate_model_on_sample(\n",
    "            model, tokenizer, sample_texts, sample_sentiment_labels, sample_emotion_labels,\n",
    "            model_sentiment_encoder, model_emotion_encoder\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results['sentiment_accuracy'].append(metrics['sentiment_accuracy'])\n",
    "        results['sentiment_f1'].append(metrics['sentiment_f1'])\n",
    "        results['emotion_accuracy'].append(metrics['emotion_accuracy'])\n",
    "        results['emotion_f1'].append(metrics['emotion_f1'])\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Bootstrap evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Run Bootstrap Analysis\n",
    "print(\"üöÄ Running Bootstrap Analysis for BERTweet Model\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run bootstrap evaluation\n",
    "bootstrap_results = bootstrap_evaluation(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data=annotated_data,\n",
    "    model_sentiment_encoder=model_sentiment_encoder,\n",
    "    model_emotion_encoder=model_emotion_encoder,\n",
    "    n_iterations=1000,\n",
    "    sample_size=95\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Bootstrap analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86704af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Calculate Statistics and Confidence Intervals\n",
    "def calculate_bootstrap_statistics(results):\n",
    "    \"\"\"Calculate bootstrap statistics\"\"\"\n",
    "    statistics = {}\n",
    "    \n",
    "    for metric_name, values in results.items():\n",
    "        values = np.array(values)\n",
    "        \n",
    "        # Basic statistics\n",
    "        mean = np.mean(values)\n",
    "        std = np.std(values)\n",
    "        \n",
    "        # 95% Confidence Interval (using percentile method)\n",
    "        ci_lower = np.percentile(values, 2.5)\n",
    "        ci_upper = np.percentile(values, 97.5)\n",
    "        \n",
    "        statistics[metric_name] = {\n",
    "            'mean': mean,\n",
    "            'std': std,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper,\n",
    "            'values': values\n",
    "        }\n",
    "    \n",
    "    return statistics\n",
    "\n",
    "# Calculate statistics\n",
    "bootstrap_stats = calculate_bootstrap_statistics(bootstrap_results)\n",
    "\n",
    "# Print results\n",
    "print(\"üìä Bootstrap Analysis Results for BERTweet Model\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for metric_name, stats in bootstrap_stats.items():\n",
    "    task, measure = metric_name.split('_')\n",
    "    print(f\"\\nüéØ {task.upper()} - {measure.upper()}\")\n",
    "    print(f\"   Mean: {stats['mean']:.4f}\")\n",
    "    print(f\"   Std:  {stats['std']:.4f}\")\n",
    "    print(f\"   95% CI: [{stats['ci_lower']:.4f}, {stats['ci_upper']:.4f}]\")\n",
    "\n",
    "print(f\"\\nüìà Summary:\")\n",
    "print(f\"   Sentiment Accuracy: {bootstrap_stats['sentiment_accuracy']['mean']:.4f} ¬± {bootstrap_stats['sentiment_accuracy']['std']:.4f}\")\n",
    "print(f\"   Sentiment Macro-F1: {bootstrap_stats['sentiment_f1']['mean']:.4f} ¬± {bootstrap_stats['sentiment_f1']['std']:.4f}\")\n",
    "print(f\"   Emotion Accuracy:   {bootstrap_stats['emotion_accuracy']['mean']:.4f} ¬± {bootstrap_stats['emotion_accuracy']['std']:.4f}\")\n",
    "print(f\"   Emotion Macro-F1:   {bootstrap_stats['emotion_f1']['mean']:.4f} ¬± {bootstrap_stats['emotion_f1']['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2eb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create Histograms - Figure 1 (Accuracy Distributions)\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Sentiment Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "sentiment_acc_values = bootstrap_stats['sentiment_accuracy']['values']\n",
    "plt.hist(sentiment_acc_values, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(bootstrap_stats['sentiment_accuracy']['mean'], color='red', linestyle='--', linewidth=2, \n",
    "           label=f\"Mean: {bootstrap_stats['sentiment_accuracy']['mean']:.4f}\")\n",
    "plt.axvline(bootstrap_stats['sentiment_accuracy']['ci_lower'], color='orange', linestyle=':', linewidth=2,\n",
    "           label=f\"95% CI: [{bootstrap_stats['sentiment_accuracy']['ci_lower']:.4f}, {bootstrap_stats['sentiment_accuracy']['ci_upper']:.4f}]\")\n",
    "plt.axvline(bootstrap_stats['sentiment_accuracy']['ci_upper'], color='orange', linestyle=':', linewidth=2)\n",
    "plt.xlabel('Accuracy Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('BERTweet: Sentiment Classification Accuracy\\nBootstrap Distribution (1000 iterations)', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Emotion Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "emotion_acc_values = bootstrap_stats['emotion_accuracy']['values']\n",
    "plt.hist(emotion_acc_values, bins=50, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "plt.axvline(bootstrap_stats['emotion_accuracy']['mean'], color='red', linestyle='--', linewidth=2,\n",
    "           label=f\"Mean: {bootstrap_stats['emotion_accuracy']['mean']:.4f}\")\n",
    "plt.axvline(bootstrap_stats['emotion_accuracy']['ci_lower'], color='orange', linestyle=':', linewidth=2,\n",
    "           label=f\"95% CI: [{bootstrap_stats['emotion_accuracy']['ci_lower']:.4f}, {bootstrap_stats['emotion_accuracy']['ci_upper']:.4f}]\")\n",
    "plt.axvline(bootstrap_stats['emotion_accuracy']['ci_upper'], color='orange', linestyle=':', linewidth=2)\n",
    "plt.xlabel('Accuracy Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('BERTweet: Emotion Classification Accuracy\\nBootstrap Distribution (1000 iterations)', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('bertweet_bootstrap_accuracy_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71bf57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Create Histograms - Figure 2 (Macro-F1 Distributions)\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Sentiment Macro-F1\n",
    "plt.subplot(1, 2, 1)\n",
    "sentiment_f1_values = bootstrap_stats['sentiment_f1']['values']\n",
    "plt.hist(sentiment_f1_values, bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "plt.axvline(bootstrap_stats['sentiment_f1']['mean'], color='red', linestyle='--', linewidth=2,\n",
    "           label=f\"Mean: {bootstrap_stats['sentiment_f1']['mean']:.4f}\")\n",
    "plt.axvline(bootstrap_stats['sentiment_f1']['ci_lower'], color='orange', linestyle=':', linewidth=2,\n",
    "           label=f\"95% CI: [{bootstrap_stats['sentiment_f1']['ci_lower']:.4f}, {bootstrap_stats['sentiment_f1']['ci_upper']:.4f}]\")\n",
    "plt.axvline(bootstrap_stats['sentiment_f1']['ci_upper'], color='orange', linestyle=':', linewidth=2)\n",
    "plt.xlabel('Macro-F1 Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('BERTweet: Sentiment Classification Macro-F1\\nBootstrap Distribution (1000 iterations)', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Emotion Macro-F1\n",
    "plt.subplot(1, 2, 2)\n",
    "emotion_f1_values = bootstrap_stats['emotion_f1']['values']\n",
    "plt.hist(emotion_f1_values, bins=50, alpha=0.7, color='plum', edgecolor='black')\n",
    "plt.axvline(bootstrap_stats['emotion_f1']['mean'], color='red', linestyle='--', linewidth=2,\n",
    "           label=f\"Mean: {bootstrap_stats['emotion_f1']['mean']:.4f}\")\n",
    "plt.axvline(bootstrap_stats['emotion_f1']['ci_lower'], color='orange', linestyle=':', linewidth=2,\n",
    "           label=f\"95% CI: [{bootstrap_stats['emotion_f1']['ci_lower']:.4f}, {bootstrap_stats['emotion_f1']['ci_upper']:.4f}]\")\n",
    "plt.axvline(bootstrap_stats['emotion_f1']['ci_upper'], color='orange', linestyle=':', linewidth=2)\n",
    "plt.xlabel('Macro-F1 Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('BERTweet: Emotion Classification Macro-F1\\nBootstrap Distribution (1000 iterations)', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('bertweet_bootstrap_f1_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5958667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Save Bootstrap Results and Generate Summary Report\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_bootstrap_results(bootstrap_stats, model_name=\"BERTweet\"):\n",
    "    \"\"\"Save bootstrap results to files\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Prepare serializable results\n",
    "    serializable_results = {}\n",
    "    for metric_name, stats in bootstrap_stats.items():\n",
    "        serializable_results[metric_name] = {\n",
    "            'mean': float(stats['mean']),\n",
    "            'std': float(stats['std']),\n",
    "            'ci_lower': float(stats['ci_lower']),\n",
    "            'ci_upper': float(stats['ci_upper']),\n",
    "            'values': [float(x) for x in stats['values']]\n",
    "        }\n",
    "    \n",
    "    # Save detailed results\n",
    "    results_file = f\"bertweet_bootstrap_results_{timestamp}.json\"\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    # Create summary report\n",
    "    summary_file = f\"bertweet_bootstrap_summary_{timestamp}.txt\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(f\"{model_name} Bootstrap Analysis Summary Report\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        f.write(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Bootstrap Iterations: 1000\\n\")\n",
    "        f.write(f\"Sample Size per Iteration: 95\\n\")\n",
    "        f.write(f\"Total Dataset Size: 95\\n\\n\")\n",
    "        \n",
    "        f.write(\"PERFORMANCE METRICS (Mean ¬± Std)\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\\n\")\n",
    "        \n",
    "        for metric_name, stats in bootstrap_stats.items():\n",
    "            task, measure = metric_name.split('_')\n",
    "            f.write(f\"{task.upper()} {measure.upper()}:\\n\")\n",
    "            f.write(f\"  Mean: {stats['mean']:.4f}\\n\")\n",
    "            f.write(f\"  Std:  {stats['std']:.4f}\\n\")\n",
    "            f.write(f\"  95% CI: [{stats['ci_lower']:.4f}, {stats['ci_upper']:.4f}]\\n\\n\")\n",
    "        \n",
    "        f.write(\"KEY FINDINGS:\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        \n",
    "        # Calculate coefficient of variation for stability assessment\n",
    "        sent_acc_cv = bootstrap_stats['sentiment_accuracy']['std'] / bootstrap_stats['sentiment_accuracy']['mean']\n",
    "        sent_f1_cv = bootstrap_stats['sentiment_f1']['std'] / bootstrap_stats['sentiment_f1']['mean']\n",
    "        emot_acc_cv = bootstrap_stats['emotion_accuracy']['std'] / bootstrap_stats['emotion_accuracy']['mean']\n",
    "        emot_f1_cv = bootstrap_stats['emotion_f1']['std'] / bootstrap_stats['emotion_f1']['mean']\n",
    "        \n",
    "        f.write(f\"1. Stability Assessment (Coefficient of Variation):\\n\")\n",
    "        f.write(f\"   - Sentiment Accuracy CV: {sent_acc_cv:.4f}\\n\")\n",
    "        f.write(f\"   - Sentiment F1 CV: {sent_f1_cv:.4f}\\n\")\n",
    "        f.write(f\"   - Emotion Accuracy CV: {emot_acc_cv:.4f}\\n\")\n",
    "        f.write(f\"   - Emotion F1 CV: {emot_f1_cv:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"2. Best Performing Task:\\n\")\n",
    "        if bootstrap_stats['sentiment_f1']['mean'] > bootstrap_stats['emotion_f1']['mean']:\n",
    "            f.write(f\"   - Sentiment classification (F1: {bootstrap_stats['sentiment_f1']['mean']:.4f})\\n\")\n",
    "        else:\n",
    "            f.write(f\"   - Emotion classification (F1: {bootstrap_stats['emotion_f1']['mean']:.4f})\\n\")\n",
    "        \n",
    "        f.write(f\"\\n3. Confidence Interval Widths:\\n\")\n",
    "        for metric_name, stats in bootstrap_stats.items():\n",
    "            ci_width = stats['ci_upper'] - stats['ci_lower']\n",
    "            f.write(f\"   - {metric_name}: {ci_width:.4f}\\n\")\n",
    "    \n",
    "    print(f\"\\nüíæ Bootstrap results saved:\")\n",
    "    print(f\"   Detailed results: {results_file}\")\n",
    "    print(f\"   Summary report: {summary_file}\")\n",
    "    \n",
    "    return results_file, summary_file\n",
    "\n",
    "# Save results\n",
    "results_file, summary_file = save_bootstrap_results(bootstrap_stats, \"BERTweet\")\n",
    "\n",
    "print(\"\\nüéâ Bootstrap Analysis Complete!\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üìä Final Summary:\")\n",
    "for metric_name, stats in bootstrap_stats.items():\n",
    "    task, measure = metric_name.split('_')\n",
    "    print(f\"   {task.title()} {measure.title()}: {stats['mean']:.4f} ¬± {stats['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050d299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
