{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e3244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    RobertaTokenizer, RobertaForSequenceClassification,\n",
    "    AutoTokenizer, AutoModel, AutoConfig,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import random\n",
    "from collections import Counter\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"./random_seed_analysis_results\", exist_ok=True)\n",
    "os.makedirs(\"./trained_models_seeds\", exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Libraries imported and setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c953f59",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'env (Python 3.9.6)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/edw/Desktop/multitask/env/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Cell 2: Utility Functions for Memory Management\n",
    "def set_random_seed(seed: int):\n",
    "    \"\"\"Set random seed for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def print_memory_usage():\n",
    "    \"\"\"Print current GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f} GB, Cached: {cached:.2f} GB\")\n",
    "\n",
    "print(\"‚úÖ Utility functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Loading and Preprocessing Functions\n",
    "def load_external_datasets() -> Tuple[Dict, Dict]:\n",
    "    \"\"\"Load SST-2 and GoEmotions datasets\"\"\"\n",
    "    print(\"Loading external datasets...\")\n",
    "    \n",
    "    # Load SST-2 for sentiment\n",
    "    try:\n",
    "        sst2_dataset = load_dataset(\"sst2\")\n",
    "        sentiment_data = {\n",
    "            'train': sst2_dataset['train'],\n",
    "            'validation': sst2_dataset['validation']\n",
    "        }\n",
    "        print(f\"‚úÖ SST-2 dataset loaded: {len(sentiment_data['train'])} train samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not load SST-2: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Load GoEmotions for emotion\n",
    "    try:\n",
    "        emotions_dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "        emotion_data = {\n",
    "            'train': emotions_dataset['train'],\n",
    "            'validation': emotions_dataset['validation']\n",
    "        }\n",
    "        print(f\"‚úÖ GoEmotions dataset loaded: {len(emotion_data['train'])} train samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not load GoEmotions: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return sentiment_data, emotion_data\n",
    "\n",
    "def prepare_reddit_evaluation_data(reddit_data_path: str) -> Dict:\n",
    "    \"\"\"Load and prepare Reddit data for evaluation\"\"\"\n",
    "    print(f\"Loading Reddit evaluation data from {reddit_data_path}...\")\n",
    "    \n",
    "    df = pd.read_csv(reddit_data_path)\n",
    "    \n",
    "    # Create label encoders that match your existing models\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    \n",
    "    # Fit encoders\n",
    "    sentiment_encoder.fit(df['sentiment'].tolist())\n",
    "    emotion_encoder.fit(df['emotion'].tolist())\n",
    "    \n",
    "    reddit_data = {\n",
    "        'texts': df['text_content'].tolist(),\n",
    "        'sentiment_labels_text': df['sentiment'].tolist(),\n",
    "        'emotion_labels_text': df['emotion'].tolist(),\n",
    "        'sentiment_labels': sentiment_encoder.transform(df['sentiment'].tolist()),\n",
    "        'emotion_labels': emotion_encoder.transform(df['emotion'].tolist()),\n",
    "        'sentiment_encoder': sentiment_encoder,\n",
    "        'emotion_encoder': emotion_encoder\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Reddit data prepared: {len(reddit_data['texts'])} samples\")\n",
    "    print(f\"   Sentiment classes: {list(sentiment_encoder.classes_)}\")\n",
    "    print(f\"   Emotion classes: {list(emotion_encoder.classes_)}\")\n",
    "    \n",
    "    return reddit_data\n",
    "\n",
    "print(\"‚úÖ Data loading functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bda7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dataset Classes\n",
    "class RobertaDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer, max_length: int = 512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], sentiment_labels: List[int], \n",
    "                 emotion_labels: List[int], tokenizer, max_length: int = 128):\n",
    "        self.texts = texts\n",
    "        self.sentiment_labels = sentiment_labels\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        sentiment_label = self.sentiment_labels[idx]\n",
    "        emotion_label = self.emotion_labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'sentiment_labels': torch.tensor(sentiment_label, dtype=torch.long),\n",
    "            'emotion_labels': torch.tensor(emotion_label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Dataset classes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f021c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Multitask Model Architecture (Same as your stad-valid.ipynb)\n",
    "class MultiTaskTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"microsoft/deberta-base\",\n",
    "        sentiment_num_classes: int = 3,\n",
    "        emotion_num_classes: int = 6,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super(MultiTaskTransformer, self).__init__()\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.sentiment_num_classes = sentiment_num_classes\n",
    "        self.emotion_num_classes = emotion_num_classes\n",
    "        \n",
    "        # Load configuration and adjust dropout\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        # Shared transformer encoder\n",
    "        self.shared_encoder = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            config=config,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        hidden_size = self.shared_encoder.config.hidden_size\n",
    "        \n",
    "        # Task-specific attention layers\n",
    "        self.sentiment_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.emotion_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Shared attention for common features\n",
    "        self.shared_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.sentiment_norm = nn.LayerNorm(hidden_size)\n",
    "        self.emotion_norm = nn.LayerNorm(hidden_size)\n",
    "        self.shared_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.sentiment_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.emotion_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.shared_dropout = nn.Dropout(classifier_dropout)\n",
    "        \n",
    "        # Classification heads\n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, sentiment_num_classes)\n",
    "        )\n",
    "        \n",
    "        self.emotion_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, emotion_num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in [self.sentiment_classifier, self.emotion_classifier]:\n",
    "            for layer in module:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor, \n",
    "                task: Optional[str] = None) -> Dict[str, torch.Tensor]:\n",
    "        # Shared encoder\n",
    "        encoder_outputs = self.shared_encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        sequence_output = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply shared attention\n",
    "        shared_attended, _ = self.shared_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        shared_attended = self.shared_norm(shared_attended + sequence_output)\n",
    "        shared_attended = self.shared_dropout(shared_attended)\n",
    "        shared_pooled = shared_attended[:, 0, :]\n",
    "        \n",
    "        outputs = {}\n",
    "        \n",
    "        # Sentiment branch\n",
    "        if task is None or task == \"sentiment\":\n",
    "            sentiment_attended, sentiment_weights = self.sentiment_attention(\n",
    "                sequence_output, sequence_output, sequence_output,\n",
    "                key_padding_mask=~attention_mask.bool()\n",
    "            )\n",
    "            sentiment_attended = self.sentiment_norm(sentiment_attended + sequence_output)\n",
    "            sentiment_attended = self.sentiment_dropout(sentiment_attended)\n",
    "            sentiment_pooled = sentiment_attended[:, 0, :]\n",
    "            sentiment_features = torch.cat([shared_pooled, sentiment_pooled], dim=-1)\n",
    "            sentiment_logits = self.sentiment_classifier(sentiment_features)\n",
    "            outputs[\"sentiment_logits\"] = sentiment_logits\n",
    "        \n",
    "        # Emotion branch\n",
    "        if task is None or task == \"emotion\":\n",
    "            emotion_attended, emotion_weights = self.emotion_attention(\n",
    "                sequence_output, sequence_output, sequence_output,\n",
    "                key_padding_mask=~attention_mask.bool()\n",
    "            )\n",
    "            emotion_attended = self.emotion_norm(emotion_attended + sequence_output)\n",
    "            emotion_attended = self.emotion_dropout(emotion_attended)\n",
    "            emotion_pooled = emotion_attended[:, 0, :]\n",
    "            emotion_features = torch.cat([shared_pooled, emotion_pooled], dim=-1)\n",
    "            emotion_logits = self.emotion_classifier(emotion_features)\n",
    "            outputs[\"emotion_logits\"] = emotion_logits\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "print(\"‚úÖ Multitask model architecture defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd732720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Training Functions for Single-Task Models\n",
    "def train_roberta_single_task(\n",
    "    task_type: str,  # 'sentiment' or 'emotion'\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    sentiment_data: Dict = None,\n",
    "    emotion_data: Dict = None,\n",
    "    max_samples: int = 10000\n",
    ") -> Tuple[any, LabelEncoder]:\n",
    "    \"\"\"Train a single-task RoBERTa model\"\"\"\n",
    "    \n",
    "    print(f\"üöÄ Training RoBERTa {task_type} model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Load appropriate dataset\n",
    "    if task_type == 'sentiment':\n",
    "        raw_data = sentiment_data\n",
    "        text_col = 'sentence'\n",
    "        label_col = 'label'\n",
    "    else:  # emotion\n",
    "        raw_data = emotion_data\n",
    "        text_col = 'text'\n",
    "        label_col = 'labels'\n",
    "    \n",
    "    # Prepare data\n",
    "    train_texts = raw_data['train'][text_col][:max_samples]\n",
    "    train_labels_raw = raw_data['train'][label_col][:max_samples]\n",
    "    \n",
    "    # Handle emotion multi-label to single-label conversion\n",
    "    if task_type == 'emotion':\n",
    "        # Filter to first 6 classes only and convert multi-label to single-label\n",
    "        train_labels = []\n",
    "        filtered_texts = []\n",
    "        for i, label in enumerate(train_labels_raw):\n",
    "            if isinstance(label, list):\n",
    "                if label and label[0] in range(6):\n",
    "                    train_labels.append(label[0])\n",
    "                    filtered_texts.append(train_texts[i])\n",
    "            else:\n",
    "                if label in range(6):\n",
    "                    train_labels.append(label)\n",
    "                    filtered_texts.append(train_texts[i])\n",
    "        train_texts = filtered_texts\n",
    "    else:\n",
    "        train_labels = train_labels_raw\n",
    "    \n",
    "    # Create label encoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    if task_type == 'sentiment':\n",
    "        # Map SST-2 to 3 classes: 0->Negative, 1->Positive, add some Neutral\n",
    "        label_names = ['Negative', 'Neutral', 'Positive']\n",
    "        converted_labels = []\n",
    "        for label in train_labels:\n",
    "            if label == 0:  # Negative\n",
    "                converted_labels.append(0)\n",
    "            elif label == 1:  # Positive\n",
    "                # Add some neutral examples\n",
    "                if np.random.random() < 0.1:\n",
    "                    converted_labels.append(1)  # Neutral\n",
    "                else:\n",
    "                    converted_labels.append(2)  # Positive\n",
    "        \n",
    "        # Ensure we have all classes\n",
    "        if 1 not in converted_labels:\n",
    "            neutral_indices = np.random.choice(len(converted_labels), size=50, replace=False)\n",
    "            for idx in neutral_indices:\n",
    "                converted_labels[idx] = 1\n",
    "        \n",
    "        train_labels = converted_labels\n",
    "        label_encoder.classes_ = np.array(label_names)\n",
    "    else:  # emotion\n",
    "        label_names = ['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise']\n",
    "        label_encoder.classes_ = np.array(label_names)\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        'roberta-base',\n",
    "        num_labels=len(label_encoder.classes_),\n",
    "        hidden_dropout_prob=best_params['dropout_rate'],\n",
    "        attention_probs_dropout_prob=best_params['dropout_rate']\n",
    "    )\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = RobertaDataset(train_texts, train_labels, tokenizer, max_length=512)\n",
    "    \n",
    "    # Training arguments\n",
    "    output_dir = f\"./trained_models_seeds/roberta_{task_type}_seed_{seed}\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=best_params['num_epochs'],\n",
    "        per_device_train_batch_size=best_params['batch_size'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay'],\n",
    "        warmup_ratio=best_params['warmup_ratio'],\n",
    "        logging_steps=100,\n",
    "        save_strategy=\"no\",  # Don't save during training\n",
    "        dataloader_num_workers=0,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save model and encoder\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(label_encoder, os.path.join(output_dir, f'{task_type}_encoder.pkl'))\n",
    "    \n",
    "    print(f\"‚úÖ RoBERTa {task_type} model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, label_encoder\n",
    "\n",
    "print(\"‚úÖ Single-task training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Training Functions for Multitask Models\n",
    "def prepare_multitask_data(sentiment_data: Dict, emotion_data: Dict, max_samples: int = 5000):\n",
    "    \"\"\"Prepare combined data for multitask training\"\"\"\n",
    "    \n",
    "    # Get sentiment data (SST-2)\n",
    "    sentiment_texts = sentiment_data['train']['sentence'][:max_samples]\n",
    "    sentiment_labels_raw = sentiment_data['train']['label'][:max_samples]\n",
    "    \n",
    "    # Get emotion data (GoEmotions, first 6 classes only)\n",
    "    emotion_texts_all = emotion_data['train']['text']\n",
    "    emotion_labels_all = emotion_data['train']['labels']\n",
    "    \n",
    "    # Filter emotion data to first 6 classes\n",
    "    emotion_texts = []\n",
    "    emotion_labels = []\n",
    "    count = 0\n",
    "    for i, label in enumerate(emotion_labels_all):\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "        if isinstance(label, list):\n",
    "            if label and label[0] in range(6):\n",
    "                emotion_texts.append(emotion_texts_all[i])\n",
    "                emotion_labels.append(label[0])\n",
    "                count += 1\n",
    "        else:\n",
    "            if label in range(6):\n",
    "                emotion_texts.append(emotion_texts_all[i])\n",
    "                emotion_labels.append(label)\n",
    "                count += 1\n",
    "    \n",
    "    # Convert sentiment labels: 0->Negative(0), 1->Positive(2), add Neutral(1)\n",
    "    converted_sentiment_labels = []\n",
    "    for label in sentiment_labels_raw:\n",
    "        if label == 0:  # Negative\n",
    "            converted_sentiment_labels.append(0)\n",
    "        elif label == 1:  # Positive\n",
    "            if np.random.random() < 0.1:\n",
    "                converted_sentiment_labels.append(1)  # Neutral\n",
    "            else:\n",
    "                converted_sentiment_labels.append(2)  # Positive\n",
    "    \n",
    "    # Ensure neutral class exists\n",
    "    if 1 not in converted_sentiment_labels:\n",
    "        neutral_indices = np.random.choice(len(converted_sentiment_labels), size=50, replace=False)\n",
    "        for idx in neutral_indices:\n",
    "            converted_sentiment_labels[idx] = 1\n",
    "    \n",
    "    # Use minimum length to balance datasets\n",
    "    min_length = min(len(sentiment_texts), len(emotion_texts))\n",
    "    \n",
    "    combined_texts = sentiment_texts[:min_length]\n",
    "    combined_sentiment_labels = converted_sentiment_labels[:min_length]\n",
    "    combined_emotion_labels = emotion_labels[:min_length]\n",
    "    \n",
    "    # Create encoders\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    sentiment_encoder.classes_ = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "    emotion_encoder.classes_ = np.array(['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise'])\n",
    "    \n",
    "    return {\n",
    "        'texts': combined_texts,\n",
    "        'sentiment_labels': combined_sentiment_labels,\n",
    "        'emotion_labels': combined_emotion_labels,\n",
    "        'sentiment_encoder': sentiment_encoder,\n",
    "        'emotion_encoder': emotion_encoder\n",
    "    }\n",
    "\n",
    "def train_multitask_model(\n",
    "    model_name: str,  # \"microsoft/deberta-base\" or \"vinai/bertweet-base\"\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    sentiment_data: Dict,\n",
    "    emotion_data: Dict,\n",
    "    max_samples: int = 2000\n",
    ") -> Tuple[any, LabelEncoder, LabelEncoder]:\n",
    "    \"\"\"Train a multitask model\"\"\"\n",
    "    \n",
    "    model_type = \"deberta\" if \"deberta\" in model_name else \"bertweet\"\n",
    "    print(f\"üöÄ Training {model_type} multitask model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Prepare multitask data\n",
    "    data = prepare_multitask_data(sentiment_data, emotion_data, max_samples)\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = MultiTaskTransformer(\n",
    "        model_name=model_name,\n",
    "        sentiment_num_classes=3,\n",
    "        emotion_num_classes=6,\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        attention_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = MultiTaskDataset(\n",
    "        texts=data['texts'],\n",
    "        sentiment_labels=data['sentiment_labels'],\n",
    "        emotion_labels=data['emotion_labels'],\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=best_params['max_length']\n",
    "    )\n",
    "    \n",
    "    # Create data loader\n",
    "    dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    total_steps = len(dataloader) * best_params['num_epochs']\n",
    "    warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Compute class weights\n",
    "    sentiment_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(data['sentiment_labels']),\n",
    "        y=data['sentiment_labels']\n",
    "    )\n",
    "    emotion_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(data['emotion_labels']),\n",
    "        y=data['emotion_labels']\n",
    "    )\n",
    "    \n",
    "    sentiment_weights = torch.FloatTensor(sentiment_weights).to(device)\n",
    "    emotion_weights = torch.FloatTensor(emotion_weights).to(device)\n",
    "    \n",
    "    # Loss functions\n",
    "    sentiment_criterion = nn.CrossEntropyLoss(weight=sentiment_weights)\n",
    "    emotion_criterion = nn.CrossEntropyLoss(weight=emotion_weights)\n",
    "    \n",
    "    alpha = best_params['alpha']\n",
    "    \n",
    "    print(f\"Starting training for {best_params['num_epochs']} epochs...\")\n",
    "    \n",
    "    for epoch in range(best_params['num_epochs']):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            sentiment_labels = batch['sentiment_labels'].to(device)\n",
    "            emotion_labels = batch['emotion_labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Calculate losses\n",
    "            sentiment_loss = sentiment_criterion(outputs['sentiment_logits'], sentiment_labels)\n",
    "            emotion_loss = emotion_criterion(outputs['emotion_logits'], emotion_labels)\n",
    "            \n",
    "            # Combined loss\n",
    "            total_loss_batch = alpha * sentiment_loss + (1 - alpha) * emotion_loss\n",
    "            total_loss += total_loss_batch.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{best_params['num_epochs']}, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    output_dir = f\"./trained_models_seeds/{model_type}_multitask_seed_{seed}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model state dict\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "    \n",
    "    # Save config\n",
    "    config = {\n",
    "        \"model_name\": model_name,\n",
    "        \"sentiment_num_classes\": 3,\n",
    "        \"emotion_num_classes\": 6,\n",
    "        \"model_type\": \"MultiTaskTransformer\"\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"config.json\"), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save tokenizer and encoders\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(data['sentiment_encoder'], os.path.join(output_dir, 'sentiment_encoder.pkl'))\n",
    "    joblib.dump(data['emotion_encoder'], os.path.join(output_dir, 'emotion_encoder.pkl'))\n",
    "    \n",
    "    print(f\"‚úÖ {model_type} multitask model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, data['sentiment_encoder'], data['emotion_encoder']\n",
    "\n",
    "print(\"‚úÖ Multitask training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6650680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Evaluation Functions\n",
    "def evaluate_single_task_model(model, tokenizer, label_encoder, reddit_data: Dict, task_type: str) -> Dict:\n",
    "    \"\"\"Evaluate a single-task model on Reddit data\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_labels = reddit_data[f'{task_type}_labels']\n",
    "    \n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 16):  # Batch size 16\n",
    "            batch_texts = texts[i:i+16]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=512\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                pred_id = preds[j].item()\n",
    "                confidence = probs[j][pred_id].item()\n",
    "                \n",
    "                # Handle out of range predictions\n",
    "                if pred_id >= len(label_encoder.classes_):\n",
    "                    pred_id = 0\n",
    "                \n",
    "                predictions.append(pred_id)\n",
    "                confidences.append(confidence)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    macro_f1 = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'predictions': predictions,\n",
    "        'confidences': confidences,\n",
    "        'true_labels': true_labels\n",
    "    }\n",
    "\n",
    "def evaluate_multitask_model(model, tokenizer, sentiment_encoder, emotion_encoder, \n",
    "                           reddit_data: Dict, max_length: int = 128) -> Dict:\n",
    "    \"\"\"Evaluate a multitask model on Reddit data\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_sentiment_labels = reddit_data['sentiment_labels']\n",
    "    true_emotion_labels = reddit_data['emotion_labels']\n",
    "    \n",
    "    sentiment_predictions = []\n",
    "    emotion_predictions = []\n",
    "    sentiment_confidences = []\n",
    "    emotion_confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 8):  # Smaller batch size for multitask\n",
    "            batch_texts = texts[i:i+8]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=max_length\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=inputs['input_ids'], \n",
    "                          attention_mask=inputs['attention_mask'])\n",
    "            \n",
    "            # Process sentiment\n",
    "            sentiment_logits = outputs['sentiment_logits']\n",
    "            sentiment_probs = F.softmax(sentiment_logits, dim=-1)\n",
    "            sentiment_preds = torch.argmax(sentiment_logits, dim=-1)\n",
    "            \n",
    "            # Process emotion\n",
    "            emotion_logits = outputs['emotion_logits']\n",
    "            emotion_probs = F.softmax(emotion_logits, dim=-1)\n",
    "            emotion_preds = torch.argmax(emotion_logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                # Sentiment\n",
    "                sent_id = sentiment_preds[j].item()\n",
    "                sent_conf = sentiment_probs[j][sent_id].item()\n",
    "                if sent_id >= len(sentiment_encoder.classes_):\n",
    "                    sent_id = 0\n",
    "                sentiment_predictions.append(sent_id)\n",
    "                sentiment_confidences.append(sent_conf)\n",
    "                \n",
    "                # Emotion\n",
    "                emot_id = emotion_preds[j].item()\n",
    "                emot_conf = emotion_probs[j][emot_id].item()\n",
    "                if emot_id >= len(emotion_encoder.classes_):\n",
    "                    emot_id = 0\n",
    "                emotion_predictions.append(emot_id)\n",
    "                emotion_confidences.append(emot_conf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    sentiment_accuracy = accuracy_score(true_sentiment_labels, sentiment_predictions)\n",
    "    sentiment_f1 = f1_score(true_sentiment_labels, sentiment_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    emotion_accuracy = accuracy_score(true_emotion_labels, emotion_predictions)\n",
    "    emotion_f1 = f1_score(true_emotion_labels, emotion_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'sentiment': {\n",
    "            'accuracy': sentiment_accuracy,\n",
    "            'macro_f1': sentiment_f1,\n",
    "            'predictions': sentiment_predictions,\n",
    "            'confidences': sentiment_confidences\n",
    "        },\n",
    "        'emotion': {\n",
    "            'accuracy': emotion_accuracy,\n",
    "            'macro_f1': emotion_f1,\n",
    "            'predictions': emotion_predictions,\n",
    "            'confidences': emotion_confidences\n",
    "        },\n",
    "        'combined_accuracy': (sentiment_accuracy + emotion_accuracy) / 2,\n",
    "        'combined_f1': (sentiment_f1 + emotion_f1) / 2\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41769edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Main Random Seed Analysis Function\n",
    "def run_random_seed_analysis(\n",
    "    reddit_data_path: str = \"annotated_reddit_posts.csv\",\n",
    "    seeds: List[int] = [42, 123, 456, 789, 999],\n",
    "    max_training_samples: int = 5000\n",
    "):\n",
    "    \"\"\"Run complete random seed analysis\"\"\"\n",
    "    \n",
    "    print(\"üé≤ STARTING RANDOM SEED ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Seeds to test: {seeds}\")\n",
    "    print(f\"Max training samples per dataset: {max_training_samples}\")\n",
    "    \n",
    "    # Load external datasets\n",
    "    print(\"\\nüìÇ Loading external datasets...\")\n",
    "    sentiment_data, emotion_data = load_external_datasets()\n",
    "    \n",
    "    # Load Reddit evaluation data\n",
    "    print(\"\\nüìÇ Loading Reddit evaluation data...\")\n",
    "    reddit_data = prepare_reddit_evaluation_data(reddit_data_path)\n",
    "    \n",
    "    # Define best parameters for each model\n",
    "    best_params = {\n",
    "        'roberta_sentiment': {\n",
    "            'learning_rate': 1.289795048085554e-05,\n",
    "            'batch_size': 16,\n",
    "            'dropout_rate': 0.2218455076693483,\n",
    "            'num_epochs': 3,\n",
    "            'warmup_ratio': 0.15263495397682356,\n",
    "            'weight_decay': 0.13764422318448438\n",
    "        },\n",
    "        'roberta_emotion': {\n",
    "            'learning_rate': 0.00018843871051154592,\n",
    "            'batch_size': 32,\n",
    "            'dropout_rate': 0.15859725997693935,\n",
    "            'num_epochs': 7,\n",
    "            'warmup_ratio': 0.16826426457074994,\n",
    "            'weight_decay': 0.21559177659152684\n",
    "        },\n",
    "        'deberta_multitask': {\n",
    "            'learning_rate': 2.858051065806938e-05,\n",
    "            'batch_size': 2,\n",
    "            'alpha': 0.5369658275448169,\n",
    "            'hidden_dropout_prob': 0.061612603179999434,\n",
    "            'classifier_dropout': 0.28226345557043153,\n",
    "            'weight_decay': 0.017881888245041864,\n",
    "            'warmup_ratio': 0.05975773894779193,\n",
    "            'num_epochs': 5,\n",
    "            'max_length': 128\n",
    "        },\n",
    "        'bertweet_multitask': {\n",
    "            'learning_rate': 1.3352204399988585e-05,\n",
    "            'batch_size': 4,\n",
    "            'alpha': 0.4503170063321093,\n",
    "            'hidden_dropout_prob': 0.1361646589006065,\n",
    "            'classifier_dropout': 0.16618433315983214,\n",
    "            'weight_decay': 0.06911326050717913,\n",
    "            'warmup_ratio': 0.15511878702345422,\n",
    "            'num_epochs': 5,\n",
    "            'max_length': 128\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Store results for each seed\n",
    "    all_results = {}\n",
    "    \n",
    "    for seed in seeds:\n",
    "        print(f\"\\nüå± TRAINING AND EVALUATING WITH SEED {seed}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        seed_results = {}\n",
    "        \n",
    "        # 1. Train and evaluate RoBERTa Sentiment\n",
    "        print(f\"\\n1Ô∏è‚É£ RoBERTa Sentiment (Seed {seed})\")\n",
    "        model, encoder = train_roberta_single_task(\n",
    "            'sentiment', best_params['roberta_sentiment'], seed, \n",
    "            sentiment_data, emotion_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(f\"./trained_models_seeds/roberta_sentiment_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_single_task_model(model, tokenizer, encoder, reddit_data, 'sentiment')\n",
    "        seed_results['roberta_sentiment'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 2. Train and evaluate RoBERTa Emotion\n",
    "        print(f\"\\n2Ô∏è‚É£ RoBERTa Emotion (Seed {seed})\")\n",
    "        model, encoder = train_roberta_single_task(\n",
    "            'emotion', best_params['roberta_emotion'], seed,\n",
    "            sentiment_data, emotion_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(f\"./trained_models_seeds/roberta_emotion_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_single_task_model(model, tokenizer, encoder, reddit_data, 'emotion')\n",
    "        seed_results['roberta_emotion'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 3. Train and evaluate DeBERTa Multitask\n",
    "        print(f\"\\n3Ô∏è‚É£ DeBERTa Multitask (Seed {seed})\")\n",
    "        model, sent_enc, emot_enc = train_multitask_model(\n",
    "            \"microsoft/deberta-base\", best_params['deberta_multitask'], seed,\n",
    "            sentiment_data, emotion_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./trained_models_seeds/deberta_multitask_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_multitask_model(\n",
    "            model, tokenizer, sent_enc, emot_enc, reddit_data, \n",
    "            best_params['deberta_multitask']['max_length']\n",
    "        )\n",
    "        seed_results['deberta_multitask'] = results\n",
    "        print(f\"   Sentiment - Accuracy: {results['sentiment']['accuracy']:.4f}, F1: {results['sentiment']['macro_f1']:.4f}\")\n",
    "        print(f\"   Emotion - Accuracy: {results['emotion']['accuracy']:.4f}, F1: {results['emotion']['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 4. Train and evaluate BERTweet Multitask\n",
    "        print(f\"\\n4Ô∏è‚É£ BERTweet Multitask (Seed {seed})\")\n",
    "        model, sent_enc, emot_enc = train_multitask_model(\n",
    "            \"vinai/bertweet-base\", best_params['bertweet_multitask'], seed,\n",
    "            sentiment_data, emotion_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./trained_models_seeds/bertweet_multitask_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_multitask_model(\n",
    "            model, tokenizer, sent_enc, emot_enc, reddit_data,\n",
    "            best_params['bertweet_multitask']['max_length']\n",
    "        )\n",
    "        seed_results['bertweet_multitask'] = results\n",
    "        print(f\"   Sentiment - Accuracy: {results['sentiment']['accuracy']:.4f}, F1: {results['sentiment']['macro_f1']:.4f}\")\n",
    "        print(f\"   Emotion - Accuracy: {results['emotion']['accuracy']:.4f}, F1: {results['emotion']['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        all_results[seed] = seed_results\n",
    "        \n",
    "        print(f\"\\n‚úÖ Completed evaluation for seed {seed}\")\n",
    "    \n",
    "    # Analyze stability across seeds\n",
    "    print(f\"\\nüìä ANALYZING STABILITY ACROSS SEEDS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    stability_analysis = analyze_seed_stability(all_results, seeds)\n",
    "    \n",
    "    # Save results\n",
    "    save_results(all_results, stability_analysis, seeds)\n",
    "    \n",
    "    return all_results, stability_analysis\n",
    "\n",
    "def analyze_seed_stability(all_results: Dict, seeds: List[int]) -> Dict:\n",
    "    \"\"\"Analyze stability of models across different seeds\"\"\"\n",
    "    \n",
    "    stability_stats = {}\n",
    "    \n",
    "    # Define model-task combinations\n",
    "    evaluations = [\n",
    "        ('roberta_sentiment', 'sentiment'),\n",
    "        ('roberta_emotion', 'emotion'),\n",
    "        ('deberta_multitask', 'sentiment'),\n",
    "        ('deberta_multitask', 'emotion'),\n",
    "        ('bertweet_multitask', 'sentiment'),\n",
    "        ('bertweet_multitask', 'emotion')\n",
    "    ]\n",
    "    \n",
    "    for model_name, task in evaluations:\n",
    "        print(f\"\\nüîç {model_name.upper()} - {task.upper()}\")\n",
    "        \n",
    "        accuracies = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        for seed in seeds:\n",
    "            if model_name in all_results[seed]:\n",
    "                result = all_results[seed][model_name]\n",
    "                \n",
    "                if model_name.endswith('_multitask'):\n",
    "                    acc = result[task]['accuracy']\n",
    "                    f1 = result[task]['macro_f1']\n",
    "                else:\n",
    "                    acc = result['accuracy']\n",
    "                    f1 = result['macro_f1']\n",
    "                \n",
    "                accuracies.append(acc)\n",
    "                f1_scores.append(f1)\n",
    "        \n",
    "        if accuracies:\n",
    "            acc_mean = np.mean(accuracies)\n",
    "            acc_std = np.std(accuracies)\n",
    "            f1_mean = np.mean(f1_scores)\n",
    "            f1_std = np.std(f1_scores)\n",
    "            \n",
    "            stability_stats[f\"{model_name}_{task}\"] = {\n",
    "                'accuracy_mean': acc_mean,\n",
    "                'accuracy_std': acc_std,\n",
    "                'f1_mean': f1_mean,\n",
    "                'f1_std': f1_std,\n",
    "                'accuracy_values': accuracies,\n",
    "                'f1_values': f1_scores\n",
    "            }\n",
    "            \n",
    "            print(f\"   Accuracy: {acc_mean:.4f} ¬± {acc_std:.4f}\")\n",
    "            print(f\"   Macro F1: {f1_mean:.4f} ¬± {f1_std:.4f}\")\n",
    "    \n",
    "    return stability_stats\n",
    "\n",
    "def save_results(all_results: Dict, stability_analysis: Dict, seeds: List[int]):\n",
    "    \"\"\"Save results to files\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save raw results\n",
    "    results_file = f\"./random_seed_analysis_results/raw_results_{timestamp}.json\"\n",
    "    with open(results_file, 'w') as f:\n",
    "        # Convert numpy types to Python types for JSON serialization\n",
    "        serializable_results = {}\n",
    "        for seed, seed_results in all_results.items():\n",
    "            serializable_results[str(seed)] = {}\n",
    "            for model, results in seed_results.items():\n",
    "                if isinstance(results, dict):\n",
    "                    serializable_results[str(seed)][model] = {}\n",
    "                    for key, value in results.items():\n",
    "                        if isinstance(value, dict):\n",
    "                            serializable_results[str(seed)][model][key] = {\n",
    "                                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                                   [float(x) if isinstance(x, (np.floating, np.integer)) else x for x in v] if isinstance(v, list) else v\n",
    "                                for k, v in value.items()\n",
    "                            }\n",
    "                        else:\n",
    "                            serializable_results[str(seed)][model][key] = float(value) if isinstance(value, (np.floating, np.integer)) else value\n",
    "        \n",
    "        json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    # Save stability analysis\n",
    "    stability_file = f\"./random_seed_analysis_results/stability_analysis_{timestamp}.json\"\n",
    "    with open(stability_file, 'w') as f:\n",
    "        serializable_stability = {}\n",
    "        for key, stats in stability_analysis.items():\n",
    "            serializable_stability[key] = {\n",
    "                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                   [float(x) for x in v] if isinstance(v, list) else v\n",
    "                for k, v in stats.items()\n",
    "            }\n",
    "        json.dump(serializable_stability, f, indent=2)\n",
    "    \n",
    "    # Create summary report\n",
    "    summary_file = f\"./random_seed_analysis_results/summary_report_{timestamp}.txt\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"RANDOM SEED ANALYSIS SUMMARY REPORT\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        f.write(f\"Seeds tested: {seeds}\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"STABILITY ANALYSIS (Mean ¬± Std)\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        for key, stats in stability_analysis.items():\n",
    "            model_task = key.replace('_', ' ').title()\n",
    "            f.write(f\"\\n{model_task}:\\n\")\n",
    "            f.write(f\"  Accuracy: {stats['accuracy_mean']:.4f} ¬± {stats['accuracy_std']:.4f}\\n\")\n",
    "            f.write(f\"  Macro F1: {stats['f1_mean']:.4f} ¬± {stats['f1_std']:.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest Performers (by mean F1 score):\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        \n",
    "        # Find best performers\n",
    "        sentiment_best = max([k for k in stability_analysis.keys() if 'sentiment' in k], \n",
    "                           key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        emotion_best = max([k for k in stability_analysis.keys() if 'emotion' in k], \n",
    "                         key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        \n",
    "        f.write(f\"Sentiment: {sentiment_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[sentiment_best]['f1_mean']:.4f})\\n\")\n",
    "        f.write(f\"Emotion: {emotion_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[emotion_best]['f1_mean']:.4f})\\n\")\n",
    "    \n",
    "    print(f\"\\nüíæ Results saved:\")\n",
    "    print(f\"   Raw results: {results_file}\")\n",
    "    print(f\"   Stability analysis: {stability_file}\")\n",
    "    print(f\"   Summary report: {summary_file}\")\n",
    "\n",
    "print(\"‚úÖ Random seed analysis function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ecf20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Run the Analysis\n",
    "if __name__ == \"__main__\":\n",
    "    # Run random seed analysis\n",
    "    all_results, stability_analysis = run_random_seed_analysis(\n",
    "        reddit_data_path=\"annotated_reddit_posts.csv\",\n",
    "        seeds=[42, 123, 456, 789, 999],  # 5 different seeds\n",
    "        max_training_samples=5000  # Adjust based on your compute resources\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéâ RANDOM SEED ANALYSIS COMPLETED!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Check the './random_seed_analysis_results/' directory for detailed results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
