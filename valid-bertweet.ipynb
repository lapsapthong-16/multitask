{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ebee31",
   "metadata": {},
   "source": [
    "# General Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5dbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "‚úÖ Libraries imported and setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, AutoConfig,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import random\n",
    "from collections import Counter\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"./bertweet_seed_analysis_results\", exist_ok=True)\n",
    "os.makedirs(\"./bertweet_trained_models_seeds\", exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "print(\"‚úÖ Libraries imported and setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95fc10fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "def set_random_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def clear_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def print_memory_usage():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f} GB, Cached: {cached:.2f} GB\")\n",
    "\n",
    "print(\"Utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee15564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet model architectures defined\n"
     ]
    }
   ],
   "source": [
    "class BERTweetSingleTaskTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"vinai/bertweet-base\",\n",
    "        num_classes: int = 3,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load BERTweet model\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        self.bertweet = AutoModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        # Classification head\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(self.bertweet.config.hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERTweet outputs\n",
    "        outputs = self.bertweet(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return {'logits': logits}\n",
    "\n",
    "class BERTweetMultiTaskTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"vinai/bertweet-base\",\n",
    "        sentiment_num_classes: int = 3,\n",
    "        emotion_num_classes: int = 6,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sentiment_num_classes = sentiment_num_classes\n",
    "        self.emotion_num_classes = emotion_num_classes\n",
    "        \n",
    "        # Load BERTweet model\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        self.bertweet = AutoModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        hidden_size = self.bertweet.config.hidden_size\n",
    "        \n",
    "        # Task-specific attention layers\n",
    "        self.sentiment_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.emotion_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Shared attention for common features\n",
    "        self.shared_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.sentiment_norm = nn.LayerNorm(hidden_size)\n",
    "        self.emotion_norm = nn.LayerNorm(hidden_size)\n",
    "        self.shared_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.sentiment_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.emotion_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.shared_dropout = nn.Dropout(classifier_dropout)\n",
    "        \n",
    "        # Classification heads\n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, sentiment_num_classes)\n",
    "        )\n",
    "        \n",
    "        self.emotion_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, emotion_num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in [self.sentiment_classifier, self.emotion_classifier]:\n",
    "            for layer in module:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        # Shared encoder\n",
    "        encoder_outputs = self.bertweet(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        sequence_output = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply shared attention\n",
    "        shared_attended, _ = self.shared_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        shared_attended = self.shared_norm(shared_attended + sequence_output)\n",
    "        shared_attended = self.shared_dropout(shared_attended)\n",
    "        shared_pooled = shared_attended[:, 0, :]\n",
    "        \n",
    "        outputs = {}\n",
    "        \n",
    "        # Sentiment branch\n",
    "        sentiment_attended, _ = self.sentiment_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        sentiment_attended = self.sentiment_norm(sentiment_attended + sequence_output)\n",
    "        sentiment_attended = self.sentiment_dropout(sentiment_attended)\n",
    "        sentiment_pooled = sentiment_attended[:, 0, :]\n",
    "        sentiment_features = torch.cat([shared_pooled, sentiment_pooled], dim=-1)\n",
    "        sentiment_logits = self.sentiment_classifier(sentiment_features)\n",
    "        outputs[\"sentiment_logits\"] = sentiment_logits\n",
    "        \n",
    "        # Emotion branch\n",
    "        emotion_attended, _ = self.emotion_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        emotion_attended = self.emotion_norm(emotion_attended + sequence_output)\n",
    "        emotion_attended = self.emotion_dropout(emotion_attended)\n",
    "        emotion_pooled = emotion_attended[:, 0, :]\n",
    "        emotion_features = torch.cat([shared_pooled, emotion_pooled], dim=-1)\n",
    "        emotion_logits = self.emotion_classifier(emotion_features)\n",
    "        outputs[\"emotion_logits\"] = emotion_logits\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "print(\"BERTweet model architectures defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84190c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet dataset classes defined\n"
     ]
    }
   ],
   "source": [
    "class BERTweetDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer, max_length: int = 128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class BERTweetMultiTaskDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], sentiment_labels: List[int], \n",
    "                 emotion_labels: List[int], tokenizer, max_length: int = 128):\n",
    "        self.texts = texts\n",
    "        self.sentiment_labels = sentiment_labels\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        sentiment_label = self.sentiment_labels[idx]\n",
    "        emotion_label = self.emotion_labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'sentiment_labels': torch.tensor(sentiment_label, dtype=torch.long),\n",
    "            'emotion_labels': torch.tensor(emotion_label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"BERTweet dataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feded95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modified data loading functions defined!\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, Dict\n",
    "\n",
    "def load_external_datasets() -> Tuple[Dict, Dict]:\n",
    "    print(\"Loading external datasets...\")\n",
    "    \n",
    "    # Load SST-2 for sentiment\n",
    "    try:\n",
    "        sst2_dataset = load_dataset(\"sst2\")\n",
    "        sentiment_data = {\n",
    "            'train': sst2_dataset['train'],\n",
    "            'validation': sst2_dataset['validation']\n",
    "        }\n",
    "        print(f\"‚úÖ SST-2 dataset loaded: {len(sentiment_data['train'])} train, {len(sentiment_data['validation'])} validation samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not load SST-2: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Load GoEmotions for emotion\n",
    "    try:\n",
    "        emotions_dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "        emotion_data = {\n",
    "            'train': emotions_dataset['train'],\n",
    "            'validation': emotions_dataset['validation'],\n",
    "            'test': emotions_dataset['test']  # GoEmotions has a test split\n",
    "        }\n",
    "        print(f\"‚úÖ GoEmotions dataset loaded: {len(emotion_data['train'])} train, {len(emotion_data['validation'])} validation, {len(emotion_data['test'])} test samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not load GoEmotions: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return sentiment_data, emotion_data\n",
    "\n",
    "def prepare_sst2_evaluation_data(sentiment_data: Dict, max_samples: int = 1000) -> Dict:\n",
    "    print(\"Preparing SST-2 evaluation data...\")\n",
    "    \n",
    "    eval_texts = sentiment_data['validation']['sentence'][:max_samples]\n",
    "    eval_labels_raw = sentiment_data['validation']['label'][:max_samples]\n",
    "    \n",
    "    # Convert SST-2 binary to 3-class sentiment (same as training)\n",
    "    eval_labels = []\n",
    "    for label in eval_labels_raw:\n",
    "        if label == 0:  # Negative\n",
    "            eval_labels.append(0)\n",
    "        elif label == 1:  # Positive\n",
    "            if np.random.random() < 0.15:  \n",
    "                eval_labels.append(1)  # Neutral\n",
    "            else:\n",
    "                eval_labels.append(2)  # Positive\n",
    "    \n",
    "    # Create encoder that matches training\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    sentiment_encoder.classes_ = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "    \n",
    "    sst2_eval_data = {\n",
    "        'texts': eval_texts,\n",
    "        'sentiment_labels': eval_labels,\n",
    "        'sentiment_encoder': sentiment_encoder\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ SST-2 evaluation data prepared: {len(sst2_eval_data['texts'])} samples\")\n",
    "    print(f\"   Sentiment classes: {list(sentiment_encoder.classes_)}\")\n",
    "    \n",
    "    return sst2_eval_data\n",
    "\n",
    "def prepare_goemotions_evaluation_data(emotion_data: Dict, max_samples: int = 1000) -> Dict:\n",
    "    print(\"Preparing GoEmotions evaluation data...\")\n",
    "    \n",
    "    eval_split = emotion_data.get('test', emotion_data.get('validation'))\n",
    "    eval_texts_all = eval_split['text']\n",
    "    eval_labels_all = eval_split['labels']\n",
    "    \n",
    "    eval_texts = []\n",
    "    eval_labels = []\n",
    "    count = 0\n",
    "    \n",
    "    for i, label in enumerate(eval_labels_all):\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "        if isinstance(label, list):\n",
    "            if label and label[0] in range(6):\n",
    "                eval_texts.append(eval_texts_all[i])\n",
    "                eval_labels.append(label[0])\n",
    "                count += 1\n",
    "        else:\n",
    "            if label in range(6):\n",
    "                eval_texts.append(eval_texts_all[i])\n",
    "                eval_labels.append(label)\n",
    "                count += 1\n",
    "    \n",
    "    # Create encoder that matches training\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    emotion_encoder.classes_ = np.array(['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise'])\n",
    "    \n",
    "    goemotions_eval_data = {\n",
    "        'texts': eval_texts,\n",
    "        'emotion_labels': eval_labels,\n",
    "        'emotion_encoder': emotion_encoder\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ GoEmotions evaluation data prepared: {len(goemotions_eval_data['texts'])} samples\")\n",
    "    print(f\"   Emotion classes: {list(emotion_encoder.classes_)}\")\n",
    "    \n",
    "    return goemotions_eval_data\n",
    "\n",
    "def prepare_multitask_evaluation_data(sst2_eval_data: Dict, goemotions_eval_data: Dict) -> Dict:\n",
    "    print(\"Preparing multitask evaluation data...\")\n",
    "    \n",
    "    # Take minimum length to ensure both tasks have same number of samples\n",
    "    min_length = min(len(sst2_eval_data['texts']), len(goemotions_eval_data['texts']))\n",
    "    \n",
    "    multitask_eval_data = {\n",
    "        'texts': sst2_eval_data['texts'][:min_length],\n",
    "        'sentiment_labels': sst2_eval_data['sentiment_labels'][:min_length],\n",
    "        'emotion_labels': goemotions_eval_data['emotion_labels'][:min_length],\n",
    "        'sentiment_encoder': sst2_eval_data['sentiment_encoder'],\n",
    "        'emotion_encoder': goemotions_eval_data['emotion_encoder']\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Multitask evaluation data prepared: {len(multitask_eval_data['texts'])} samples\")\n",
    "    \n",
    "    return multitask_eval_data\n",
    "\n",
    "def prepare_bertweet_training_data(sentiment_data: Dict, emotion_data: Dict, max_samples: int = 3000) -> Dict:\n",
    "    print(\"Preparing BERTweet training data...\")\n",
    "    \n",
    "    # Process sentiment data (SST-2)\n",
    "    sentiment_texts = sentiment_data['train']['sentence'][:max_samples]\n",
    "    sentiment_labels = sentiment_data['train']['label'][:max_samples]\n",
    "    \n",
    "    # Process emotion data (filter to first 6 classes)\n",
    "    emotion_texts = []\n",
    "    emotion_labels = []\n",
    "    count = 0\n",
    "    \n",
    "    for i, label in enumerate(emotion_data['train']['labels']):\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "        if isinstance(label, list):\n",
    "            if label and label[0] in range(6):  # Only use first 6 emotions\n",
    "                emotion_texts.append(emotion_data['train']['text'][i])\n",
    "                emotion_labels.append(label[0])\n",
    "                count += 1\n",
    "        else:\n",
    "            if label in range(6):\n",
    "                emotion_texts.append(emotion_data['train']['text'][i])\n",
    "                emotion_labels.append(label)\n",
    "                count += 1\n",
    "    \n",
    "    # Create encoders\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    \n",
    "    # For SST-2: 0 = Negative, 1 = Positive\n",
    "    sentiment_encoder.classes_ = np.array(['Negative', 'Positive'])\n",
    "    \n",
    "    # For GoEmotions: First 6 emotions\n",
    "    emotion_encoder.classes_ = np.array(['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise'])\n",
    "    \n",
    "    training_data = {\n",
    "        'sentiment_data': {\n",
    "            'texts': sentiment_texts,\n",
    "            'labels': sentiment_labels,\n",
    "            'encoder': sentiment_encoder\n",
    "        },\n",
    "        'emotion_data': {\n",
    "            'texts': emotion_texts,\n",
    "            'labels': emotion_labels,\n",
    "            'encoder': emotion_encoder\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Training data prepared:\")\n",
    "    print(f\"   Sentiment: {len(sentiment_texts)} samples\")\n",
    "    print(f\"   Sentiment classes: {list(sentiment_encoder.classes_)}\")\n",
    "    print(f\"   Emotion: {len(emotion_texts)} samples\")\n",
    "    print(f\"   Emotion classes: {list(emotion_encoder.classes_)}\")\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "print(\"‚úÖ Modified data loading functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82afd1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet training functions defined\n"
     ]
    }
   ],
   "source": [
    "def train_bertweet_single_task(\n",
    "    task_type: str,  \n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    training_data: Dict,\n",
    "    max_samples: int = 5000\n",
    ") -> Tuple[any, LabelEncoder]:\n",
    "    \n",
    "    print(f\"üöÄ Training BERTweet {task_type} model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Get appropriate data\n",
    "    if task_type == 'sentiment':\n",
    "        texts = training_data['sentiment_data']['texts'][:max_samples]\n",
    "        labels = training_data['sentiment_data']['labels'][:max_samples]\n",
    "        encoder = training_data['sentiment_data']['encoder']\n",
    "        num_classes = 3\n",
    "    else:  # emotion\n",
    "        texts = training_data['emotion_data']['texts'][:max_samples]\n",
    "        labels = training_data['emotion_data']['labels'][:max_samples]\n",
    "        encoder = training_data['emotion_data']['encoder']\n",
    "        num_classes = 6\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model\n",
    "    model = BERTweetSingleTaskTransformer(\n",
    "        model_name='vinai/bertweet-base',\n",
    "        num_classes=num_classes,\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        attention_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = BERTweetDataset(texts, labels, tokenizer, max_length=128)\n",
    "    dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    total_steps = len(dataloader) * 3  # 3 epochs\n",
    "    warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    print(f\"Starting training for 3 epochs...\")\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels_batch = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs['logits'], labels_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/3, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    output_dir = f\"./bertweet_trained_models_seeds/bertweet_{task_type}_seed_{seed}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model state dict\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "    \n",
    "    # Save config\n",
    "    config = {\n",
    "        \"model_name\": \"vinai/bertweet-base\",\n",
    "        \"num_classes\": num_classes,\n",
    "        \"task_type\": task_type,\n",
    "        \"model_type\": \"BERTweetSingleTaskTransformer\"\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"config.json\"), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save tokenizer and encoder\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(encoder, os.path.join(output_dir, f'{task_type}_encoder.pkl'))\n",
    "    \n",
    "    print(f\"‚úÖ BERTweet {task_type} model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, encoder\n",
    "\n",
    "def train_bertweet_multitask(\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    training_data: Dict,\n",
    "    max_samples: int = 2000\n",
    ") -> Tuple[any, LabelEncoder, LabelEncoder]:\n",
    "    \n",
    "    print(f\"üöÄ Training BERTweet multitask model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    min_length = min(len(training_data['sentiment_data']['texts']), \n",
    "                     len(training_data['emotion_data']['texts']))\n",
    "    min_length = min(min_length, max_samples)\n",
    "    \n",
    "    combined_texts = training_data['sentiment_data']['texts'][:min_length]\n",
    "    combined_sentiment_labels = training_data['sentiment_data']['labels'][:min_length]\n",
    "    combined_emotion_labels = training_data['emotion_data']['labels'][:min_length]\n",
    "    \n",
    "    sentiment_encoder = training_data['sentiment_data']['encoder']\n",
    "    emotion_encoder = training_data['emotion_data']['encoder']\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model\n",
    "    model = BERTweetMultiTaskTransformer(\n",
    "        model_name='vinai/bertweet-base',\n",
    "        sentiment_num_classes=3,\n",
    "        emotion_num_classes=6,\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        attention_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = BERTweetMultiTaskDataset(\n",
    "        combined_texts, combined_sentiment_labels, combined_emotion_labels, \n",
    "        tokenizer, max_length=128\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    total_steps = len(dataloader) * 3  # 3 epochs\n",
    "    warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Loss functions\n",
    "    sentiment_criterion = nn.CrossEntropyLoss()\n",
    "    emotion_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    alpha = best_params['alpha']\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    print(f\"Starting training for 3 epochs...\")\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            sentiment_labels = batch['sentiment_labels'].to(device)\n",
    "            emotion_labels = batch['emotion_labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Calculate losses\n",
    "            sentiment_loss = sentiment_criterion(outputs['sentiment_logits'], sentiment_labels)\n",
    "            emotion_loss = emotion_criterion(outputs['emotion_logits'], emotion_labels)\n",
    "            \n",
    "            # Combined loss\n",
    "            total_loss_batch = alpha * sentiment_loss + (1 - alpha) * emotion_loss\n",
    "            total_loss += total_loss_batch.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/3, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    output_dir = f\"./bertweet_trained_models_seeds/bertweet_multitask_seed_{seed}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model state dict\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "    \n",
    "    # Save config\n",
    "    config = {\n",
    "        \"model_name\": \"vinai/bertweet-base\",\n",
    "        \"sentiment_num_classes\": 3,\n",
    "        \"emotion_num_classes\": 6,\n",
    "        \"model_type\": \"BERTweetMultiTaskTransformer\"\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"config.json\"), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save tokenizer and encoders\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(sentiment_encoder, os.path.join(output_dir, 'sentiment_encoder.pkl'))\n",
    "    joblib.dump(emotion_encoder, os.path.join(output_dir, 'emotion_encoder.pkl'))\n",
    "    \n",
    "    print(f\"BERTweet multitask model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, sentiment_encoder, emotion_encoder\n",
    "\n",
    "print(\"BERTweet training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d9d59bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def evaluate_bertweet_single_task(model, tokenizer, label_encoder, reddit_data: Dict, task_type: str) -> Dict:\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_labels = reddit_data[f'{task_type}_labels']\n",
    "    \n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 16):  # Batch size 16\n",
    "            batch_texts = texts[i:i+16]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=128\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items() if k in ['input_ids', 'attention_mask']}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs['logits']\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                pred_id = preds[j].item()\n",
    "                confidence = probs[j][pred_id].item()\n",
    "                \n",
    "                # Handle out of range predictions\n",
    "                if pred_id >= len(label_encoder.classes_):\n",
    "                    pred_id = 0\n",
    "                \n",
    "                predictions.append(pred_id)\n",
    "                confidences.append(confidence)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    macro_f1 = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'predictions': predictions,\n",
    "        'confidences': confidences,\n",
    "        'true_labels': true_labels\n",
    "    }\n",
    "\n",
    "def evaluate_bertweet_multitask(model, tokenizer, sentiment_encoder, emotion_encoder, \n",
    "                               reddit_data: Dict, max_length: int = 128) -> Dict:\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_sentiment_labels = reddit_data['sentiment_labels']\n",
    "    true_emotion_labels = reddit_data['emotion_labels']\n",
    "    \n",
    "    sentiment_predictions = []\n",
    "    emotion_predictions = []\n",
    "    sentiment_confidences = []\n",
    "    emotion_confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 8):  # Smaller batch size for multitask\n",
    "            batch_texts = texts[i:i+8]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=max_length\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items() if k in ['input_ids', 'attention_mask']}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            # Process sentiment\n",
    "            sentiment_logits = outputs['sentiment_logits']\n",
    "            sentiment_probs = F.softmax(sentiment_logits, dim=-1)\n",
    "            sentiment_preds = torch.argmax(sentiment_logits, dim=-1)\n",
    "            \n",
    "            # Process emotion\n",
    "            emotion_logits = outputs['emotion_logits']\n",
    "            emotion_probs = F.softmax(emotion_logits, dim=-1)\n",
    "            emotion_preds = torch.argmax(emotion_logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                # Sentiment\n",
    "                sent_id = sentiment_preds[j].item()\n",
    "                sent_conf = sentiment_probs[j][sent_id].item()\n",
    "                if sent_id >= len(sentiment_encoder.classes_):\n",
    "                    sent_id = 0\n",
    "                sentiment_predictions.append(sent_id)\n",
    "                sentiment_confidences.append(sent_conf)\n",
    "                \n",
    "                # Emotion\n",
    "                emot_id = emotion_preds[j].item()\n",
    "                emot_conf = emotion_probs[j][emot_id].item()\n",
    "                if emot_id >= len(emotion_encoder.classes_):\n",
    "                    emot_id = 0\n",
    "                emotion_predictions.append(emot_id)\n",
    "                emotion_confidences.append(emot_conf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    sentiment_accuracy = accuracy_score(true_sentiment_labels, sentiment_predictions)\n",
    "    sentiment_f1 = f1_score(true_sentiment_labels, sentiment_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    emotion_accuracy = accuracy_score(true_emotion_labels, emotion_predictions)\n",
    "    emotion_f1 = f1_score(true_emotion_labels, emotion_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'sentiment': {\n",
    "            'accuracy': sentiment_accuracy,\n",
    "            'macro_f1': sentiment_f1,\n",
    "            'predictions': sentiment_predictions,\n",
    "            'confidences': sentiment_confidences\n",
    "        },\n",
    "        'emotion': {\n",
    "            'accuracy': emotion_accuracy,\n",
    "            'macro_f1': emotion_f1,\n",
    "            'predictions': emotion_predictions,\n",
    "            'confidences': emotion_confidences\n",
    "        },\n",
    "        'combined_accuracy': (sentiment_accuracy + emotion_accuracy) / 2,\n",
    "        'combined_f1': (sentiment_f1 + emotion_f1) / 2\n",
    "    }\n",
    "\n",
    "print(\"BERTweet evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bertweet_seed_stability(all_results: Dict, seeds: List[int]) -> Dict:\n",
    "    \n",
    "    stability_stats = {}\n",
    "    \n",
    "    # Define model-task combinations\n",
    "    evaluations = [\n",
    "        ('bertweet_sentiment', 'sentiment'),\n",
    "        ('bertweet_emotion', 'emotion'),\n",
    "        ('bertweet_multitask', 'sentiment'),\n",
    "        ('bertweet_multitask', 'emotion')\n",
    "    ]\n",
    "    \n",
    "    for model_name, task in evaluations:\n",
    "        print(f\"\\nüîç {model_name.upper()} - {task.upper()}\")\n",
    "        \n",
    "        accuracies = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        for seed in seeds:\n",
    "            if model_name in all_results[seed]:\n",
    "                result = all_results[seed][model_name]\n",
    "                \n",
    "                if model_name.endswith('_multitask'):\n",
    "                    acc = result[task]['accuracy']\n",
    "                    f1 = result[task]['macro_f1']\n",
    "                else:\n",
    "                    acc = result['accuracy']\n",
    "                    f1 = result['macro_f1']\n",
    "                \n",
    "                accuracies.append(acc)\n",
    "                f1_scores.append(f1)\n",
    "        \n",
    "        if accuracies:\n",
    "            acc_mean = np.mean(accuracies)\n",
    "            acc_std = np.std(accuracies)\n",
    "            f1_mean = np.mean(f1_scores)\n",
    "            f1_std = np.std(f1_scores)\n",
    "            \n",
    "            stability_stats[f\"{model_name}_{task}\"] = {\n",
    "                'accuracy_mean': acc_mean,\n",
    "                'accuracy_std': acc_std,\n",
    "                'f1_mean': f1_mean,\n",
    "                'f1_std': f1_std,\n",
    "                'accuracy_values': accuracies,\n",
    "                'f1_values': f1_scores\n",
    "            }\n",
    "            \n",
    "            print(f\"   Accuracy: {acc_mean:.4f} ¬± {acc_std:.4f}\")\n",
    "            print(f\"   Macro F1: {f1_mean:.4f} ¬± {f1_std:.4f}\")\n",
    "    \n",
    "    return stability_stats\n",
    "\n",
    "def save_bertweet_results(all_results: Dict, stability_analysis: Dict, seeds: List[int]):\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save raw results\n",
    "    results_file = f\"./bertweet_seed_analysis_results/bertweet_raw_results_{timestamp}.json\"\n",
    "    with open(results_file, 'w') as f:\n",
    "        # Convert numpy types to Python types for JSON serialization\n",
    "        serializable_results = {}\n",
    "        for seed, seed_results in all_results.items():\n",
    "            serializable_results[str(seed)] = {}\n",
    "            for model, results in seed_results.items():\n",
    "                if isinstance(results, dict):\n",
    "                    serializable_results[str(seed)][model] = {}\n",
    "                    for key, value in results.items():\n",
    "                        if isinstance(value, dict):\n",
    "                            serializable_results[str(seed)][model][key] = {\n",
    "                                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                                   [float(x) if isinstance(x, (np.floating, np.integer)) else x for x in v] if isinstance(v, list) else v\n",
    "                                for k, v in value.items()\n",
    "                            }\n",
    "                        else:\n",
    "                            serializable_results[str(seed)][model][key] = float(value) if isinstance(value, (np.floating, np.integer)) else value\n",
    "        \n",
    "        json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    # Save stability analysis\n",
    "    stability_file = f\"./bertweet_seed_analysis_results/bertweet_stability_analysis_{timestamp}.json\"\n",
    "    with open(stability_file, 'w') as f:\n",
    "        serializable_stability = {}\n",
    "        for key, stats in stability_analysis.items():\n",
    "            serializable_stability[key] = {\n",
    "                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                   [float(x) for x in v] if isinstance(v, list) else v\n",
    "                for k, v in stats.items()\n",
    "            }\n",
    "        json.dump(serializable_stability, f, indent=2)\n",
    "    \n",
    "    # Create summary report\n",
    "    summary_file = f\"./bertweet_seed_analysis_results/bertweet_summary_report_{timestamp}.txt\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"BERTWEET RANDOM SEED ANALYSIS SUMMARY REPORT\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        f.write(f\"Seeds tested: {seeds}\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"STABILITY ANALYSIS (Mean ¬± Std)\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        for key, stats in stability_analysis.items():\n",
    "            model_task = key.replace('_', ' ').title()\n",
    "            f.write(f\"\\n{model_task}:\\n\")\n",
    "            f.write(f\"  Accuracy: {stats['accuracy_mean']:.4f} ¬± {stats['accuracy_std']:.4f}\\n\")\n",
    "            f.write(f\"  Macro F1: {stats['f1_mean']:.4f} ¬± {stats['f1_std']:.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest Performers (by mean F1 score):\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        \n",
    "        # Find best performers\n",
    "        sentiment_best = max([k for k in stability_analysis.keys() if 'sentiment' in k], \n",
    "                           key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        emotion_best = max([k for k in stability_analysis.keys() if 'emotion' in k], \n",
    "                         key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        \n",
    "        f.write(f\"Sentiment: {sentiment_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[sentiment_best]['f1_mean']:.4f})\\n\")\n",
    "        f.write(f\"Emotion: {emotion_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[emotion_best]['f1_mean']:.4f})\\n\")\n",
    "    \n",
    "    print(f\"\\nüíæ BERTweet results saved:\")\n",
    "    print(f\"   Raw results: {results_file}\")\n",
    "    print(f\"   Stability analysis: {stability_file}\")\n",
    "    print(f\"   Summary report: {summary_file}\")\n",
    "\n",
    "print(\"BERTweet stability analysis functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1097d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modified BERTweet random seed analysis function defined!\n"
     ]
    }
   ],
   "source": [
    "def run_bertweet_seed_analysis(\n",
    "    seeds: List[int] = [42, 123, 456, 789, 999],\n",
    "    max_training_samples: int = 3000,\n",
    "    max_eval_samples: int = 1000\n",
    "):\n",
    "    \n",
    "    print(\"üé≤ STARTING BERTWEET RANDOM SEED ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Seeds to test: {seeds}\")\n",
    "    print(f\"Max training samples per dataset: {max_training_samples}\")\n",
    "    print(f\"Max evaluation samples per dataset: {max_eval_samples}\")\n",
    "    \n",
    "    # Load external datasets\n",
    "    print(\"\\nüìÇ Loading external datasets...\")\n",
    "    sentiment_data, emotion_data = load_external_datasets()\n",
    "    \n",
    "    # Prepare training data\n",
    "    print(\"\\nüîÑ Preparing BERTweet training data...\")\n",
    "    training_data = prepare_bertweet_training_data(sentiment_data, emotion_data, max_training_samples)\n",
    "    \n",
    "    # Prepare evaluation data\n",
    "    print(\"\\nüìÇ Preparing evaluation datasets...\")\n",
    "    sst2_eval_data = prepare_sst2_evaluation_data(sentiment_data, max_eval_samples)\n",
    "    goemotions_eval_data = prepare_goemotions_evaluation_data(emotion_data, max_eval_samples)\n",
    "    multitask_eval_data = prepare_multitask_evaluation_data(sst2_eval_data, goemotions_eval_data)\n",
    "    \n",
    "    # Define best parameters for each BERTweet model\n",
    "    best_params = {\n",
    "        'sentiment': {\n",
    "            'learning_rate': 3.65445235521325e-05,\n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.15986584841970367,\n",
    "            'weight_decay': 0.02404167763981929,\n",
    "            'hidden_dropout_prob': 0.13119890406724052,\n",
    "            'classifier_dropout': 0.1116167224336399\n",
    "        },\n",
    "        'emotion': {\n",
    "            'learning_rate': 2.503410215228042e-05, \n",
    "            'batch_size': 32,\n",
    "            'warmup_ratio': 0.1456069984217036,\n",
    "            'weight_decay': 0.08066583652537122,\n",
    "            'hidden_dropout_prob': 0.13993475643167194,\n",
    "            'classifier_dropout': 0.2028468876827223\n",
    "        },\n",
    "        'multitask': {\n",
    "            'learning_rate': 2.2207471217033647e-05,\n",
    "            'batch_size': 32,\n",
    "            'warmup_ratio': 0.1808397348116461,\n",
    "            'weight_decay': 0.037415239225603365,\n",
    "            'hidden_dropout_prob': 0.11953442280127678,\n",
    "            'classifier_dropout': 0.23684660530243137,\n",
    "            'alpha': 0.48803049874792026\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    # Store results for each seed\n",
    "    all_results = {}\n",
    "    \n",
    "    for seed in seeds:\n",
    "        print(f\"\\nüå± TRAINING AND EVALUATING BERTWEET WITH SEED {seed}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        seed_results = {}\n",
    "        \n",
    "        # 1. Train and evaluate BERTweet Sentiment on SST-2\n",
    "        print(f\"\\n1Ô∏è‚É£ BERTweet Sentiment on SST-2 (Seed {seed})\")\n",
    "        model, encoder = train_bertweet_single_task(\n",
    "            'sentiment', best_params['sentiment'], seed, \n",
    "            training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_sentiment_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate on SST-2 validation set\n",
    "        results = evaluate_bertweet_single_task(model, tokenizer, encoder, sst2_eval_data, 'sentiment')\n",
    "        seed_results['bertweet_sentiment'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 2. Train and evaluate BERTweet Emotion on GoEmotions\n",
    "        print(f\"\\n2Ô∏è‚É£ BERTweet Emotion on GoEmotions (Seed {seed})\")\n",
    "        model, encoder = train_bertweet_single_task(\n",
    "            'emotion', best_params['emotion'], seed,\n",
    "            training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_emotion_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate on GoEmotions test set\n",
    "        results = evaluate_bertweet_single_task(model, tokenizer, encoder, goemotions_eval_data, 'emotion')\n",
    "        seed_results['bertweet_emotion'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 3. Train and evaluate BERTweet Multitask on both datasets\n",
    "        print(f\"\\n3Ô∏è‚É£ BERTweet Multitask on SST-2 + GoEmotions (Seed {seed})\")\n",
    "        model, sent_enc, emot_enc = train_bertweet_multitask(\n",
    "            best_params['multitask'], seed, training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_multitask_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate on combined test sets\n",
    "        results = evaluate_bertweet_multitask(\n",
    "            model, tokenizer, sent_enc, emot_enc, multitask_eval_data, 128\n",
    "        )\n",
    "        seed_results['bertweet_multitask'] = results\n",
    "        print(f\"   Sentiment - Accuracy: {results['sentiment']['accuracy']:.4f}, F1: {results['sentiment']['macro_f1']:.4f}\")\n",
    "        print(f\"   Emotion - Accuracy: {results['emotion']['accuracy']:.4f}, F1: {results['emotion']['macro_f1']:.4f}\")\n",
    "        print(f\"   Combined - Accuracy: {results['combined_accuracy']:.4f}, F1: {results['combined_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        all_results[seed] = seed_results\n",
    "        \n",
    "        print(f\"\\n‚úÖ Completed evaluation for seed {seed}\")\n",
    "    \n",
    "    # Analyze stability across seeds\n",
    "    print(f\"\\nüìä ANALYZING BERTWEET STABILITY ACROSS SEEDS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    stability_analysis = analyze_bertweet_seed_stability(all_results, seeds)\n",
    "    \n",
    "    # Save results\n",
    "    save_bertweet_results(all_results, stability_analysis, seeds)\n",
    "    \n",
    "    return all_results, stability_analysis\n",
    "\n",
    "print(\"‚úÖ Modified BERTweet random seed analysis function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1784c2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ STARTING BERTWEET RANDOM SEED ANALYSIS\n",
      "======================================================================\n",
      "Seeds to test: [42, 123, 456, 789, 999]\n",
      "Max training samples per dataset: 3000\n",
      "Max evaluation samples per dataset: 1000\n",
      "\n",
      "üìÇ Loading external datasets...\n",
      "Loading external datasets...\n",
      "‚úÖ SST-2 dataset loaded: 67349 train, 872 validation samples\n",
      "‚úÖ GoEmotions dataset loaded: 43410 train, 5426 validation, 5427 test samples\n",
      "\n",
      "üîÑ Preparing BERTweet training data...\n",
      "Preparing BERTweet training data...\n",
      "‚úÖ Training data prepared:\n",
      "   Sentiment: 3000 samples\n",
      "   Sentiment classes: ['Negative', 'Positive']\n",
      "   Emotion: 3000 samples\n",
      "   Emotion classes: ['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise']\n",
      "\n",
      "üìÇ Preparing evaluation datasets...\n",
      "Preparing SST-2 evaluation data...\n",
      "‚úÖ SST-2 evaluation data prepared: 872 samples\n",
      "   Sentiment classes: ['Negative', 'Neutral', 'Positive']\n",
      "Preparing GoEmotions evaluation data...\n",
      "‚úÖ GoEmotions evaluation data prepared: 1000 samples\n",
      "   Emotion classes: ['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise']\n",
      "Preparing multitask evaluation data...\n",
      "‚úÖ Multitask evaluation data prepared: 872 samples\n",
      "\n",
      "üå± TRAINING AND EVALUATING BERTWEET WITH SEED 42\n",
      "------------------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ BERTweet Sentiment on SST-2 (Seed 42)\n",
      "üöÄ Training BERTweet sentiment model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.5872\n",
      "Epoch 2/3, Average Loss: 0.2380\n",
      "Epoch 3/3, Average Loss: 0.1185\n",
      "‚úÖ BERTweet sentiment model trained and saved with seed 42\n",
      "   Accuracy: 0.5161, Macro F1: 0.3870\n",
      "\n",
      "2Ô∏è‚É£ BERTweet Emotion on GoEmotions (Seed 42)\n",
      "üöÄ Training BERTweet emotion model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.6296\n",
      "Epoch 2/3, Average Loss: 0.9459\n",
      "Epoch 3/3, Average Loss: 0.6962\n",
      "‚úÖ BERTweet emotion model trained and saved with seed 42\n",
      "   Accuracy: 0.7200, Macro F1: 0.6846\n",
      "\n",
      "3Ô∏è‚É£ BERTweet Multitask on SST-2 + GoEmotions (Seed 42)\n",
      "üöÄ Training BERTweet multitask model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5238\n",
      "Epoch 2/3, Average Loss: 1.1787\n",
      "Epoch 3/3, Average Loss: 1.0967\n",
      "BERTweet multitask model trained and saved with seed 42\n",
      "   Sentiment - Accuracy: 0.5149, F1: 0.3838\n",
      "   Emotion - Accuracy: 0.2959, F1: 0.1018\n",
      "   Combined - Accuracy: 0.4054, F1: 0.2428\n",
      "\n",
      "‚úÖ Completed evaluation for seed 42\n",
      "\n",
      "üå± TRAINING AND EVALUATING BERTWEET WITH SEED 123\n",
      "------------------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ BERTweet Sentiment on SST-2 (Seed 123)\n",
      "üöÄ Training BERTweet sentiment model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.6605\n",
      "Epoch 2/3, Average Loss: 0.3059\n",
      "Epoch 3/3, Average Loss: 0.1587\n",
      "‚úÖ BERTweet sentiment model trained and saved with seed 123\n",
      "   Accuracy: 0.5034, Macro F1: 0.3844\n",
      "\n",
      "2Ô∏è‚É£ BERTweet Emotion on GoEmotions (Seed 123)\n",
      "üöÄ Training BERTweet emotion model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.6251\n",
      "Epoch 2/3, Average Loss: 0.9329\n",
      "Epoch 3/3, Average Loss: 0.6839\n",
      "‚úÖ BERTweet emotion model trained and saved with seed 123\n",
      "   Accuracy: 0.7130, Macro F1: 0.6781\n",
      "\n",
      "3Ô∏è‚É£ BERTweet Multitask on SST-2 + GoEmotions (Seed 123)\n",
      "üöÄ Training BERTweet multitask model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5768\n",
      "Epoch 2/3, Average Loss: 1.1922\n",
      "Epoch 3/3, Average Loss: 1.0833\n",
      "BERTweet multitask model trained and saved with seed 123\n",
      "   Sentiment - Accuracy: 0.5092, F1: 0.3838\n",
      "   Emotion - Accuracy: 0.2924, F1: 0.1074\n",
      "   Combined - Accuracy: 0.4008, F1: 0.2456\n",
      "\n",
      "‚úÖ Completed evaluation for seed 123\n",
      "\n",
      "üå± TRAINING AND EVALUATING BERTWEET WITH SEED 456\n",
      "------------------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ BERTweet Sentiment on SST-2 (Seed 456)\n",
      "üöÄ Training BERTweet sentiment model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.6452\n",
      "Epoch 2/3, Average Loss: 0.2622\n",
      "Epoch 3/3, Average Loss: 0.1454\n",
      "‚úÖ BERTweet sentiment model trained and saved with seed 456\n",
      "   Accuracy: 0.5161, Macro F1: 0.3876\n",
      "\n",
      "2Ô∏è‚É£ BERTweet Emotion on GoEmotions (Seed 456)\n",
      "üöÄ Training BERTweet emotion model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.6056\n",
      "Epoch 2/3, Average Loss: 0.9359\n",
      "Epoch 3/3, Average Loss: 0.6983\n",
      "‚úÖ BERTweet emotion model trained and saved with seed 456\n",
      "   Accuracy: 0.7280, Macro F1: 0.6903\n",
      "\n",
      "3Ô∏è‚É£ BERTweet Multitask on SST-2 + GoEmotions (Seed 456)\n",
      "üöÄ Training BERTweet multitask model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5904\n",
      "Epoch 2/3, Average Loss: 1.2239\n",
      "Epoch 3/3, Average Loss: 1.1226\n",
      "BERTweet multitask model trained and saved with seed 456\n",
      "   Sentiment - Accuracy: 0.5126, F1: 0.3856\n",
      "   Emotion - Accuracy: 0.3108, F1: 0.0940\n",
      "   Combined - Accuracy: 0.4117, F1: 0.2398\n",
      "\n",
      "‚úÖ Completed evaluation for seed 456\n",
      "\n",
      "üå± TRAINING AND EVALUATING BERTWEET WITH SEED 789\n",
      "------------------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ BERTweet Sentiment on SST-2 (Seed 789)\n",
      "üöÄ Training BERTweet sentiment model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.6038\n",
      "Epoch 2/3, Average Loss: 0.2392\n",
      "Epoch 3/3, Average Loss: 0.1423\n",
      "‚úÖ BERTweet sentiment model trained and saved with seed 789\n",
      "   Accuracy: 0.5195, Macro F1: 0.3890\n",
      "\n",
      "2Ô∏è‚É£ BERTweet Emotion on GoEmotions (Seed 789)\n",
      "üöÄ Training BERTweet emotion model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.6244\n",
      "Epoch 2/3, Average Loss: 0.9621\n",
      "Epoch 3/3, Average Loss: 0.6710\n",
      "‚úÖ BERTweet emotion model trained and saved with seed 789\n",
      "   Accuracy: 0.7360, Macro F1: 0.7011\n",
      "\n",
      "3Ô∏è‚É£ BERTweet Multitask on SST-2 + GoEmotions (Seed 789)\n",
      "üöÄ Training BERTweet multitask model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.4732\n",
      "Epoch 2/3, Average Loss: 1.1708\n",
      "Epoch 3/3, Average Loss: 1.0700\n",
      "BERTweet multitask model trained and saved with seed 789\n",
      "   Sentiment - Accuracy: 0.5138, F1: 0.3888\n",
      "   Emotion - Accuracy: 0.2993, F1: 0.0999\n",
      "   Combined - Accuracy: 0.4065, F1: 0.2443\n",
      "\n",
      "‚úÖ Completed evaluation for seed 789\n",
      "\n",
      "üå± TRAINING AND EVALUATING BERTWEET WITH SEED 999\n",
      "------------------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ BERTweet Sentiment on SST-2 (Seed 999)\n",
      "üöÄ Training BERTweet sentiment model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.5978\n",
      "Epoch 2/3, Average Loss: 0.2331\n",
      "Epoch 3/3, Average Loss: 0.1184\n",
      "‚úÖ BERTweet sentiment model trained and saved with seed 999\n",
      "   Accuracy: 0.5172, Macro F1: 0.3887\n",
      "\n",
      "2Ô∏è‚É£ BERTweet Emotion on GoEmotions (Seed 999)\n",
      "üöÄ Training BERTweet emotion model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.6253\n",
      "Epoch 2/3, Average Loss: 1.5770\n",
      "Epoch 3/3, Average Loss: 1.3145\n",
      "‚úÖ BERTweet emotion model trained and saved with seed 999\n",
      "   Accuracy: 0.5480, Macro F1: 0.4431\n",
      "\n",
      "3Ô∏è‚É£ BERTweet Multitask on SST-2 + GoEmotions (Seed 999)\n",
      "üöÄ Training BERTweet multitask model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5349\n",
      "Epoch 2/3, Average Loss: 1.2290\n",
      "Epoch 3/3, Average Loss: 1.1571\n",
      "BERTweet multitask model trained and saved with seed 999\n",
      "   Sentiment - Accuracy: 0.5034, F1: 0.3824\n",
      "   Emotion - Accuracy: 0.2638, F1: 0.1237\n",
      "   Combined - Accuracy: 0.3836, F1: 0.2530\n",
      "\n",
      "‚úÖ Completed evaluation for seed 999\n",
      "\n",
      "üìä ANALYZING BERTWEET STABILITY ACROSS SEEDS\n",
      "======================================================================\n",
      "\n",
      "üîç BERTWEET_SENTIMENT - SENTIMENT\n",
      "   Accuracy: 0.5144 ¬± 0.0056\n",
      "   Macro F1: 0.3874 ¬± 0.0016\n",
      "\n",
      "üîç BERTWEET_EMOTION - EMOTION\n",
      "   Accuracy: 0.6890 ¬± 0.0709\n",
      "   Macro F1: 0.6395 ¬± 0.0985\n",
      "\n",
      "üîç BERTWEET_MULTITASK - SENTIMENT\n",
      "   Accuracy: 0.5108 ¬± 0.0041\n",
      "   Macro F1: 0.3849 ¬± 0.0022\n",
      "\n",
      "üîç BERTWEET_MULTITASK - EMOTION\n",
      "   Accuracy: 0.2924 ¬± 0.0156\n",
      "   Macro F1: 0.1054 ¬± 0.0101\n",
      "\n",
      "üíæ BERTweet results saved:\n",
      "   Raw results: ./bertweet_seed_analysis_results/bertweet_raw_results_20250813_114832.json\n",
      "   Stability analysis: ./bertweet_seed_analysis_results/bertweet_stability_analysis_20250813_114832.json\n",
      "   Summary report: ./bertweet_seed_analysis_results/bertweet_summary_report_20250813_114832.txt\n",
      "\n",
      "BERTWEET RANDOM SEED ANALYSIS COMPLETED\n",
      "============================================================\n",
      "Check the './bertweet_seed_analysis_results/' directory for detailed results.\n",
      "\n",
      "üìä QUICK STABILITY SUMMARY:\n",
      "----------------------------------------\n",
      "\n",
      "Bertweet Sentiment Sentiment:\n",
      "  Accuracy: 0.514 ¬± 0.006\n",
      "  F1 Score: 0.387 ¬± 0.002\n",
      "\n",
      "Bertweet Emotion Emotion:\n",
      "  Accuracy: 0.689 ¬± 0.071\n",
      "  F1 Score: 0.639 ¬± 0.098\n",
      "\n",
      "Bertweet Multitask Sentiment:\n",
      "  Accuracy: 0.511 ¬± 0.004\n",
      "  F1 Score: 0.385 ¬± 0.002\n",
      "\n",
      "Bertweet Multitask Emotion:\n",
      "  Accuracy: 0.292 ¬± 0.016\n",
      "  F1 Score: 0.105 ¬± 0.010\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# Run BERTweet random seed analysis with the modified function signature\n",
    "try:\n",
    "    all_results, stability_analysis = run_bertweet_seed_analysis(\n",
    "        seeds=[42, 123, 456, 789, 999],  # 5 different seeds\n",
    "        max_training_samples=3000,  # Reduced for faster training\n",
    "        max_eval_samples=1000  # Max evaluation samples per dataset\n",
    "    )\n",
    "    \n",
    "    print(\"\\nBERTWEET RANDOM SEED ANALYSIS COMPLETED\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Check the './bertweet_seed_analysis_results/' directory for detailed results.\")\n",
    "    \n",
    "    # Display quick summary\n",
    "    print(\"\\nüìä QUICK STABILITY SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Updated to match the actual structure of stability_analysis\n",
    "    for key, stats in stability_analysis.items():\n",
    "        model_task = key.replace('_', ' ').title()\n",
    "        print(f\"\\n{model_task}:\")\n",
    "        print(f\"  Accuracy: {stats['accuracy_mean']:.3f} ¬± {stats['accuracy_std']:.3f}\")\n",
    "        print(f\"  F1 Score: {stats['f1_mean']:.3f} ¬± {stats['f1_std']:.3f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during analysis: {str(e)}\")\n",
    "    print(\"üîß Try restarting the kernel and running cells 1-9 again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b729e75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet bootstrap analysis functions defined!\n"
     ]
    }
   ],
   "source": [
    "def load_bertweet_model_for_bootstrap(model_path: str, model_type: str):\n",
    "    print(f\"üì• Loading BERTweet {model_type} model from {model_path}...\")\n",
    "    \n",
    "    # Load config\n",
    "    with open(os.path.join(model_path, 'config.json'), 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    if model_type == \"multitask\":\n",
    "        # Load multitask model\n",
    "        model = BERTweetMultiTaskTransformer(\n",
    "            model_name=\"vinai/bertweet-base\",\n",
    "            sentiment_num_classes=config['sentiment_num_classes'],\n",
    "            emotion_num_classes=config['emotion_num_classes']\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        state_dict = torch.load(os.path.join(model_path, 'pytorch_model.bin'), map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "        \n",
    "        # Load encoders\n",
    "        sentiment_encoder = joblib.load(os.path.join(model_path, 'sentiment_encoder.pkl'))\n",
    "        emotion_encoder = joblib.load(os.path.join(model_path, 'emotion_encoder.pkl'))\n",
    "        \n",
    "        return model, tokenizer, sentiment_encoder, emotion_encoder\n",
    "        \n",
    "    else:\n",
    "        # Load single-task model\n",
    "        model = BERTweetSingleTaskTransformer(\n",
    "            model_name=\"vinai/bertweet-base\",\n",
    "            num_classes=config['num_classes']\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        state_dict = torch.load(os.path.join(model_path, 'pytorch_model.bin'), map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "        \n",
    "        # Load encoder\n",
    "        encoder = joblib.load(os.path.join(model_path, f'{config[\"task_type\"]}_encoder.pkl'))\n",
    "        \n",
    "        return model, tokenizer, encoder\n",
    "\n",
    "def evaluate_bertweet_on_bootstrap_sample(model, tokenizer, texts, sentiment_labels, emotion_labels, \n",
    "                                        model_sentiment_encoder, model_emotion_encoder, \n",
    "                                        data_sentiment_encoder, data_emotion_encoder, \n",
    "                                        model_type=\"multitask\", max_length=128):\n",
    "    model.eval()\n",
    "    \n",
    "    if model_type == \"multitask\":\n",
    "        sentiment_predictions = []\n",
    "        emotion_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(texts), 8):\n",
    "                batch_texts = texts[i:i+8]\n",
    "                \n",
    "                inputs = tokenizer(\n",
    "                    batch_texts,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\",\n",
    "                    max_length=max_length\n",
    "                )\n",
    "                \n",
    "                filtered_inputs = {\n",
    "                    'input_ids': inputs['input_ids'].to(device),\n",
    "                    'attention_mask': inputs['attention_mask'].to(device)\n",
    "                }\n",
    "                \n",
    "                outputs = model(**filtered_inputs)\n",
    "                \n",
    "                sentiment_preds = torch.argmax(outputs['sentiment_logits'], dim=-1)\n",
    "                emotion_preds = torch.argmax(outputs['emotion_logits'], dim=-1)\n",
    "                \n",
    "                for j in range(len(batch_texts)):\n",
    "                    sent_id = sentiment_preds[j].item()\n",
    "                    emot_id = emotion_preds[j].item()\n",
    "                    \n",
    "                    if sent_id >= len(model_sentiment_encoder.classes_):\n",
    "                        sent_id = 0\n",
    "                    if emot_id >= len(model_emotion_encoder.classes_):\n",
    "                        emot_id = 0\n",
    "                    \n",
    "                    sentiment_predictions.append(sent_id)\n",
    "                    emotion_predictions.append(emot_id)\n",
    "        \n",
    "        # Map predictions to data label space\n",
    "        mapped_sentiment_preds = []\n",
    "        mapped_emotion_preds = []\n",
    "        \n",
    "        for sent_pred, emot_pred in zip(sentiment_predictions, emotion_predictions):\n",
    "            sent_class = model_sentiment_encoder.classes_[sent_pred]\n",
    "            emot_class = model_emotion_encoder.classes_[emot_pred]\n",
    "            \n",
    "            try:\n",
    "                mapped_sent = data_sentiment_encoder.transform([sent_class])[0]\n",
    "                mapped_emot = data_emotion_encoder.transform([emot_class])[0]\n",
    "            except ValueError:\n",
    "                mapped_sent = 0\n",
    "                mapped_emot = 0\n",
    "            \n",
    "            mapped_sentiment_preds.append(mapped_sent)\n",
    "            mapped_emotion_preds.append(mapped_emot)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sentiment_accuracy = accuracy_score(sentiment_labels, mapped_sentiment_preds)\n",
    "        sentiment_f1 = f1_score(sentiment_labels, mapped_sentiment_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        emotion_accuracy = accuracy_score(emotion_labels, mapped_emotion_preds)\n",
    "        emotion_f1 = f1_score(emotion_labels, mapped_emotion_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        return {\n",
    "            'sentiment_accuracy': sentiment_accuracy,\n",
    "            'sentiment_f1': sentiment_f1,\n",
    "            'emotion_accuracy': emotion_accuracy,\n",
    "            'emotion_f1': emotion_f1\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def bootstrap_evaluation_bertweet(model, tokenizer, data, model_sentiment_encoder, model_emotion_encoder,\n",
    "                                data_sentiment_encoder, data_emotion_encoder, \n",
    "                                n_iterations=1000, sample_size=95):\n",
    "    print(f\"üîÑ Starting BERTweet bootstrap evaluation...\")\n",
    "    print(f\"   Iterations: {n_iterations}\")\n",
    "    print(f\"   Sample size: {sample_size}\")\n",
    "    \n",
    "    results = {\n",
    "        'sentiment_accuracy': [],\n",
    "        'sentiment_f1': [],\n",
    "        'emotion_accuracy': [],\n",
    "        'emotion_f1': []\n",
    "    }\n",
    "    \n",
    "    texts = data['texts']\n",
    "    sentiment_labels = data['sentiment_labels']\n",
    "    emotion_labels = data['emotion_labels']\n",
    "    n_samples = len(texts)\n",
    "    \n",
    "    for i in tqdm(range(n_iterations), desc=\"Bootstrap iterations\"):\n",
    "        # Bootstrap sample with replacement\n",
    "        indices = np.random.choice(n_samples, size=sample_size, replace=True)\n",
    "        \n",
    "        sample_texts = [texts[idx] for idx in indices]\n",
    "        sample_sentiment_labels = [sentiment_labels[idx] for idx in indices]\n",
    "        sample_emotion_labels = [emotion_labels[idx] for idx in indices]\n",
    "        \n",
    "        # Evaluate on bootstrap sample\n",
    "        metrics = evaluate_bertweet_on_bootstrap_sample(\n",
    "            model, tokenizer, sample_texts, sample_sentiment_labels, sample_emotion_labels,\n",
    "            model_sentiment_encoder, model_emotion_encoder,\n",
    "            data_sentiment_encoder, data_emotion_encoder\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results['sentiment_accuracy'].append(metrics['sentiment_accuracy'])\n",
    "        results['sentiment_f1'].append(metrics['sentiment_f1'])\n",
    "        results['emotion_accuracy'].append(metrics['emotion_accuracy'])\n",
    "        results['emotion_f1'].append(metrics['emotion_f1'])\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"BERTweet bootstrap analysis functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05733328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bertweet_bootstrap_analysis():\n",
    "    print(\"üöÄ Running BERTweet Bootstrap Analysis on General Datasets\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Load external datasets\n",
    "    print(\"\\nüìÇ Loading general evaluation datasets...\")\n",
    "    sentiment_data, emotion_data = load_external_datasets()\n",
    "    \n",
    "    # 2. Prepare evaluation data\n",
    "    print(\"Preparing SST-2 evaluation data...\")\n",
    "    sst2_eval_data = prepare_sst2_evaluation_data(sentiment_data)\n",
    "    print(\"Preparing GoEmotions evaluation data...\")\n",
    "    goemotions_eval_data = prepare_goemotions_evaluation_data(emotion_data)\n",
    "    print(\"Preparing multitask evaluation data...\")\n",
    "    multitask_eval_data = prepare_multitask_evaluation_data(sst2_eval_data, goemotions_eval_data)\n",
    "    \n",
    "    # 3. Load models\n",
    "    # Load single task models\n",
    "    sentiment_model_path = \"./bertweet_trained_models_seeds/bertweet_sentiment_seed_42\"\n",
    "    sentiment_model, sentiment_tokenizer, sentiment_encoder = load_bertweet_model_for_bootstrap(\n",
    "        sentiment_model_path, \"sentiment\"\n",
    "    )\n",
    "    \n",
    "    emotion_model_path = \"./bertweet_trained_models_seeds/bertweet_emotion_seed_42\"\n",
    "    emotion_model, emotion_tokenizer, emotion_encoder = load_bertweet_model_for_bootstrap(\n",
    "        emotion_model_path, \"emotion\"\n",
    "    )\n",
    "    \n",
    "    # Load multitask model\n",
    "    multitask_model_path = \"./bertweet_trained_models_seeds/bertweet_multitask_seed_42\"\n",
    "    multitask_model, multitask_tokenizer, multitask_sent_encoder, multitask_emot_encoder = load_bertweet_model_for_bootstrap(\n",
    "        multitask_model_path, \"multitask\"\n",
    "    )\n",
    "    \n",
    "    # 4. Run bootstrap evaluation\n",
    "    print(\"\\nüîÑ Starting bootstrap evaluation...\")\n",
    "    n_iterations = 1000\n",
    "    sample_size = 95\n",
    "    \n",
    "    # Initialize results dictionary for F1 scores\n",
    "    f1_results = {\n",
    "        'sentiment_single': [],\n",
    "        'emotion_single': [],\n",
    "        'multitask_sentiment': [],\n",
    "        'multitask_emotion': []\n",
    "    }\n",
    "    \n",
    "    # Run bootstrap iterations\n",
    "    for i in tqdm(range(n_iterations), desc=\"Bootstrap iterations\"):\n",
    "        # Sample indices with replacement for each dataset\n",
    "        sst2_indices = np.random.choice(len(sst2_eval_data['texts']), size=sample_size, replace=True)\n",
    "        goemotions_indices = np.random.choice(len(goemotions_eval_data['texts']), size=sample_size, replace=True)\n",
    "        \n",
    "        # Prepare bootstrap samples\n",
    "        sst2_sample = {\n",
    "            'texts': [sst2_eval_data['texts'][i] for i in sst2_indices],\n",
    "            'sentiment_labels': [sst2_eval_data['sentiment_labels'][i] for i in sst2_indices]\n",
    "        }\n",
    "        \n",
    "        goemotions_sample = {\n",
    "            'texts': [goemotions_eval_data['texts'][i] for i in goemotions_indices],\n",
    "            'emotion_labels': [goemotions_eval_data['emotion_labels'][i] for i in goemotions_indices]\n",
    "        }\n",
    "        \n",
    "        multitask_sample = {\n",
    "            'texts': sst2_sample['texts'],  # Use SST-2 texts for multitask\n",
    "            'sentiment_labels': sst2_sample['sentiment_labels'],\n",
    "            'emotion_labels': [goemotions_eval_data['emotion_labels'][i] for i in sst2_indices]\n",
    "        }\n",
    "        \n",
    "        # Evaluate single task models\n",
    "        sentiment_results = evaluate_bertweet_single_task(\n",
    "            sentiment_model, sentiment_tokenizer, sentiment_encoder, \n",
    "            sst2_sample, 'sentiment'\n",
    "        )\n",
    "        f1_results['sentiment_single'].append(sentiment_results['macro_f1'])\n",
    "        \n",
    "        emotion_results = evaluate_bertweet_single_task(\n",
    "            emotion_model, emotion_tokenizer, emotion_encoder, \n",
    "            goemotions_sample, 'emotion'\n",
    "        )\n",
    "        f1_results['emotion_single'].append(emotion_results['macro_f1'])\n",
    "        \n",
    "        # Evaluate multitask model\n",
    "        multitask_results = evaluate_bertweet_multitask(\n",
    "            multitask_model, multitask_tokenizer, \n",
    "            multitask_sent_encoder, multitask_emot_encoder,\n",
    "            multitask_sample\n",
    "        )\n",
    "        f1_results['multitask_sentiment'].append(multitask_results['sentiment']['macro_f1'])\n",
    "        f1_results['multitask_emotion'].append(multitask_results['emotion']['macro_f1'])\n",
    "    \n",
    "    # 5. Calculate and display statistics\n",
    "    print(\"\\nüìä BERTweet Bootstrap Analysis Results (General Datasets)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for model_name, f1_scores in f1_results.items():\n",
    "        values = np.array(f1_scores)\n",
    "        mean = np.mean(values)\n",
    "        std = np.std(values)\n",
    "        ci_lower = np.percentile(values, 2.5)\n",
    "        ci_upper = np.percentile(values, 97.5)\n",
    "        \n",
    "        print(f\"\\nüéØ {model_name.replace('_', ' ').upper()} - F1\")\n",
    "        print(f\"   Mean: {mean:.4f}\")\n",
    "        print(f\"   Std:  {std:.4f}\")\n",
    "        print(f\"   95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "    \n",
    "    # 6. Save results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_file = f\"./bertweet_seed_analysis_results/bertweet_bootstrap_general_datasets_{timestamp}.json\"\n",
    "    \n",
    "    results_to_save = {\n",
    "        model_name: {\n",
    "            'values': [float(x) for x in values],\n",
    "            'mean': float(np.mean(values)),\n",
    "            'std': float(np.std(values)),\n",
    "            'ci_lower': float(np.percentile(values, 2.5)),\n",
    "            'ci_upper': float(np.percentile(values, 97.5))\n",
    "        }\n",
    "        for model_name, values in f1_results.items()\n",
    "    }\n",
    "    \n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results_to_save, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüíæ Bootstrap results saved to: {results_file}\")\n",
    "    \n",
    "    return results_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dec111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running BERTweet Bootstrap Analysis on General Datasets\n",
      "============================================================\n",
      "\n",
      "üìÇ Loading general evaluation datasets...\n",
      "Loading external datasets...\n",
      "‚úÖ SST-2 dataset loaded: 67349 train, 872 validation samples\n",
      "‚úÖ GoEmotions dataset loaded: 43410 train, 5426 validation, 5427 test samples\n",
      "Preparing SST-2 evaluation data...\n",
      "Preparing SST-2 evaluation data...\n",
      "‚úÖ SST-2 evaluation data prepared: 872 samples\n",
      "   Sentiment classes: ['Negative', 'Neutral', 'Positive']\n",
      "Preparing GoEmotions evaluation data...\n",
      "Preparing GoEmotions evaluation data...\n",
      "‚úÖ GoEmotions evaluation data prepared: 1000 samples\n",
      "   Emotion classes: ['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise']\n",
      "Preparing multitask evaluation data...\n",
      "Preparing multitask evaluation data...\n",
      "‚úÖ Multitask evaluation data prepared: 872 samples\n",
      "üì• Loading BERTweet sentiment model from ./bertweet_trained_models_seeds/bertweet_sentiment_seed_42...\n",
      "üì• Loading BERTweet emotion model from ./bertweet_trained_models_seeds/bertweet_emotion_seed_42...\n",
      "üì• Loading BERTweet multitask model from ./bertweet_trained_models_seeds/bertweet_multitask_seed_42...\n",
      "\n",
      "üîÑ Starting bootstrap evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap iterations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [17:11<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä BERTweet Bootstrap Analysis Results (General Datasets)\n",
      "============================================================\n",
      "\n",
      "üéØ SENTIMENT SINGLE - F1\n",
      "   Mean: 0.3804\n",
      "   Std:  0.0286\n",
      "   95% CI: [0.3238, 0.4370]\n",
      "\n",
      "üéØ EMOTION SINGLE - F1\n",
      "   Mean: 0.6758\n",
      "   Std:  0.0519\n",
      "   95% CI: [0.5717, 0.7720]\n",
      "\n",
      "üéØ MULTITASK SENTIMENT - F1\n",
      "   Mean: 0.3776\n",
      "   Std:  0.0289\n",
      "   95% CI: [0.3206, 0.4331]\n",
      "\n",
      "üéØ MULTITASK EMOTION - F1\n",
      "   Mean: 0.1003\n",
      "   Std:  0.0195\n",
      "   95% CI: [0.0661, 0.1402]\n",
      "\n",
      "üíæ Bootstrap results saved to: ./bertweet_seed_analysis_results/bertweet_bootstrap_general_datasets_20250813_120612.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run bootstrap analysis\n",
    "bootstrap_stats = run_bertweet_bootstrap_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ead5e",
   "metadata": {},
   "source": [
    "# Reddit specific dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b40f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "‚úÖ Libraries imported and setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, AutoConfig,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import random\n",
    "from collections import Counter\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"./bertweet_seed_analysis_results\", exist_ok=True)\n",
    "os.makedirs(\"./bertweet_trained_models_seeds\", exist_ok=True)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "print(\"‚úÖ Libraries imported and setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31672e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "def set_random_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def clear_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def print_memory_usage():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f} GB, Cached: {cached:.2f} GB\")\n",
    "\n",
    "print(\"Utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e948c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet model architectures defined\n"
     ]
    }
   ],
   "source": [
    "class BERTweetSingleTaskTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"vinai/bertweet-base\",\n",
    "        num_classes: int = 3,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load BERTweet model\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        self.bertweet = AutoModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        # Classification head\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(self.bertweet.config.hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERTweet outputs\n",
    "        outputs = self.bertweet(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return {'logits': logits}\n",
    "\n",
    "class BERTweetMultiTaskTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"vinai/bertweet-base\",\n",
    "        sentiment_num_classes: int = 3,\n",
    "        emotion_num_classes: int = 6,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sentiment_num_classes = sentiment_num_classes\n",
    "        self.emotion_num_classes = emotion_num_classes\n",
    "        \n",
    "        # Load BERTweet model\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        self.bertweet = AutoModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        hidden_size = self.bertweet.config.hidden_size\n",
    "        \n",
    "        # Task-specific attention layers\n",
    "        self.sentiment_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.emotion_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Shared attention for common features\n",
    "        self.shared_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.sentiment_norm = nn.LayerNorm(hidden_size)\n",
    "        self.emotion_norm = nn.LayerNorm(hidden_size)\n",
    "        self.shared_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.sentiment_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.emotion_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.shared_dropout = nn.Dropout(classifier_dropout)\n",
    "        \n",
    "        # Classification heads\n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, sentiment_num_classes)\n",
    "        )\n",
    "        \n",
    "        self.emotion_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, emotion_num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in [self.sentiment_classifier, self.emotion_classifier]:\n",
    "            for layer in module:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        # Shared encoder\n",
    "        encoder_outputs = self.bertweet(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        sequence_output = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply shared attention\n",
    "        shared_attended, _ = self.shared_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        shared_attended = self.shared_norm(shared_attended + sequence_output)\n",
    "        shared_attended = self.shared_dropout(shared_attended)\n",
    "        shared_pooled = shared_attended[:, 0, :]\n",
    "        \n",
    "        outputs = {}\n",
    "        \n",
    "        # Sentiment branch\n",
    "        sentiment_attended, _ = self.sentiment_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        sentiment_attended = self.sentiment_norm(sentiment_attended + sequence_output)\n",
    "        sentiment_attended = self.sentiment_dropout(sentiment_attended)\n",
    "        sentiment_pooled = sentiment_attended[:, 0, :]\n",
    "        sentiment_features = torch.cat([shared_pooled, sentiment_pooled], dim=-1)\n",
    "        sentiment_logits = self.sentiment_classifier(sentiment_features)\n",
    "        outputs[\"sentiment_logits\"] = sentiment_logits\n",
    "        \n",
    "        # Emotion branch\n",
    "        emotion_attended, _ = self.emotion_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        emotion_attended = self.emotion_norm(emotion_attended + sequence_output)\n",
    "        emotion_attended = self.emotion_dropout(emotion_attended)\n",
    "        emotion_pooled = emotion_attended[:, 0, :]\n",
    "        emotion_features = torch.cat([shared_pooled, emotion_pooled], dim=-1)\n",
    "        emotion_logits = self.emotion_classifier(emotion_features)\n",
    "        outputs[\"emotion_logits\"] = emotion_logits\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "print(\"BERTweet model architectures defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8a07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet dataset classes defined\n"
     ]
    }
   ],
   "source": [
    "class BERTweetDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer, max_length: int = 128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class BERTweetMultiTaskDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], sentiment_labels: List[int], \n",
    "                 emotion_labels: List[int], tokenizer, max_length: int = 128):\n",
    "        self.texts = texts\n",
    "        self.sentiment_labels = sentiment_labels\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        sentiment_label = self.sentiment_labels[idx]\n",
    "        emotion_label = self.emotion_labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'sentiment_labels': torch.tensor(sentiment_label, dtype=torch.long),\n",
    "            'emotion_labels': torch.tensor(emotion_label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"BERTweet dataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf64a759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "def load_external_datasets() -> Tuple[Dict, Dict]:\n",
    "    print(\"Loading external datasets...\")\n",
    "    \n",
    "    # Load SST-2 for sentiment\n",
    "    try:\n",
    "        sst2_dataset = load_dataset(\"sst2\")\n",
    "        sentiment_data = {\n",
    "            'train': sst2_dataset['train'],\n",
    "            'validation': sst2_dataset['validation']\n",
    "        }\n",
    "        print(f\"‚úÖ SST-2 dataset loaded: {len(sentiment_data['train'])} train samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not load SST-2: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Load GoEmotions for emotion\n",
    "    try:\n",
    "        emotions_dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "        emotion_data = {\n",
    "            'train': emotions_dataset['train'],\n",
    "            'validation': emotions_dataset['validation']\n",
    "        }\n",
    "        print(f\"‚úÖ GoEmotions dataset loaded: {len(emotion_data['train'])} train samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not load GoEmotions: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return sentiment_data, emotion_data\n",
    "\n",
    "def prepare_reddit_evaluation_data(reddit_data_path: str) -> Dict:\n",
    "    print(f\"Loading Reddit evaluation data from {reddit_data_path}...\")\n",
    "    \n",
    "    df = pd.read_csv(reddit_data_path)\n",
    "    \n",
    "    # Create label encoders that match BERTweet models\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    \n",
    "    # Fit encoders\n",
    "    sentiment_encoder.fit(df['sentiment'].tolist())\n",
    "    emotion_encoder.fit(df['emotion'].tolist())\n",
    "    \n",
    "    reddit_data = {\n",
    "        'texts': df['text_content'].tolist(),\n",
    "        'sentiment_labels_text': df['sentiment'].tolist(),\n",
    "        'emotion_labels_text': df['emotion'].tolist(),\n",
    "        'sentiment_labels': sentiment_encoder.transform(df['sentiment'].tolist()),\n",
    "        'emotion_labels': emotion_encoder.transform(df['emotion'].tolist()),\n",
    "        'sentiment_encoder': sentiment_encoder,\n",
    "        'emotion_encoder': emotion_encoder\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Reddit data prepared: {len(reddit_data['texts'])} samples\")\n",
    "    print(f\"   Sentiment classes: {list(sentiment_encoder.classes_)}\")\n",
    "    print(f\"   Emotion classes: {list(emotion_encoder.classes_)}\")\n",
    "    \n",
    "    return reddit_data\n",
    "\n",
    "def prepare_bertweet_training_data(sentiment_data: Dict, emotion_data: Dict, max_samples: int = 5000):\n",
    "\n",
    "    # Process sentiment data (SST-2 to 3 classes)\n",
    "    sentiment_texts = sentiment_data['train']['sentence'][:max_samples]\n",
    "    sentiment_labels_raw = sentiment_data['train']['label'][:max_samples]\n",
    "    \n",
    "    # Convert SST-2 binary to 3-class sentiment\n",
    "    sentiment_labels = []\n",
    "    for label in sentiment_labels_raw:\n",
    "        if label == 0:  # Negative\n",
    "            sentiment_labels.append(0)\n",
    "        elif label == 1:  # Positive\n",
    "            if np.random.random() < 0.15:  # 15% chance to be neutral\n",
    "                sentiment_labels.append(1)  # Neutral\n",
    "            else:\n",
    "                sentiment_labels.append(2)  # Positive\n",
    "    \n",
    "    # Ensure we have all 3 classes\n",
    "    if 1 not in sentiment_labels:\n",
    "        neutral_indices = np.random.choice(len(sentiment_labels), size=100, replace=False)\n",
    "        for idx in neutral_indices:\n",
    "            sentiment_labels[idx] = 1\n",
    "    \n",
    "    # Process emotion data (filter to first 6 classes)\n",
    "    emotion_texts_all = emotion_data['train']['text']\n",
    "    emotion_labels_all = emotion_data['train']['labels']\n",
    "    \n",
    "    emotion_texts = []\n",
    "    emotion_labels = []\n",
    "    count = 0\n",
    "    for i, label in enumerate(emotion_labels_all):\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "        if isinstance(label, list):\n",
    "            if label and label[0] in range(6):\n",
    "                emotion_texts.append(emotion_texts_all[i])\n",
    "                emotion_labels.append(label[0])\n",
    "                count += 1\n",
    "        else:\n",
    "            if label in range(6):\n",
    "                emotion_texts.append(emotion_texts_all[i])\n",
    "                emotion_labels.append(label)\n",
    "                count += 1\n",
    "    \n",
    "    # Create encoders\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    sentiment_encoder.classes_ = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "    emotion_encoder.classes_ = np.array(['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise'])\n",
    "    \n",
    "    return {\n",
    "        'sentiment_data': {\n",
    "            'texts': sentiment_texts,\n",
    "            'labels': sentiment_labels,\n",
    "            'encoder': sentiment_encoder\n",
    "        },\n",
    "        'emotion_data': {\n",
    "            'texts': emotion_texts,\n",
    "            'labels': emotion_labels,\n",
    "            'encoder': emotion_encoder\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"Data loading functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b499d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet training functions defined\n"
     ]
    }
   ],
   "source": [
    "def train_bertweet_single_task(\n",
    "    task_type: str,  # 'sentiment' or 'emotion'\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    training_data: Dict,\n",
    "    max_samples: int = 5000\n",
    ") -> Tuple[any, LabelEncoder]:\n",
    "    \n",
    "    print(f\"üöÄ Training BERTweet {task_type} model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Get appropriate data\n",
    "    if task_type == 'sentiment':\n",
    "        texts = training_data['sentiment_data']['texts'][:max_samples]\n",
    "        labels = training_data['sentiment_data']['labels'][:max_samples]\n",
    "        encoder = training_data['sentiment_data']['encoder']\n",
    "        num_classes = 3\n",
    "    else:  # emotion\n",
    "        texts = training_data['emotion_data']['texts'][:max_samples]\n",
    "        labels = training_data['emotion_data']['labels'][:max_samples]\n",
    "        encoder = training_data['emotion_data']['encoder']\n",
    "        num_classes = 6\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model\n",
    "    model = BERTweetSingleTaskTransformer(\n",
    "        model_name='vinai/bertweet-base',\n",
    "        num_classes=num_classes,\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        attention_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = BERTweetDataset(texts, labels, tokenizer, max_length=128)\n",
    "    dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    total_steps = len(dataloader) * 3  # 3 epochs\n",
    "    warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    print(f\"Starting training for 3 epochs...\")\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels_batch = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs['logits'], labels_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/3, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    output_dir = f\"./bertweet_trained_models_seeds/bertweet_{task_type}_seed_{seed}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model state dict\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "    \n",
    "    # Save config\n",
    "    config = {\n",
    "        \"model_name\": \"vinai/bertweet-base\",\n",
    "        \"num_classes\": num_classes,\n",
    "        \"task_type\": task_type,\n",
    "        \"model_type\": \"BERTweetSingleTaskTransformer\"\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"config.json\"), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save tokenizer and encoder\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(encoder, os.path.join(output_dir, f'{task_type}_encoder.pkl'))\n",
    "    \n",
    "    print(f\"‚úÖ BERTweet {task_type} model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, encoder\n",
    "\n",
    "def train_bertweet_multitask(\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    training_data: Dict,\n",
    "    max_samples: int = 2000\n",
    ") -> Tuple[any, LabelEncoder, LabelEncoder]:\n",
    "    \n",
    "    print(f\"üöÄ Training BERTweet multitask model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Prepare multitask data (combine sentiment and emotion data)\n",
    "    min_length = min(len(training_data['sentiment_data']['texts']), \n",
    "                     len(training_data['emotion_data']['texts']))\n",
    "    min_length = min(min_length, max_samples)\n",
    "    \n",
    "    combined_texts = training_data['sentiment_data']['texts'][:min_length]\n",
    "    combined_sentiment_labels = training_data['sentiment_data']['labels'][:min_length]\n",
    "    combined_emotion_labels = training_data['emotion_data']['labels'][:min_length]\n",
    "    \n",
    "    sentiment_encoder = training_data['sentiment_data']['encoder']\n",
    "    emotion_encoder = training_data['emotion_data']['encoder']\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model\n",
    "    model = BERTweetMultiTaskTransformer(\n",
    "        model_name='vinai/bertweet-base',\n",
    "        sentiment_num_classes=3,\n",
    "        emotion_num_classes=6,\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        attention_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = BERTweetMultiTaskDataset(\n",
    "        combined_texts, combined_sentiment_labels, combined_emotion_labels, \n",
    "        tokenizer, max_length=128\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    total_steps = len(dataloader) * 3  # 3 epochs\n",
    "    warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Loss functions\n",
    "    sentiment_criterion = nn.CrossEntropyLoss()\n",
    "    emotion_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    alpha = best_params['alpha']\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    print(f\"Starting training for 3 epochs...\")\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            sentiment_labels = batch['sentiment_labels'].to(device)\n",
    "            emotion_labels = batch['emotion_labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Calculate losses\n",
    "            sentiment_loss = sentiment_criterion(outputs['sentiment_logits'], sentiment_labels)\n",
    "            emotion_loss = emotion_criterion(outputs['emotion_logits'], emotion_labels)\n",
    "            \n",
    "            # Combined loss\n",
    "            total_loss_batch = alpha * sentiment_loss + (1 - alpha) * emotion_loss\n",
    "            total_loss += total_loss_batch.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/3, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    output_dir = f\"./bertweet_trained_models_seeds/bertweet_multitask_seed_{seed}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model state dict\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "    \n",
    "    # Save config\n",
    "    config = {\n",
    "        \"model_name\": \"vinai/bertweet-base\",\n",
    "        \"sentiment_num_classes\": 3,\n",
    "        \"emotion_num_classes\": 6,\n",
    "        \"model_type\": \"BERTweetMultiTaskTransformer\"\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"config.json\"), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save tokenizer and encoders\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(sentiment_encoder, os.path.join(output_dir, 'sentiment_encoder.pkl'))\n",
    "    joblib.dump(emotion_encoder, os.path.join(output_dir, 'emotion_encoder.pkl'))\n",
    "    \n",
    "    print(f\"BERTweet multitask model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, sentiment_encoder, emotion_encoder\n",
    "\n",
    "print(\"BERTweet training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81d537cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Evaluation Functions for BERTweet Models\n",
    "def evaluate_bertweet_single_task(model, tokenizer, label_encoder, reddit_data: Dict, task_type: str) -> Dict:\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_labels = reddit_data[f'{task_type}_labels']\n",
    "    \n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 16):  # Batch size 16\n",
    "            batch_texts = texts[i:i+16]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=128\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items() if k in ['input_ids', 'attention_mask']}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs['logits']\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                pred_id = preds[j].item()\n",
    "                confidence = probs[j][pred_id].item()\n",
    "                \n",
    "                # Handle out of range predictions\n",
    "                if pred_id >= len(label_encoder.classes_):\n",
    "                    pred_id = 0\n",
    "                \n",
    "                predictions.append(pred_id)\n",
    "                confidences.append(confidence)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    macro_f1 = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'predictions': predictions,\n",
    "        'confidences': confidences,\n",
    "        'true_labels': true_labels\n",
    "    }\n",
    "\n",
    "def evaluate_bertweet_multitask(model, tokenizer, sentiment_encoder, emotion_encoder, \n",
    "                               reddit_data: Dict, max_length: int = 128) -> Dict:\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_sentiment_labels = reddit_data['sentiment_labels']\n",
    "    true_emotion_labels = reddit_data['emotion_labels']\n",
    "    \n",
    "    sentiment_predictions = []\n",
    "    emotion_predictions = []\n",
    "    sentiment_confidences = []\n",
    "    emotion_confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 8):  # Smaller batch size for multitask\n",
    "            batch_texts = texts[i:i+8]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=max_length\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items() if k in ['input_ids', 'attention_mask']}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            # Process sentiment\n",
    "            sentiment_logits = outputs['sentiment_logits']\n",
    "            sentiment_probs = F.softmax(sentiment_logits, dim=-1)\n",
    "            sentiment_preds = torch.argmax(sentiment_logits, dim=-1)\n",
    "            \n",
    "            # Process emotion\n",
    "            emotion_logits = outputs['emotion_logits']\n",
    "            emotion_probs = F.softmax(emotion_logits, dim=-1)\n",
    "            emotion_preds = torch.argmax(emotion_logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                # Sentiment\n",
    "                sent_id = sentiment_preds[j].item()\n",
    "                sent_conf = sentiment_probs[j][sent_id].item()\n",
    "                if sent_id >= len(sentiment_encoder.classes_):\n",
    "                    sent_id = 0\n",
    "                sentiment_predictions.append(sent_id)\n",
    "                sentiment_confidences.append(sent_conf)\n",
    "                \n",
    "                # Emotion\n",
    "                emot_id = emotion_preds[j].item()\n",
    "                emot_conf = emotion_probs[j][emot_id].item()\n",
    "                if emot_id >= len(emotion_encoder.classes_):\n",
    "                    emot_id = 0\n",
    "                emotion_predictions.append(emot_id)\n",
    "                emotion_confidences.append(emot_conf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    sentiment_accuracy = accuracy_score(true_sentiment_labels, sentiment_predictions)\n",
    "    sentiment_f1 = f1_score(true_sentiment_labels, sentiment_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    emotion_accuracy = accuracy_score(true_emotion_labels, emotion_predictions)\n",
    "    emotion_f1 = f1_score(true_emotion_labels, emotion_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'sentiment': {\n",
    "            'accuracy': sentiment_accuracy,\n",
    "            'macro_f1': sentiment_f1,\n",
    "            'predictions': sentiment_predictions,\n",
    "            'confidences': sentiment_confidences\n",
    "        },\n",
    "        'emotion': {\n",
    "            'accuracy': emotion_accuracy,\n",
    "            'macro_f1': emotion_f1,\n",
    "            'predictions': emotion_predictions,\n",
    "            'confidences': emotion_confidences\n",
    "        },\n",
    "        'combined_accuracy': (sentiment_accuracy + emotion_accuracy) / 2,\n",
    "        'combined_f1': (sentiment_f1 + emotion_f1) / 2\n",
    "    }\n",
    "\n",
    "print(\"BERTweet evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906c8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ BERTweet random seed analysis function defined!\n"
     ]
    }
   ],
   "source": [
    "def run_bertweet_seed_analysis(\n",
    "    reddit_data_path: str = \"annotated_reddit_posts.csv\",\n",
    "    seeds: List[int] = [42, 123, 456, 789, 999],\n",
    "    max_training_samples: int = 3000\n",
    "):\n",
    "    \n",
    "    print(\"üé≤ STARTING BERTWEET RANDOM SEED ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Seeds to test: {seeds}\")\n",
    "    print(f\"Max training samples per dataset: {max_training_samples}\")\n",
    "    \n",
    "    # Load external datasets\n",
    "    print(\"\\nüìÇ Loading external datasets...\")\n",
    "    sentiment_data, emotion_data = load_external_datasets()\n",
    "    \n",
    "    # Prepare training data\n",
    "    print(\"\\nüîÑ Preparing BERTweet training data...\")\n",
    "    training_data = prepare_bertweet_training_data(sentiment_data, emotion_data, max_training_samples)\n",
    "    \n",
    "    # Load Reddit evaluation data\n",
    "    print(\"\\nüìÇ Loading Reddit evaluation data...\")\n",
    "    reddit_data = prepare_reddit_evaluation_data(reddit_data_path)\n",
    "    \n",
    "    # Define best parameters for each BERTweet model\n",
    "    best_params = {\n",
    "        'sentiment': {\n",
    "            'learning_rate': 3.65445235521325e-05,\n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.15986584841970367,\n",
    "            'weight_decay': 0.02404167763981929,\n",
    "            'hidden_dropout_prob': 0.13119890406724052,\n",
    "            'classifier_dropout': 0.1116167224336399\n",
    "        },\n",
    "        'emotion': {\n",
    "            'learning_rate': 3.65445235521325e-05, \n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.15986584841970367,\n",
    "            'weight_decay': 0.02404167763981929,\n",
    "            'hidden_dropout_prob': 0.13119890406724052,\n",
    "            'classifier_dropout': 0.1116167224336399\n",
    "        },\n",
    "        'multitask': {\n",
    "            'learning_rate': 4.166863122305896e-05,\n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.15142344384136117,\n",
    "            'weight_decay': 0.06331731119758383,\n",
    "            'hidden_dropout_prob': 0.10929008254399955,\n",
    "            'classifier_dropout': 0.22150897038028766,\n",
    "            'alpha': 0.4341048247374583\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    # Store results for each seed\n",
    "    all_results = {}\n",
    "    \n",
    "    for seed in seeds:\n",
    "        print(f\"\\nüå± TRAINING AND EVALUATING BERTWEET WITH SEED {seed}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        seed_results = {}\n",
    "        \n",
    "        # 1. Train and evaluate BERTweet Sentiment\n",
    "        print(f\"\\n1Ô∏è‚É£ BERTweet Sentiment (Seed {seed})\")\n",
    "        model, encoder = train_bertweet_single_task(\n",
    "            'sentiment', best_params['sentiment'], seed, \n",
    "            training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_sentiment_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_bertweet_single_task(model, tokenizer, encoder, reddit_data, 'sentiment')\n",
    "        seed_results['bertweet_sentiment'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 2. Train and evaluate BERTweet Emotion\n",
    "        print(f\"\\n2Ô∏è‚É£ BERTweet Emotion (Seed {seed})\")\n",
    "        model, encoder = train_bertweet_single_task(\n",
    "            'emotion', best_params['emotion'], seed,\n",
    "            training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_emotion_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_bertweet_single_task(model, tokenizer, encoder, reddit_data, 'emotion')\n",
    "        seed_results['bertweet_emotion'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 3. Train and evaluate BERTweet Multitask\n",
    "        print(f\"\\n3Ô∏è‚É£ BERTweet Multitask (Seed {seed})\")\n",
    "        model, sent_enc, emot_enc = train_bertweet_multitask(\n",
    "            best_params['multitask'], seed, training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_multitask_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_bertweet_multitask(\n",
    "            model, tokenizer, sent_enc, emot_enc, reddit_data, 128\n",
    "        )\n",
    "        seed_results['bertweet_multitask'] = results\n",
    "        print(f\"   Sentiment - Accuracy: {results['sentiment']['accuracy']:.4f}, F1: {results['sentiment']['macro_f1']:.4f}\")\n",
    "        print(f\"   Emotion - Accuracy: {results['emotion']['accuracy']:.4f}, F1: {results['emotion']['macro_f1']:.4f}\")\n",
    "        print(f\"   Combined - Accuracy: {results['combined_accuracy']:.4f}, F1: {results['combined_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        all_results[seed] = seed_results\n",
    "        \n",
    "        print(f\"\\n‚úÖ Completed evaluation for seed {seed}\")\n",
    "    \n",
    "    # Analyze stability across seeds\n",
    "    print(f\"\\nüìä ANALYZING BERTWEET STABILITY ACROSS SEEDS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    stability_analysis = analyze_bertweet_seed_stability(all_results, seeds)\n",
    "    \n",
    "    # Save results\n",
    "    save_bertweet_results(all_results, stability_analysis, seeds)\n",
    "    \n",
    "    return all_results, stability_analysis\n",
    "\n",
    "print(\"‚úÖ BERTweet random seed analysis function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3da3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet stability analysis functions defined\n"
     ]
    }
   ],
   "source": [
    "def analyze_bertweet_seed_stability(all_results: Dict, seeds: List[int]) -> Dict:\n",
    "    \n",
    "    stability_stats = {}\n",
    "    \n",
    "    # Define model-task combinations\n",
    "    evaluations = [\n",
    "        ('bertweet_sentiment', 'sentiment'),\n",
    "        ('bertweet_emotion', 'emotion'),\n",
    "        ('bertweet_multitask', 'sentiment'),\n",
    "        ('bertweet_multitask', 'emotion')\n",
    "    ]\n",
    "    \n",
    "    for model_name, task in evaluations:\n",
    "        print(f\"\\nüîç {model_name.upper()} - {task.upper()}\")\n",
    "        \n",
    "        accuracies = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        for seed in seeds:\n",
    "            if model_name in all_results[seed]:\n",
    "                result = all_results[seed][model_name]\n",
    "                \n",
    "                if model_name.endswith('_multitask'):\n",
    "                    acc = result[task]['accuracy']\n",
    "                    f1 = result[task]['macro_f1']\n",
    "                else:\n",
    "                    acc = result['accuracy']\n",
    "                    f1 = result['macro_f1']\n",
    "                \n",
    "                accuracies.append(acc)\n",
    "                f1_scores.append(f1)\n",
    "        \n",
    "        if accuracies:\n",
    "            acc_mean = np.mean(accuracies)\n",
    "            acc_std = np.std(accuracies)\n",
    "            f1_mean = np.mean(f1_scores)\n",
    "            f1_std = np.std(f1_scores)\n",
    "            \n",
    "            stability_stats[f\"{model_name}_{task}\"] = {\n",
    "                'accuracy_mean': acc_mean,\n",
    "                'accuracy_std': acc_std,\n",
    "                'f1_mean': f1_mean,\n",
    "                'f1_std': f1_std,\n",
    "                'accuracy_values': accuracies,\n",
    "                'f1_values': f1_scores\n",
    "            }\n",
    "            \n",
    "            print(f\"   Accuracy: {acc_mean:.4f} ¬± {acc_std:.4f}\")\n",
    "            print(f\"   Macro F1: {f1_mean:.4f} ¬± {f1_std:.4f}\")\n",
    "    \n",
    "    return stability_stats\n",
    "\n",
    "def save_bertweet_results(all_results: Dict, stability_analysis: Dict, seeds: List[int]):\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save raw results\n",
    "    results_file = f\"./bertweet_seed_analysis_results/bertweet_raw_results_{timestamp}.json\"\n",
    "    with open(results_file, 'w') as f:\n",
    "        # Convert numpy types to Python types for JSON serialization\n",
    "        serializable_results = {}\n",
    "        for seed, seed_results in all_results.items():\n",
    "            serializable_results[str(seed)] = {}\n",
    "            for model, results in seed_results.items():\n",
    "                if isinstance(results, dict):\n",
    "                    serializable_results[str(seed)][model] = {}\n",
    "                    for key, value in results.items():\n",
    "                        if isinstance(value, dict):\n",
    "                            serializable_results[str(seed)][model][key] = {\n",
    "                                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                                   [float(x) if isinstance(x, (np.floating, np.integer)) else x for x in v] if isinstance(v, list) else v\n",
    "                                for k, v in value.items()\n",
    "                            }\n",
    "                        else:\n",
    "                            serializable_results[str(seed)][model][key] = float(value) if isinstance(value, (np.floating, np.integer)) else value\n",
    "        \n",
    "        json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    # Save stability analysis\n",
    "    stability_file = f\"./bertweet_seed_analysis_results/bertweet_stability_analysis_{timestamp}.json\"\n",
    "    with open(stability_file, 'w') as f:\n",
    "        serializable_stability = {}\n",
    "        for key, stats in stability_analysis.items():\n",
    "            serializable_stability[key] = {\n",
    "                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                   [float(x) for x in v] if isinstance(v, list) else v\n",
    "                for k, v in stats.items()\n",
    "            }\n",
    "        json.dump(serializable_stability, f, indent=2)\n",
    "    \n",
    "    # Create summary report\n",
    "    summary_file = f\"./bertweet_seed_analysis_results/bertweet_summary_report_{timestamp}.txt\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"BERTWEET RANDOM SEED ANALYSIS SUMMARY REPORT\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        f.write(f\"Seeds tested: {seeds}\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"STABILITY ANALYSIS (Mean ¬± Std)\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        for key, stats in stability_analysis.items():\n",
    "            model_task = key.replace('_', ' ').title()\n",
    "            f.write(f\"\\n{model_task}:\\n\")\n",
    "            f.write(f\"  Accuracy: {stats['accuracy_mean']:.4f} ¬± {stats['accuracy_std']:.4f}\\n\")\n",
    "            f.write(f\"  Macro F1: {stats['f1_mean']:.4f} ¬± {stats['f1_std']:.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest Performers (by mean F1 score):\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        \n",
    "        # Find best performers\n",
    "        sentiment_best = max([k for k in stability_analysis.keys() if 'sentiment' in k], \n",
    "                           key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        emotion_best = max([k for k in stability_analysis.keys() if 'emotion' in k], \n",
    "                         key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        \n",
    "        f.write(f\"Sentiment: {sentiment_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[sentiment_best]['f1_mean']:.4f})\\n\")\n",
    "        f.write(f\"Emotion: {emotion_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[emotion_best]['f1_mean']:.4f})\\n\")\n",
    "    \n",
    "    print(f\"\\nüíæ BERTweet results saved:\")\n",
    "    print(f\"   Raw results: {results_file}\")\n",
    "    print(f\"   Stability analysis: {stability_file}\")\n",
    "    print(f\"   Summary report: {summary_file}\")\n",
    "\n",
    "print(\"BERTweet stability analysis functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95302a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ STARTING BERTWEET RANDOM SEED ANALYSIS\n",
      "======================================================================\n",
      "Seeds to test: [42, 123, 456, 789, 999]\n",
      "Max training samples per dataset: 3000\n",
      "\n",
      "üìÇ Loading external datasets...\n",
      "Loading external datasets...\n",
      "‚úÖ SST-2 dataset loaded: 67349 train samples\n",
      "‚úÖ GoEmotions dataset loaded: 43410 train samples\n",
      "\n",
      "üîÑ Preparing BERTweet training data...\n",
      "\n",
      "üìÇ Loading Reddit evaluation data...\n",
      "Loading Reddit evaluation data from annotated_reddit_posts.csv...\n",
      "‚úÖ Reddit data prepared: 95 samples\n",
      "   Sentiment classes: ['Negative', 'Neutral', 'Positive']\n",
      "   Emotion classes: ['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise']\n",
      "\n",
      "üå± TRAINING AND EVALUATING BERTWEET WITH SEED 42\n",
      "------------------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ BERTweet Sentiment (Seed 42)\n",
      "üöÄ Training BERTweet sentiment model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.9036\n",
      "Epoch 2/3, Average Loss: 0.5374\n",
      "Epoch 3/3, Average Loss: 0.4057\n",
      "‚úÖ BERTweet sentiment model trained and saved with seed 42\n",
      "   Accuracy: 0.6105, Macro F1: 0.4038\n",
      "\n",
      "2Ô∏è‚É£ BERTweet Emotion (Seed 42)\n",
      "üöÄ Training BERTweet emotion model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3897\n",
      "Epoch 2/3, Average Loss: 0.6943\n",
      "Epoch 3/3, Average Loss: 0.4847\n",
      "‚úÖ BERTweet emotion model trained and saved with seed 42\n",
      "   Accuracy: 0.1579, Macro F1: 0.0941\n",
      "\n",
      "3Ô∏è‚É£ BERTweet Multitask (Seed 42)\n",
      "üöÄ Training BERTweet multitask model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5970\n",
      "Epoch 2/3, Average Loss: 1.2914\n",
      "Epoch 3/3, Average Loss: 1.1998\n",
      "BERTweet multitask model trained and saved with seed 42\n",
      "   Sentiment - Accuracy: 0.6105, F1: 0.4152\n",
      "   Emotion - Accuracy: 0.2842, F1: 0.1249\n",
      "   Combined - Accuracy: 0.4474, F1: 0.2700\n",
      "\n",
      "‚úÖ Completed evaluation for seed 42\n",
      "\n",
      "üå± TRAINING AND EVALUATING BERTWEET WITH SEED 123\n",
      "------------------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ BERTweet Sentiment (Seed 123)\n",
      "üöÄ Training BERTweet sentiment model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.8028\n",
      "Epoch 2/3, Average Loss: 0.4705\n",
      "Epoch 3/3, Average Loss: 0.3504\n",
      "‚úÖ BERTweet sentiment model trained and saved with seed 123\n",
      "   Accuracy: 0.6000, Macro F1: 0.4073\n",
      "\n",
      "2Ô∏è‚É£ BERTweet Emotion (Seed 123)\n",
      "üöÄ Training BERTweet emotion model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3615\n",
      "Epoch 2/3, Average Loss: 0.6956\n",
      "Epoch 3/3, Average Loss: 0.4921\n",
      "‚úÖ BERTweet emotion model trained and saved with seed 123\n",
      "   Accuracy: 0.1684, Macro F1: 0.0996\n",
      "\n",
      "3Ô∏è‚É£ BERTweet Multitask (Seed 123)\n",
      "üöÄ Training BERTweet multitask model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5860\n",
      "Epoch 2/3, Average Loss: 1.3214\n",
      "Epoch 3/3, Average Loss: 1.1987\n",
      "BERTweet multitask model trained and saved with seed 123\n",
      "   Sentiment - Accuracy: 0.6000, F1: 0.3988\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.0702\n",
      "   Combined - Accuracy: 0.4263, F1: 0.2345\n",
      "\n",
      "‚úÖ Completed evaluation for seed 123\n",
      "\n",
      "üå± TRAINING AND EVALUATING BERTWEET WITH SEED 456\n",
      "------------------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ BERTweet Sentiment (Seed 456)\n",
      "üöÄ Training BERTweet sentiment model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.8234\n",
      "Epoch 2/3, Average Loss: 0.4725\n",
      "Epoch 3/3, Average Loss: 0.3779\n",
      "‚úÖ BERTweet sentiment model trained and saved with seed 456\n",
      "   Accuracy: 0.6105, Macro F1: 0.4123\n",
      "\n",
      "2Ô∏è‚É£ BERTweet Emotion (Seed 456)\n",
      "üöÄ Training BERTweet emotion model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3945\n",
      "Epoch 2/3, Average Loss: 0.7019\n",
      "Epoch 3/3, Average Loss: 0.4818\n",
      "‚úÖ BERTweet emotion model trained and saved with seed 456\n",
      "   Accuracy: 0.1579, Macro F1: 0.0937\n",
      "\n",
      "3Ô∏è‚É£ BERTweet Multitask (Seed 456)\n",
      "üöÄ Training BERTweet multitask model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.6678\n",
      "Epoch 2/3, Average Loss: 1.5130\n",
      "Epoch 3/3, Average Loss: 1.4590\n",
      "BERTweet multitask model trained and saved with seed 456\n",
      "   Sentiment - Accuracy: 0.5474, F1: 0.2358\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.0672\n",
      "   Combined - Accuracy: 0.4000, F1: 0.1515\n",
      "\n",
      "‚úÖ Completed evaluation for seed 456\n",
      "\n",
      "üå± TRAINING AND EVALUATING BERTWEET WITH SEED 789\n",
      "------------------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ BERTweet Sentiment (Seed 789)\n",
      "üöÄ Training BERTweet sentiment model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.8127\n",
      "Epoch 2/3, Average Loss: 0.4849\n",
      "Epoch 3/3, Average Loss: 0.3785\n",
      "‚úÖ BERTweet sentiment model trained and saved with seed 789\n",
      "   Accuracy: 0.5895, Macro F1: 0.3846\n",
      "\n",
      "2Ô∏è‚É£ BERTweet Emotion (Seed 789)\n",
      "üöÄ Training BERTweet emotion model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3752\n",
      "Epoch 2/3, Average Loss: 0.6841\n",
      "Epoch 3/3, Average Loss: 0.4946\n",
      "‚úÖ BERTweet emotion model trained and saved with seed 789\n",
      "   Accuracy: 0.1579, Macro F1: 0.0944\n",
      "\n",
      "3Ô∏è‚É£ BERTweet Multitask (Seed 789)\n",
      "üöÄ Training BERTweet multitask model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.6214\n",
      "Epoch 2/3, Average Loss: 1.2824\n",
      "Epoch 3/3, Average Loss: 1.1796\n",
      "BERTweet multitask model trained and saved with seed 789\n",
      "   Sentiment - Accuracy: 0.5579, F1: 0.3885\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.0672\n",
      "   Combined - Accuracy: 0.4053, F1: 0.2279\n",
      "\n",
      "‚úÖ Completed evaluation for seed 789\n",
      "\n",
      "üå± TRAINING AND EVALUATING BERTWEET WITH SEED 999\n",
      "------------------------------------------------------------\n",
      "\n",
      "1Ô∏è‚É£ BERTweet Sentiment (Seed 999)\n",
      "üöÄ Training BERTweet sentiment model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.9292\n",
      "Epoch 2/3, Average Loss: 0.9331\n",
      "Epoch 3/3, Average Loss: 0.9326\n",
      "‚úÖ BERTweet sentiment model trained and saved with seed 999\n",
      "   Accuracy: 0.2632, Macro F1: 0.1725\n",
      "\n",
      "2Ô∏è‚É£ BERTweet Emotion (Seed 999)\n",
      "üöÄ Training BERTweet emotion model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3259\n",
      "Epoch 2/3, Average Loss: 0.6866\n",
      "Epoch 3/3, Average Loss: 0.4806\n",
      "‚úÖ BERTweet emotion model trained and saved with seed 999\n",
      "   Accuracy: 0.1789, Macro F1: 0.1019\n",
      "\n",
      "3Ô∏è‚É£ BERTweet Multitask (Seed 999)\n",
      "üöÄ Training BERTweet multitask model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5872\n",
      "Epoch 2/3, Average Loss: 1.3075\n",
      "Epoch 3/3, Average Loss: 1.1884\n",
      "BERTweet multitask model trained and saved with seed 999\n",
      "   Sentiment - Accuracy: 0.5684, F1: 0.3300\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.1043\n",
      "   Combined - Accuracy: 0.4105, F1: 0.2172\n",
      "\n",
      "‚úÖ Completed evaluation for seed 999\n",
      "\n",
      "üìä ANALYZING BERTWEET STABILITY ACROSS SEEDS\n",
      "======================================================================\n",
      "\n",
      "üîç BERTWEET_SENTIMENT - SENTIMENT\n",
      "   Accuracy: 0.5347 ¬± 0.1360\n",
      "   Macro F1: 0.3561 ¬± 0.0923\n",
      "\n",
      "üîç BERTWEET_EMOTION - EMOTION\n",
      "   Accuracy: 0.1642 ¬± 0.0084\n",
      "   Macro F1: 0.0967 ¬± 0.0034\n",
      "\n",
      "üîç BERTWEET_MULTITASK - SENTIMENT\n",
      "   Accuracy: 0.5768 ¬± 0.0244\n",
      "   Macro F1: 0.3537 ¬± 0.0656\n",
      "\n",
      "üîç BERTWEET_MULTITASK - EMOTION\n",
      "   Accuracy: 0.2589 ¬± 0.0126\n",
      "   Macro F1: 0.0868 ¬± 0.0237\n",
      "‚ùå Error during analysis: Object of type ndarray is not JSON serializable\n",
      "üîß Try restarting the kernel and running cells 1-9 again.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# Run BERTweet random seed analysis with the fixed saving function\n",
    "try:\n",
    "    all_results, stability_analysis = run_bertweet_seed_analysis(\n",
    "        reddit_data_path=\"annotated_reddit_posts.csv\",\n",
    "        seeds=[42, 123, 456, 789, 999],  # 5 different seeds\n",
    "        max_training_samples=3000  # Reduced for faster training\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéâ BERTWEET RANDOM SEED ANALYSIS COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Check the './bertweet_seed_analysis_results/' directory for detailed results.\")\n",
    "    \n",
    "    # Display quick summary\n",
    "    print(\"\\nüìä QUICK STABILITY SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for model_name in ['BERTWEET_SENTIMENT', 'BERTWEET_EMOTION', 'BERTWEET_MULTITASK']:\n",
    "        if model_name in stability_analysis:\n",
    "            print(f\"\\n{model_name}:\")\n",
    "            for task in ['sentiment', 'emotion']:\n",
    "                if task in stability_analysis[model_name]:\n",
    "                    metrics = stability_analysis[model_name][task]\n",
    "                    print(f\"  {task.title()}:\")\n",
    "                    print(f\"    Accuracy: {metrics.get('accuracy_mean', 0):.3f} ¬± {metrics.get('accuracy_std', 0):.3f}\")\n",
    "                    print(f\"    F1 Score: {metrics.get('f1_mean', 0):.3f} ¬± {metrics.get('f1_std', 0):.3f}\")\n",
    "                    print(f\"    Stability: {metrics.get('stability_score', 0):.3f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during analysis: {str(e)}\")\n",
    "    print(\"üîß Try restarting the kernel and running cells 1-9 again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
