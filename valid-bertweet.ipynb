{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ebee31",
   "metadata": {},
   "source": [
    "# General Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e5dbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "âœ… Libraries imported and setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports for BERTweet Seed & Bootstrap Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, AutoConfig,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import random\n",
    "from collections import Counter\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"./bertweet_seed_analysis_results\", exist_ok=True)\n",
    "os.makedirs(\"./bertweet_trained_models_seeds\", exist_ok=True)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "print(\"âœ… Libraries imported and setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95fc10fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Utility Functions for Analysis\n",
    "def set_random_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def clear_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def print_memory_usage():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f} GB, Cached: {cached:.2f} GB\")\n",
    "\n",
    "print(\"Utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee15564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet model architectures defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: BERTweet Model Architectures\n",
    "class BERTweetSingleTaskTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"vinai/bertweet-base\",\n",
    "        num_classes: int = 3,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load BERTweet model\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        self.bertweet = AutoModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        # Classification head\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(self.bertweet.config.hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERTweet outputs\n",
    "        outputs = self.bertweet(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return {'logits': logits}\n",
    "\n",
    "class BERTweetMultiTaskTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"vinai/bertweet-base\",\n",
    "        sentiment_num_classes: int = 3,\n",
    "        emotion_num_classes: int = 6,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sentiment_num_classes = sentiment_num_classes\n",
    "        self.emotion_num_classes = emotion_num_classes\n",
    "        \n",
    "        # Load BERTweet model\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        self.bertweet = AutoModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        hidden_size = self.bertweet.config.hidden_size\n",
    "        \n",
    "        # Task-specific attention layers\n",
    "        self.sentiment_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.emotion_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Shared attention for common features\n",
    "        self.shared_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.sentiment_norm = nn.LayerNorm(hidden_size)\n",
    "        self.emotion_norm = nn.LayerNorm(hidden_size)\n",
    "        self.shared_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.sentiment_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.emotion_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.shared_dropout = nn.Dropout(classifier_dropout)\n",
    "        \n",
    "        # Classification heads\n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, sentiment_num_classes)\n",
    "        )\n",
    "        \n",
    "        self.emotion_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, emotion_num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in [self.sentiment_classifier, self.emotion_classifier]:\n",
    "            for layer in module:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        # Shared encoder\n",
    "        encoder_outputs = self.bertweet(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        sequence_output = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply shared attention\n",
    "        shared_attended, _ = self.shared_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        shared_attended = self.shared_norm(shared_attended + sequence_output)\n",
    "        shared_attended = self.shared_dropout(shared_attended)\n",
    "        shared_pooled = shared_attended[:, 0, :]\n",
    "        \n",
    "        outputs = {}\n",
    "        \n",
    "        # Sentiment branch\n",
    "        sentiment_attended, _ = self.sentiment_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        sentiment_attended = self.sentiment_norm(sentiment_attended + sequence_output)\n",
    "        sentiment_attended = self.sentiment_dropout(sentiment_attended)\n",
    "        sentiment_pooled = sentiment_attended[:, 0, :]\n",
    "        sentiment_features = torch.cat([shared_pooled, sentiment_pooled], dim=-1)\n",
    "        sentiment_logits = self.sentiment_classifier(sentiment_features)\n",
    "        outputs[\"sentiment_logits\"] = sentiment_logits\n",
    "        \n",
    "        # Emotion branch\n",
    "        emotion_attended, _ = self.emotion_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        emotion_attended = self.emotion_norm(emotion_attended + sequence_output)\n",
    "        emotion_attended = self.emotion_dropout(emotion_attended)\n",
    "        emotion_pooled = emotion_attended[:, 0, :]\n",
    "        emotion_features = torch.cat([shared_pooled, emotion_pooled], dim=-1)\n",
    "        emotion_logits = self.emotion_classifier(emotion_features)\n",
    "        outputs[\"emotion_logits\"] = emotion_logits\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "print(\"BERTweet model architectures defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84190c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet dataset classes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Dataset Classes for BERTweet\n",
    "class BERTweetDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer, max_length: int = 128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class BERTweetMultiTaskDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], sentiment_labels: List[int], \n",
    "                 emotion_labels: List[int], tokenizer, max_length: int = 128):\n",
    "        self.texts = texts\n",
    "        self.sentiment_labels = sentiment_labels\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        sentiment_label = self.sentiment_labels[idx]\n",
    "        emotion_label = self.emotion_labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'sentiment_labels': torch.tensor(sentiment_label, dtype=torch.long),\n",
    "            'emotion_labels': torch.tensor(emotion_label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"BERTweet dataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3feded95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modified data loading functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Modified Data Loading Functions for General Dataset Evaluation\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "def load_external_datasets() -> Tuple[Dict, Dict]:\n",
    "    print(\"Loading external datasets...\")\n",
    "    \n",
    "    # Load SST-2 for sentiment\n",
    "    try:\n",
    "        sst2_dataset = load_dataset(\"sst2\")\n",
    "        sentiment_data = {\n",
    "            'train': sst2_dataset['train'],\n",
    "            'validation': sst2_dataset['validation']\n",
    "        }\n",
    "        print(f\"âœ… SST-2 dataset loaded: {len(sentiment_data['train'])} train, {len(sentiment_data['validation'])} validation samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Could not load SST-2: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Load GoEmotions for emotion\n",
    "    try:\n",
    "        emotions_dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "        emotion_data = {\n",
    "            'train': emotions_dataset['train'],\n",
    "            'validation': emotions_dataset['validation'],\n",
    "            'test': emotions_dataset['test']  # GoEmotions has a test split\n",
    "        }\n",
    "        print(f\"âœ… GoEmotions dataset loaded: {len(emotion_data['train'])} train, {len(emotion_data['validation'])} validation, {len(emotion_data['test'])} test samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Could not load GoEmotions: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return sentiment_data, emotion_data\n",
    "\n",
    "def prepare_sst2_evaluation_data(sentiment_data: Dict, max_samples: int = 1000) -> Dict:\n",
    "    \"\"\"Prepare SST-2 validation data for evaluation\"\"\"\n",
    "    print(\"Preparing SST-2 evaluation data...\")\n",
    "    \n",
    "    # Use validation split for evaluation\n",
    "    eval_texts = sentiment_data['validation']['sentence'][:max_samples]\n",
    "    eval_labels_raw = sentiment_data['validation']['label'][:max_samples]\n",
    "    \n",
    "    # Convert SST-2 binary to 3-class sentiment (same as training)\n",
    "    eval_labels = []\n",
    "    for label in eval_labels_raw:\n",
    "        if label == 0:  # Negative\n",
    "            eval_labels.append(0)\n",
    "        elif label == 1:  # Positive\n",
    "            if np.random.random() < 0.15:  # 15% chance to be neutral (same as training)\n",
    "                eval_labels.append(1)  # Neutral\n",
    "            else:\n",
    "                eval_labels.append(2)  # Positive\n",
    "    \n",
    "    # Create encoder that matches training\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    sentiment_encoder.classes_ = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "    \n",
    "    sst2_eval_data = {\n",
    "        'texts': eval_texts,\n",
    "        'sentiment_labels': eval_labels,\n",
    "        'sentiment_encoder': sentiment_encoder\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… SST-2 evaluation data prepared: {len(sst2_eval_data['texts'])} samples\")\n",
    "    print(f\"   Sentiment classes: {list(sentiment_encoder.classes_)}\")\n",
    "    \n",
    "    return sst2_eval_data\n",
    "\n",
    "def prepare_goemotions_evaluation_data(emotion_data: Dict, max_samples: int = 1000) -> Dict:\n",
    "    \"\"\"Prepare GoEmotions test data for evaluation\"\"\"\n",
    "    print(\"Preparing GoEmotions evaluation data...\")\n",
    "    \n",
    "    # Use test split for evaluation (or validation if test not available)\n",
    "    eval_split = emotion_data.get('test', emotion_data.get('validation'))\n",
    "    eval_texts_all = eval_split['text']\n",
    "    eval_labels_all = eval_split['labels']\n",
    "    \n",
    "    eval_texts = []\n",
    "    eval_labels = []\n",
    "    count = 0\n",
    "    \n",
    "    for i, label in enumerate(eval_labels_all):\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "        if isinstance(label, list):\n",
    "            if label and label[0] in range(6):\n",
    "                eval_texts.append(eval_texts_all[i])\n",
    "                eval_labels.append(label[0])\n",
    "                count += 1\n",
    "        else:\n",
    "            if label in range(6):\n",
    "                eval_texts.append(eval_texts_all[i])\n",
    "                eval_labels.append(label)\n",
    "                count += 1\n",
    "    \n",
    "    # Create encoder that matches training\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    emotion_encoder.classes_ = np.array(['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise'])\n",
    "    \n",
    "    goemotions_eval_data = {\n",
    "        'texts': eval_texts,\n",
    "        'emotion_labels': eval_labels,\n",
    "        'emotion_encoder': emotion_encoder\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… GoEmotions evaluation data prepared: {len(goemotions_eval_data['texts'])} samples\")\n",
    "    print(f\"   Emotion classes: {list(emotion_encoder.classes_)}\")\n",
    "    \n",
    "    return goemotions_eval_data\n",
    "\n",
    "def prepare_multitask_evaluation_data(sst2_eval_data: Dict, goemotions_eval_data: Dict) -> Dict:\n",
    "    \"\"\"Prepare combined evaluation data for multitask model\"\"\"\n",
    "    print(\"Preparing multitask evaluation data...\")\n",
    "    \n",
    "    # Take minimum length to ensure both tasks have same number of samples\n",
    "    min_length = min(len(sst2_eval_data['texts']), len(goemotions_eval_data['texts']))\n",
    "    \n",
    "    multitask_eval_data = {\n",
    "        'texts': sst2_eval_data['texts'][:min_length],\n",
    "        'sentiment_labels': sst2_eval_data['sentiment_labels'][:min_length],\n",
    "        'emotion_labels': goemotions_eval_data['emotion_labels'][:min_length],\n",
    "        'sentiment_encoder': sst2_eval_data['sentiment_encoder'],\n",
    "        'emotion_encoder': goemotions_eval_data['emotion_encoder']\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Multitask evaluation data prepared: {len(multitask_eval_data['texts'])} samples\")\n",
    "    \n",
    "    return multitask_eval_data\n",
    "\n",
    "def prepare_bertweet_training_data(sentiment_data: Dict, emotion_data: Dict, max_samples: int = 3000) -> Dict:\n",
    "    print(\"Preparing BERTweet training data...\")\n",
    "    \n",
    "    # Process sentiment data (SST-2)\n",
    "    sentiment_texts = sentiment_data['train']['sentence'][:max_samples]\n",
    "    sentiment_labels = sentiment_data['train']['label'][:max_samples]\n",
    "    \n",
    "    # Process emotion data (filter to first 6 classes)\n",
    "    emotion_texts = []\n",
    "    emotion_labels = []\n",
    "    count = 0\n",
    "    \n",
    "    for i, label in enumerate(emotion_data['train']['labels']):\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "        if isinstance(label, list):\n",
    "            if label and label[0] in range(6):  # Only use first 6 emotions\n",
    "                emotion_texts.append(emotion_data['train']['text'][i])\n",
    "                emotion_labels.append(label[0])\n",
    "                count += 1\n",
    "        else:\n",
    "            if label in range(6):\n",
    "                emotion_texts.append(emotion_data['train']['text'][i])\n",
    "                emotion_labels.append(label)\n",
    "                count += 1\n",
    "    \n",
    "    # Create encoders\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    \n",
    "    # For SST-2: 0 = Negative, 1 = Positive\n",
    "    sentiment_encoder.classes_ = np.array(['Negative', 'Positive'])\n",
    "    \n",
    "    # For GoEmotions: First 6 emotions\n",
    "    emotion_encoder.classes_ = np.array(['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise'])\n",
    "    \n",
    "    training_data = {\n",
    "        'sentiment_data': {\n",
    "            'texts': sentiment_texts,\n",
    "            'labels': sentiment_labels,\n",
    "            'encoder': sentiment_encoder\n",
    "        },\n",
    "        'emotion_data': {\n",
    "            'texts': emotion_texts,\n",
    "            'labels': emotion_labels,\n",
    "            'encoder': emotion_encoder\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Training data prepared:\")\n",
    "    print(f\"   Sentiment: {len(sentiment_texts)} samples\")\n",
    "    print(f\"   Sentiment classes: {list(sentiment_encoder.classes_)}\")\n",
    "    print(f\"   Emotion: {len(emotion_texts)} samples\")\n",
    "    print(f\"   Emotion classes: {list(emotion_encoder.classes_)}\")\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "print(\"âœ… Modified data loading functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82afd1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet training functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: BERTweet Training Functions with Best Parameters\n",
    "def train_bertweet_single_task(\n",
    "    task_type: str,  # 'sentiment' or 'emotion'\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    training_data: Dict,\n",
    "    max_samples: int = 5000\n",
    ") -> Tuple[any, LabelEncoder]:\n",
    "    \n",
    "    print(f\"ðŸš€ Training BERTweet {task_type} model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Get appropriate data\n",
    "    if task_type == 'sentiment':\n",
    "        texts = training_data['sentiment_data']['texts'][:max_samples]\n",
    "        labels = training_data['sentiment_data']['labels'][:max_samples]\n",
    "        encoder = training_data['sentiment_data']['encoder']\n",
    "        num_classes = 3\n",
    "    else:  # emotion\n",
    "        texts = training_data['emotion_data']['texts'][:max_samples]\n",
    "        labels = training_data['emotion_data']['labels'][:max_samples]\n",
    "        encoder = training_data['emotion_data']['encoder']\n",
    "        num_classes = 6\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model\n",
    "    model = BERTweetSingleTaskTransformer(\n",
    "        model_name='vinai/bertweet-base',\n",
    "        num_classes=num_classes,\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        attention_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = BERTweetDataset(texts, labels, tokenizer, max_length=128)\n",
    "    dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    total_steps = len(dataloader) * 3  # 3 epochs\n",
    "    warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    print(f\"Starting training for 3 epochs...\")\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels_batch = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs['logits'], labels_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/3, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    output_dir = f\"./bertweet_trained_models_seeds/bertweet_{task_type}_seed_{seed}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model state dict\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "    \n",
    "    # Save config\n",
    "    config = {\n",
    "        \"model_name\": \"vinai/bertweet-base\",\n",
    "        \"num_classes\": num_classes,\n",
    "        \"task_type\": task_type,\n",
    "        \"model_type\": \"BERTweetSingleTaskTransformer\"\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"config.json\"), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save tokenizer and encoder\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(encoder, os.path.join(output_dir, f'{task_type}_encoder.pkl'))\n",
    "    \n",
    "    print(f\"âœ… BERTweet {task_type} model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, encoder\n",
    "\n",
    "def train_bertweet_multitask(\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    training_data: Dict,\n",
    "    max_samples: int = 2000\n",
    ") -> Tuple[any, LabelEncoder, LabelEncoder]:\n",
    "    \n",
    "    print(f\"ðŸš€ Training BERTweet multitask model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Prepare multitask data (combine sentiment and emotion data)\n",
    "    min_length = min(len(training_data['sentiment_data']['texts']), \n",
    "                     len(training_data['emotion_data']['texts']))\n",
    "    min_length = min(min_length, max_samples)\n",
    "    \n",
    "    combined_texts = training_data['sentiment_data']['texts'][:min_length]\n",
    "    combined_sentiment_labels = training_data['sentiment_data']['labels'][:min_length]\n",
    "    combined_emotion_labels = training_data['emotion_data']['labels'][:min_length]\n",
    "    \n",
    "    sentiment_encoder = training_data['sentiment_data']['encoder']\n",
    "    emotion_encoder = training_data['emotion_data']['encoder']\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model\n",
    "    model = BERTweetMultiTaskTransformer(\n",
    "        model_name='vinai/bertweet-base',\n",
    "        sentiment_num_classes=3,\n",
    "        emotion_num_classes=6,\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        attention_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = BERTweetMultiTaskDataset(\n",
    "        combined_texts, combined_sentiment_labels, combined_emotion_labels, \n",
    "        tokenizer, max_length=128\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    total_steps = len(dataloader) * 3  # 3 epochs\n",
    "    warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Loss functions\n",
    "    sentiment_criterion = nn.CrossEntropyLoss()\n",
    "    emotion_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    alpha = best_params['alpha']\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    print(f\"Starting training for 3 epochs...\")\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            sentiment_labels = batch['sentiment_labels'].to(device)\n",
    "            emotion_labels = batch['emotion_labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Calculate losses\n",
    "            sentiment_loss = sentiment_criterion(outputs['sentiment_logits'], sentiment_labels)\n",
    "            emotion_loss = emotion_criterion(outputs['emotion_logits'], emotion_labels)\n",
    "            \n",
    "            # Combined loss\n",
    "            total_loss_batch = alpha * sentiment_loss + (1 - alpha) * emotion_loss\n",
    "            total_loss += total_loss_batch.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/3, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    output_dir = f\"./bertweet_trained_models_seeds/bertweet_multitask_seed_{seed}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model state dict\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "    \n",
    "    # Save config\n",
    "    config = {\n",
    "        \"model_name\": \"vinai/bertweet-base\",\n",
    "        \"sentiment_num_classes\": 3,\n",
    "        \"emotion_num_classes\": 6,\n",
    "        \"model_type\": \"BERTweetMultiTaskTransformer\"\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"config.json\"), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save tokenizer and encoders\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(sentiment_encoder, os.path.join(output_dir, 'sentiment_encoder.pkl'))\n",
    "    joblib.dump(emotion_encoder, os.path.join(output_dir, 'emotion_encoder.pkl'))\n",
    "    \n",
    "    print(f\"BERTweet multitask model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, sentiment_encoder, emotion_encoder\n",
    "\n",
    "print(\"BERTweet training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d9d59bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Evaluation Functions for BERTweet Models\n",
    "def evaluate_bertweet_single_task(model, tokenizer, label_encoder, reddit_data: Dict, task_type: str) -> Dict:\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_labels = reddit_data[f'{task_type}_labels']\n",
    "    \n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 16):  # Batch size 16\n",
    "            batch_texts = texts[i:i+16]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=128\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items() if k in ['input_ids', 'attention_mask']}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs['logits']\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                pred_id = preds[j].item()\n",
    "                confidence = probs[j][pred_id].item()\n",
    "                \n",
    "                # Handle out of range predictions\n",
    "                if pred_id >= len(label_encoder.classes_):\n",
    "                    pred_id = 0\n",
    "                \n",
    "                predictions.append(pred_id)\n",
    "                confidences.append(confidence)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    macro_f1 = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'predictions': predictions,\n",
    "        'confidences': confidences,\n",
    "        'true_labels': true_labels\n",
    "    }\n",
    "\n",
    "def evaluate_bertweet_multitask(model, tokenizer, sentiment_encoder, emotion_encoder, \n",
    "                               reddit_data: Dict, max_length: int = 128) -> Dict:\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_sentiment_labels = reddit_data['sentiment_labels']\n",
    "    true_emotion_labels = reddit_data['emotion_labels']\n",
    "    \n",
    "    sentiment_predictions = []\n",
    "    emotion_predictions = []\n",
    "    sentiment_confidences = []\n",
    "    emotion_confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 8):  # Smaller batch size for multitask\n",
    "            batch_texts = texts[i:i+8]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=max_length\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items() if k in ['input_ids', 'attention_mask']}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            # Process sentiment\n",
    "            sentiment_logits = outputs['sentiment_logits']\n",
    "            sentiment_probs = F.softmax(sentiment_logits, dim=-1)\n",
    "            sentiment_preds = torch.argmax(sentiment_logits, dim=-1)\n",
    "            \n",
    "            # Process emotion\n",
    "            emotion_logits = outputs['emotion_logits']\n",
    "            emotion_probs = F.softmax(emotion_logits, dim=-1)\n",
    "            emotion_preds = torch.argmax(emotion_logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                # Sentiment\n",
    "                sent_id = sentiment_preds[j].item()\n",
    "                sent_conf = sentiment_probs[j][sent_id].item()\n",
    "                if sent_id >= len(sentiment_encoder.classes_):\n",
    "                    sent_id = 0\n",
    "                sentiment_predictions.append(sent_id)\n",
    "                sentiment_confidences.append(sent_conf)\n",
    "                \n",
    "                # Emotion\n",
    "                emot_id = emotion_preds[j].item()\n",
    "                emot_conf = emotion_probs[j][emot_id].item()\n",
    "                if emot_id >= len(emotion_encoder.classes_):\n",
    "                    emot_id = 0\n",
    "                emotion_predictions.append(emot_id)\n",
    "                emotion_confidences.append(emot_conf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    sentiment_accuracy = accuracy_score(true_sentiment_labels, sentiment_predictions)\n",
    "    sentiment_f1 = f1_score(true_sentiment_labels, sentiment_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    emotion_accuracy = accuracy_score(true_emotion_labels, emotion_predictions)\n",
    "    emotion_f1 = f1_score(true_emotion_labels, emotion_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'sentiment': {\n",
    "            'accuracy': sentiment_accuracy,\n",
    "            'macro_f1': sentiment_f1,\n",
    "            'predictions': sentiment_predictions,\n",
    "            'confidences': sentiment_confidences\n",
    "        },\n",
    "        'emotion': {\n",
    "            'accuracy': emotion_accuracy,\n",
    "            'macro_f1': emotion_f1,\n",
    "            'predictions': emotion_predictions,\n",
    "            'confidences': emotion_confidences\n",
    "        },\n",
    "        'combined_accuracy': (sentiment_accuracy + emotion_accuracy) / 2,\n",
    "        'combined_f1': (sentiment_f1 + emotion_f1) / 2\n",
    "    }\n",
    "\n",
    "print(\"BERTweet evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1097d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modified BERTweet random seed analysis function defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Modified BERTweet Random Seed Analysis Function\n",
    "def run_bertweet_seed_analysis(\n",
    "    seeds: List[int] = [42, 123, 456, 789, 999],\n",
    "    max_training_samples: int = 3000,\n",
    "    max_eval_samples: int = 1000\n",
    "):\n",
    "    \n",
    "    print(\"ðŸŽ² STARTING BERTWEET RANDOM SEED ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Seeds to test: {seeds}\")\n",
    "    print(f\"Max training samples per dataset: {max_training_samples}\")\n",
    "    print(f\"Max evaluation samples per dataset: {max_eval_samples}\")\n",
    "    \n",
    "    # Load external datasets\n",
    "    print(\"\\nðŸ“‚ Loading external datasets...\")\n",
    "    sentiment_data, emotion_data = load_external_datasets()\n",
    "    \n",
    "    # Prepare training data\n",
    "    print(\"\\nðŸ”„ Preparing BERTweet training data...\")\n",
    "    training_data = prepare_bertweet_training_data(sentiment_data, emotion_data, max_training_samples)\n",
    "    \n",
    "    # Prepare evaluation data\n",
    "    print(\"\\nðŸ“‚ Preparing evaluation datasets...\")\n",
    "    sst2_eval_data = prepare_sst2_evaluation_data(sentiment_data, max_eval_samples)\n",
    "    goemotions_eval_data = prepare_goemotions_evaluation_data(emotion_data, max_eval_samples)\n",
    "    multitask_eval_data = prepare_multitask_evaluation_data(sst2_eval_data, goemotions_eval_data)\n",
    "    \n",
    "    # Define best parameters for each BERTweet model\n",
    "    best_params = {\n",
    "        'sentiment': {\n",
    "            'learning_rate': 3.65445235521325e-05,\n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.15986584841970367,\n",
    "            'weight_decay': 0.02404167763981929,\n",
    "            'hidden_dropout_prob': 0.13119890406724052,\n",
    "            'classifier_dropout': 0.1116167224336399\n",
    "        },\n",
    "        'emotion': {\n",
    "            'learning_rate': 3.65445235521325e-05, \n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.15986584841970367,\n",
    "            'weight_decay': 0.02404167763981929,\n",
    "            'hidden_dropout_prob': 0.13119890406724052,\n",
    "            'classifier_dropout': 0.1116167224336399\n",
    "        },\n",
    "        'multitask': {\n",
    "            'learning_rate': 4.166863122305896e-05,\n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.15142344384136117,\n",
    "            'weight_decay': 0.06331731119758383,\n",
    "            'hidden_dropout_prob': 0.10929008254399955,\n",
    "            'classifier_dropout': 0.22150897038028766,\n",
    "            'alpha': 0.4341048247374583\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    # Store results for each seed\n",
    "    all_results = {}\n",
    "    \n",
    "    for seed in seeds:\n",
    "        print(f\"\\nðŸŒ± TRAINING AND EVALUATING BERTWEET WITH SEED {seed}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        seed_results = {}\n",
    "        \n",
    "        # 1. Train and evaluate BERTweet Sentiment on SST-2\n",
    "        print(f\"\\n1ï¸âƒ£ BERTweet Sentiment on SST-2 (Seed {seed})\")\n",
    "        model, encoder = train_bertweet_single_task(\n",
    "            'sentiment', best_params['sentiment'], seed, \n",
    "            training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_sentiment_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate on SST-2 validation set\n",
    "        results = evaluate_bertweet_single_task(model, tokenizer, encoder, sst2_eval_data, 'sentiment')\n",
    "        seed_results['bertweet_sentiment'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 2. Train and evaluate BERTweet Emotion on GoEmotions\n",
    "        print(f\"\\n2ï¸âƒ£ BERTweet Emotion on GoEmotions (Seed {seed})\")\n",
    "        model, encoder = train_bertweet_single_task(\n",
    "            'emotion', best_params['emotion'], seed,\n",
    "            training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_emotion_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate on GoEmotions test set\n",
    "        results = evaluate_bertweet_single_task(model, tokenizer, encoder, goemotions_eval_data, 'emotion')\n",
    "        seed_results['bertweet_emotion'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 3. Train and evaluate BERTweet Multitask on both datasets\n",
    "        print(f\"\\n3ï¸âƒ£ BERTweet Multitask on SST-2 + GoEmotions (Seed {seed})\")\n",
    "        model, sent_enc, emot_enc = train_bertweet_multitask(\n",
    "            best_params['multitask'], seed, training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_multitask_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate on combined test sets\n",
    "        results = evaluate_bertweet_multitask(\n",
    "            model, tokenizer, sent_enc, emot_enc, multitask_eval_data, 128\n",
    "        )\n",
    "        seed_results['bertweet_multitask'] = results\n",
    "        print(f\"   Sentiment - Accuracy: {results['sentiment']['accuracy']:.4f}, F1: {results['sentiment']['macro_f1']:.4f}\")\n",
    "        print(f\"   Emotion - Accuracy: {results['emotion']['accuracy']:.4f}, F1: {results['emotion']['macro_f1']:.4f}\")\n",
    "        print(f\"   Combined - Accuracy: {results['combined_accuracy']:.4f}, F1: {results['combined_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        all_results[seed] = seed_results\n",
    "        \n",
    "        print(f\"\\nâœ… Completed evaluation for seed {seed}\")\n",
    "    \n",
    "    # Analyze stability across seeds\n",
    "    print(f\"\\nðŸ“Š ANALYZING BERTWEET STABILITY ACROSS SEEDS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    stability_analysis = analyze_bertweet_seed_stability(all_results, seeds)\n",
    "    \n",
    "    # Save results\n",
    "    save_bertweet_results(all_results, stability_analysis, seeds)\n",
    "    \n",
    "    return all_results, stability_analysis\n",
    "\n",
    "print(\"âœ… Modified BERTweet random seed analysis function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05c3b9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet stability analysis functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: BERTweet Stability Analysis Functions\n",
    "def analyze_bertweet_seed_stability(all_results: Dict, seeds: List[int]) -> Dict:\n",
    "    \n",
    "    stability_stats = {}\n",
    "    \n",
    "    # Define model-task combinations\n",
    "    evaluations = [\n",
    "        ('bertweet_sentiment', 'sentiment'),\n",
    "        ('bertweet_emotion', 'emotion'),\n",
    "        ('bertweet_multitask', 'sentiment'),\n",
    "        ('bertweet_multitask', 'emotion')\n",
    "    ]\n",
    "    \n",
    "    for model_name, task in evaluations:\n",
    "        print(f\"\\nðŸ” {model_name.upper()} - {task.upper()}\")\n",
    "        \n",
    "        accuracies = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        for seed in seeds:\n",
    "            if model_name in all_results[seed]:\n",
    "                result = all_results[seed][model_name]\n",
    "                \n",
    "                if model_name.endswith('_multitask'):\n",
    "                    acc = result[task]['accuracy']\n",
    "                    f1 = result[task]['macro_f1']\n",
    "                else:\n",
    "                    acc = result['accuracy']\n",
    "                    f1 = result['macro_f1']\n",
    "                \n",
    "                accuracies.append(acc)\n",
    "                f1_scores.append(f1)\n",
    "        \n",
    "        if accuracies:\n",
    "            acc_mean = np.mean(accuracies)\n",
    "            acc_std = np.std(accuracies)\n",
    "            f1_mean = np.mean(f1_scores)\n",
    "            f1_std = np.std(f1_scores)\n",
    "            \n",
    "            stability_stats[f\"{model_name}_{task}\"] = {\n",
    "                'accuracy_mean': acc_mean,\n",
    "                'accuracy_std': acc_std,\n",
    "                'f1_mean': f1_mean,\n",
    "                'f1_std': f1_std,\n",
    "                'accuracy_values': accuracies,\n",
    "                'f1_values': f1_scores\n",
    "            }\n",
    "            \n",
    "            print(f\"   Accuracy: {acc_mean:.4f} Â± {acc_std:.4f}\")\n",
    "            print(f\"   Macro F1: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
    "    \n",
    "    return stability_stats\n",
    "\n",
    "def save_bertweet_results(all_results: Dict, stability_analysis: Dict, seeds: List[int]):\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save raw results\n",
    "    results_file = f\"./bertweet_seed_analysis_results/bertweet_raw_results_{timestamp}.json\"\n",
    "    with open(results_file, 'w') as f:\n",
    "        # Convert numpy types to Python types for JSON serialization\n",
    "        serializable_results = {}\n",
    "        for seed, seed_results in all_results.items():\n",
    "            serializable_results[str(seed)] = {}\n",
    "            for model, results in seed_results.items():\n",
    "                if isinstance(results, dict):\n",
    "                    serializable_results[str(seed)][model] = {}\n",
    "                    for key, value in results.items():\n",
    "                        if isinstance(value, dict):\n",
    "                            serializable_results[str(seed)][model][key] = {\n",
    "                                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                                   [float(x) if isinstance(x, (np.floating, np.integer)) else x for x in v] if isinstance(v, list) else v\n",
    "                                for k, v in value.items()\n",
    "                            }\n",
    "                        else:\n",
    "                            serializable_results[str(seed)][model][key] = float(value) if isinstance(value, (np.floating, np.integer)) else value\n",
    "        \n",
    "        json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    # Save stability analysis\n",
    "    stability_file = f\"./bertweet_seed_analysis_results/bertweet_stability_analysis_{timestamp}.json\"\n",
    "    with open(stability_file, 'w') as f:\n",
    "        serializable_stability = {}\n",
    "        for key, stats in stability_analysis.items():\n",
    "            serializable_stability[key] = {\n",
    "                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                   [float(x) for x in v] if isinstance(v, list) else v\n",
    "                for k, v in stats.items()\n",
    "            }\n",
    "        json.dump(serializable_stability, f, indent=2)\n",
    "    \n",
    "    # Create summary report\n",
    "    summary_file = f\"./bertweet_seed_analysis_results/bertweet_summary_report_{timestamp}.txt\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"BERTWEET RANDOM SEED ANALYSIS SUMMARY REPORT\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        f.write(f\"Seeds tested: {seeds}\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"STABILITY ANALYSIS (Mean Â± Std)\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        for key, stats in stability_analysis.items():\n",
    "            model_task = key.replace('_', ' ').title()\n",
    "            f.write(f\"\\n{model_task}:\\n\")\n",
    "            f.write(f\"  Accuracy: {stats['accuracy_mean']:.4f} Â± {stats['accuracy_std']:.4f}\\n\")\n",
    "            f.write(f\"  Macro F1: {stats['f1_mean']:.4f} Â± {stats['f1_std']:.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest Performers (by mean F1 score):\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        \n",
    "        # Find best performers\n",
    "        sentiment_best = max([k for k in stability_analysis.keys() if 'sentiment' in k], \n",
    "                           key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        emotion_best = max([k for k in stability_analysis.keys() if 'emotion' in k], \n",
    "                         key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        \n",
    "        f.write(f\"Sentiment: {sentiment_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[sentiment_best]['f1_mean']:.4f})\\n\")\n",
    "        f.write(f\"Emotion: {emotion_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[emotion_best]['f1_mean']:.4f})\\n\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¾ BERTweet results saved:\")\n",
    "    print(f\"   Raw results: {results_file}\")\n",
    "    print(f\"   Stability analysis: {stability_file}\")\n",
    "    print(f\"   Summary report: {summary_file}\")\n",
    "\n",
    "print(\"BERTweet stability analysis functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1784c2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ² STARTING BERTWEET RANDOM SEED ANALYSIS\n",
      "======================================================================\n",
      "Seeds to test: [42, 123, 456, 789, 999]\n",
      "Max training samples per dataset: 3000\n",
      "Max evaluation samples per dataset: 1000\n",
      "\n",
      "ðŸ“‚ Loading external datasets...\n",
      "Loading external datasets...\n",
      "âœ… SST-2 dataset loaded: 67349 train, 872 validation samples\n",
      "âœ… GoEmotions dataset loaded: 43410 train, 5426 validation, 5427 test samples\n",
      "\n",
      "ðŸ”„ Preparing BERTweet training data...\n",
      "Preparing BERTweet training data...\n",
      "âœ… Training data prepared:\n",
      "   Sentiment: 3000 samples\n",
      "   Sentiment classes: [np.str_('Negative'), np.str_('Positive')]\n",
      "   Emotion: 3000 samples\n",
      "   Emotion classes: [np.str_('Anger'), np.str_('Fear'), np.str_('Joy'), np.str_('No Emotion'), np.str_('Sadness'), np.str_('Surprise')]\n",
      "\n",
      "ðŸ“‚ Preparing evaluation datasets...\n",
      "Preparing SST-2 evaluation data...\n",
      "âœ… SST-2 evaluation data prepared: 872 samples\n",
      "   Sentiment classes: [np.str_('Negative'), np.str_('Neutral'), np.str_('Positive')]\n",
      "Preparing GoEmotions evaluation data...\n",
      "âœ… GoEmotions evaluation data prepared: 1000 samples\n",
      "   Emotion classes: [np.str_('Anger'), np.str_('Fear'), np.str_('Joy'), np.str_('No Emotion'), np.str_('Sadness'), np.str_('Surprise')]\n",
      "Preparing multitask evaluation data...\n",
      "âœ… Multitask evaluation data prepared: 872 samples\n",
      "\n",
      "ðŸŒ± TRAINING AND EVALUATING BERTWEET WITH SEED 42\n",
      "------------------------------------------------------------\n",
      "\n",
      "1ï¸âƒ£ BERTweet Sentiment on SST-2 (Seed 42)\n",
      "ðŸš€ Training BERTweet sentiment model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.5872\n",
      "Epoch 2/3, Average Loss: 0.2380\n",
      "Epoch 3/3, Average Loss: 0.1185\n",
      "âœ… BERTweet sentiment model trained and saved with seed 42\n",
      "   Accuracy: 0.5161, Macro F1: 0.3870\n",
      "\n",
      "2ï¸âƒ£ BERTweet Emotion on GoEmotions (Seed 42)\n",
      "ðŸš€ Training BERTweet emotion model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3897\n",
      "Epoch 2/3, Average Loss: 0.6943\n",
      "Epoch 3/3, Average Loss: 0.4847\n",
      "âœ… BERTweet emotion model trained and saved with seed 42\n",
      "   Accuracy: 0.7630, Macro F1: 0.7356\n",
      "\n",
      "3ï¸âƒ£ BERTweet Multitask on SST-2 + GoEmotions (Seed 42)\n",
      "ðŸš€ Training BERTweet multitask model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.4689\n",
      "Epoch 2/3, Average Loss: 1.1706\n",
      "Epoch 3/3, Average Loss: 1.0815\n",
      "BERTweet multitask model trained and saved with seed 42\n",
      "   Sentiment - Accuracy: 0.5138, F1: 0.3880\n",
      "   Emotion - Accuracy: 0.2821, F1: 0.1081\n",
      "   Combined - Accuracy: 0.3979, F1: 0.2480\n",
      "\n",
      "âœ… Completed evaluation for seed 42\n",
      "\n",
      "ðŸŒ± TRAINING AND EVALUATING BERTWEET WITH SEED 123\n",
      "------------------------------------------------------------\n",
      "\n",
      "1ï¸âƒ£ BERTweet Sentiment on SST-2 (Seed 123)\n",
      "ðŸš€ Training BERTweet sentiment model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.6605\n",
      "Epoch 2/3, Average Loss: 0.3059\n",
      "Epoch 3/3, Average Loss: 0.1587\n",
      "âœ… BERTweet sentiment model trained and saved with seed 123\n",
      "   Accuracy: 0.5034, Macro F1: 0.3844\n",
      "\n",
      "2ï¸âƒ£ BERTweet Emotion on GoEmotions (Seed 123)\n",
      "ðŸš€ Training BERTweet emotion model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3615\n",
      "Epoch 2/3, Average Loss: 0.6956\n",
      "Epoch 3/3, Average Loss: 0.4921\n",
      "âœ… BERTweet emotion model trained and saved with seed 123\n",
      "   Accuracy: 0.7590, Macro F1: 0.7324\n",
      "\n",
      "3ï¸âƒ£ BERTweet Multitask on SST-2 + GoEmotions (Seed 123)\n",
      "ðŸš€ Training BERTweet multitask model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.4639\n",
      "Epoch 2/3, Average Loss: 1.1781\n",
      "Epoch 3/3, Average Loss: 1.0722\n",
      "BERTweet multitask model trained and saved with seed 123\n",
      "   Sentiment - Accuracy: 0.5138, F1: 0.3873\n",
      "   Emotion - Accuracy: 0.2959, F1: 0.0953\n",
      "   Combined - Accuracy: 0.4048, F1: 0.2413\n",
      "\n",
      "âœ… Completed evaluation for seed 123\n",
      "\n",
      "ðŸŒ± TRAINING AND EVALUATING BERTWEET WITH SEED 456\n",
      "------------------------------------------------------------\n",
      "\n",
      "1ï¸âƒ£ BERTweet Sentiment on SST-2 (Seed 456)\n",
      "ðŸš€ Training BERTweet sentiment model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.6452\n",
      "Epoch 2/3, Average Loss: 0.2622\n",
      "Epoch 3/3, Average Loss: 0.1454\n",
      "âœ… BERTweet sentiment model trained and saved with seed 456\n",
      "   Accuracy: 0.5161, Macro F1: 0.3876\n",
      "\n",
      "2ï¸âƒ£ BERTweet Emotion on GoEmotions (Seed 456)\n",
      "ðŸš€ Training BERTweet emotion model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3945\n",
      "Epoch 2/3, Average Loss: 0.7019\n",
      "Epoch 3/3, Average Loss: 0.4818\n",
      "âœ… BERTweet emotion model trained and saved with seed 456\n",
      "   Accuracy: 0.7520, Macro F1: 0.7237\n",
      "\n",
      "3ï¸âƒ£ BERTweet Multitask on SST-2 + GoEmotions (Seed 456)\n",
      "ðŸš€ Training BERTweet multitask model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.4671\n",
      "Epoch 2/3, Average Loss: 1.1752\n",
      "Epoch 3/3, Average Loss: 1.0721\n",
      "BERTweet multitask model trained and saved with seed 456\n",
      "   Sentiment - Accuracy: 0.5092, F1: 0.3884\n",
      "   Emotion - Accuracy: 0.3131, F1: 0.0796\n",
      "   Combined - Accuracy: 0.4111, F1: 0.2340\n",
      "\n",
      "âœ… Completed evaluation for seed 456\n",
      "\n",
      "ðŸŒ± TRAINING AND EVALUATING BERTWEET WITH SEED 789\n",
      "------------------------------------------------------------\n",
      "\n",
      "1ï¸âƒ£ BERTweet Sentiment on SST-2 (Seed 789)\n",
      "ðŸš€ Training BERTweet sentiment model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.6038\n",
      "Epoch 2/3, Average Loss: 0.2392\n",
      "Epoch 3/3, Average Loss: 0.1423\n",
      "âœ… BERTweet sentiment model trained and saved with seed 789\n",
      "   Accuracy: 0.5195, Macro F1: 0.3890\n",
      "\n",
      "2ï¸âƒ£ BERTweet Emotion on GoEmotions (Seed 789)\n",
      "ðŸš€ Training BERTweet emotion model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3752\n",
      "Epoch 2/3, Average Loss: 0.6841\n",
      "Epoch 3/3, Average Loss: 0.4946\n",
      "âœ… BERTweet emotion model trained and saved with seed 789\n",
      "   Accuracy: 0.7370, Macro F1: 0.7081\n",
      "\n",
      "3ï¸âƒ£ BERTweet Multitask on SST-2 + GoEmotions (Seed 789)\n",
      "ðŸš€ Training BERTweet multitask model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5368\n",
      "Epoch 2/3, Average Loss: 1.3511\n",
      "Epoch 3/3, Average Loss: 1.2951\n",
      "BERTweet multitask model trained and saved with seed 789\n",
      "   Sentiment - Accuracy: 0.4541, F1: 0.3569\n",
      "   Emotion - Accuracy: 0.2833, F1: 0.0999\n",
      "   Combined - Accuracy: 0.3687, F1: 0.2284\n",
      "\n",
      "âœ… Completed evaluation for seed 789\n",
      "\n",
      "ðŸŒ± TRAINING AND EVALUATING BERTWEET WITH SEED 999\n",
      "------------------------------------------------------------\n",
      "\n",
      "1ï¸âƒ£ BERTweet Sentiment on SST-2 (Seed 999)\n",
      "ðŸš€ Training BERTweet sentiment model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.5978\n",
      "Epoch 2/3, Average Loss: 0.2331\n",
      "Epoch 3/3, Average Loss: 0.1184\n",
      "âœ… BERTweet sentiment model trained and saved with seed 999\n",
      "   Accuracy: 0.5172, Macro F1: 0.3887\n",
      "\n",
      "2ï¸âƒ£ BERTweet Emotion on GoEmotions (Seed 999)\n",
      "ðŸš€ Training BERTweet emotion model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3259\n",
      "Epoch 2/3, Average Loss: 0.6866\n",
      "Epoch 3/3, Average Loss: 0.4806\n",
      "âœ… BERTweet emotion model trained and saved with seed 999\n",
      "   Accuracy: 0.7500, Macro F1: 0.7276\n",
      "\n",
      "3ï¸âƒ£ BERTweet Multitask on SST-2 + GoEmotions (Seed 999)\n",
      "ðŸš€ Training BERTweet multitask model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5399\n",
      "Epoch 2/3, Average Loss: 1.3173\n",
      "Epoch 3/3, Average Loss: 1.1432\n",
      "BERTweet multitask model trained and saved with seed 999\n",
      "   Sentiment - Accuracy: 0.5046, F1: 0.3791\n",
      "   Emotion - Accuracy: 0.3119, F1: 0.0795\n",
      "   Combined - Accuracy: 0.4083, F1: 0.2293\n",
      "\n",
      "âœ… Completed evaluation for seed 999\n",
      "\n",
      "ðŸ“Š ANALYZING BERTWEET STABILITY ACROSS SEEDS\n",
      "======================================================================\n",
      "\n",
      "ðŸ” BERTWEET_SENTIMENT - SENTIMENT\n",
      "   Accuracy: 0.5144 Â± 0.0056\n",
      "   Macro F1: 0.3874 Â± 0.0016\n",
      "\n",
      "ðŸ” BERTWEET_EMOTION - EMOTION\n",
      "   Accuracy: 0.7522 Â± 0.0089\n",
      "   Macro F1: 0.7255 Â± 0.0096\n",
      "\n",
      "ðŸ” BERTWEET_MULTITASK - SENTIMENT\n",
      "   Accuracy: 0.4991 Â± 0.0227\n",
      "   Macro F1: 0.3799 Â± 0.0120\n",
      "\n",
      "ðŸ” BERTWEET_MULTITASK - EMOTION\n",
      "   Accuracy: 0.2972 Â± 0.0134\n",
      "   Macro F1: 0.0925 Â± 0.0113\n",
      "\n",
      "ðŸ’¾ BERTweet results saved:\n",
      "   Raw results: ./bertweet_seed_analysis_results/bertweet_raw_results_20250724_222657.json\n",
      "   Stability analysis: ./bertweet_seed_analysis_results/bertweet_stability_analysis_20250724_222657.json\n",
      "   Summary report: ./bertweet_seed_analysis_results/bertweet_summary_report_20250724_222657.txt\n",
      "\n",
      "ðŸŽ‰ BERTWEET RANDOM SEED ANALYSIS COMPLETED!\n",
      "============================================================\n",
      "Check the './bertweet_seed_analysis_results/' directory for detailed results.\n",
      "\n",
      "ðŸ“Š QUICK STABILITY SUMMARY:\n",
      "----------------------------------------\n",
      "\n",
      "Bertweet Sentiment Sentiment:\n",
      "  Accuracy: 0.514 Â± 0.006\n",
      "  F1 Score: 0.387 Â± 0.002\n",
      "\n",
      "Bertweet Emotion Emotion:\n",
      "  Accuracy: 0.752 Â± 0.009\n",
      "  F1 Score: 0.725 Â± 0.010\n",
      "\n",
      "Bertweet Multitask Sentiment:\n",
      "  Accuracy: 0.499 Â± 0.023\n",
      "  F1 Score: 0.380 Â± 0.012\n",
      "\n",
      "Bertweet Multitask Emotion:\n",
      "  Accuracy: 0.297 Â± 0.013\n",
      "  F1 Score: 0.092 Â± 0.011\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Run BERTweet Random Seed Analysis (Fixed)\n",
    "\n",
    "# Clear any previous results\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# Run BERTweet random seed analysis with the modified function signature\n",
    "try:\n",
    "    all_results, stability_analysis = run_bertweet_seed_analysis(\n",
    "        seeds=[42, 123, 456, 789, 999],  # 5 different seeds\n",
    "        max_training_samples=3000,  # Reduced for faster training\n",
    "        max_eval_samples=1000  # Max evaluation samples per dataset\n",
    "    )\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ BERTWEET RANDOM SEED ANALYSIS COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Check the './bertweet_seed_analysis_results/' directory for detailed results.\")\n",
    "    \n",
    "    # Display quick summary\n",
    "    print(\"\\nðŸ“Š QUICK STABILITY SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Updated to match the actual structure of stability_analysis\n",
    "    for key, stats in stability_analysis.items():\n",
    "        model_task = key.replace('_', ' ').title()\n",
    "        print(f\"\\n{model_task}:\")\n",
    "        print(f\"  Accuracy: {stats['accuracy_mean']:.3f} Â± {stats['accuracy_std']:.3f}\")\n",
    "        print(f\"  F1 Score: {stats['f1_mean']:.3f} Â± {stats['f1_std']:.3f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during analysis: {str(e)}\")\n",
    "    print(\"ðŸ”§ Try restarting the kernel and running cells 1-9 again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b729e75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet bootstrap analysis functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: BERTweet Bootstrap Analysis Functions\n",
    "def load_bertweet_model_for_bootstrap(model_path: str, model_type: str):\n",
    "    print(f\"ðŸ“¥ Loading BERTweet {model_type} model from {model_path}...\")\n",
    "    \n",
    "    # Load config\n",
    "    with open(os.path.join(model_path, 'config.json'), 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    if model_type == \"multitask\":\n",
    "        # Load multitask model\n",
    "        model = BERTweetMultiTaskTransformer(\n",
    "            model_name=\"vinai/bertweet-base\",\n",
    "            sentiment_num_classes=config['sentiment_num_classes'],\n",
    "            emotion_num_classes=config['emotion_num_classes']\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        state_dict = torch.load(os.path.join(model_path, 'pytorch_model.bin'), map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "        \n",
    "        # Load encoders\n",
    "        sentiment_encoder = joblib.load(os.path.join(model_path, 'sentiment_encoder.pkl'))\n",
    "        emotion_encoder = joblib.load(os.path.join(model_path, 'emotion_encoder.pkl'))\n",
    "        \n",
    "        return model, tokenizer, sentiment_encoder, emotion_encoder\n",
    "        \n",
    "    else:\n",
    "        # Load single-task model\n",
    "        model = BERTweetSingleTaskTransformer(\n",
    "            model_name=\"vinai/bertweet-base\",\n",
    "            num_classes=config['num_classes']\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        state_dict = torch.load(os.path.join(model_path, 'pytorch_model.bin'), map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "        \n",
    "        # Load encoder\n",
    "        encoder = joblib.load(os.path.join(model_path, f'{config[\"task_type\"]}_encoder.pkl'))\n",
    "        \n",
    "        return model, tokenizer, encoder\n",
    "\n",
    "def evaluate_bertweet_on_bootstrap_sample(model, tokenizer, texts, sentiment_labels, emotion_labels, \n",
    "                                        model_sentiment_encoder, model_emotion_encoder, \n",
    "                                        data_sentiment_encoder, data_emotion_encoder, \n",
    "                                        model_type=\"multitask\", max_length=128):\n",
    "    model.eval()\n",
    "    \n",
    "    if model_type == \"multitask\":\n",
    "        sentiment_predictions = []\n",
    "        emotion_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(texts), 8):\n",
    "                batch_texts = texts[i:i+8]\n",
    "                \n",
    "                inputs = tokenizer(\n",
    "                    batch_texts,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\",\n",
    "                    max_length=max_length\n",
    "                )\n",
    "                \n",
    "                filtered_inputs = {\n",
    "                    'input_ids': inputs['input_ids'].to(device),\n",
    "                    'attention_mask': inputs['attention_mask'].to(device)\n",
    "                }\n",
    "                \n",
    "                outputs = model(**filtered_inputs)\n",
    "                \n",
    "                sentiment_preds = torch.argmax(outputs['sentiment_logits'], dim=-1)\n",
    "                emotion_preds = torch.argmax(outputs['emotion_logits'], dim=-1)\n",
    "                \n",
    "                for j in range(len(batch_texts)):\n",
    "                    sent_id = sentiment_preds[j].item()\n",
    "                    emot_id = emotion_preds[j].item()\n",
    "                    \n",
    "                    if sent_id >= len(model_sentiment_encoder.classes_):\n",
    "                        sent_id = 0\n",
    "                    if emot_id >= len(model_emotion_encoder.classes_):\n",
    "                        emot_id = 0\n",
    "                    \n",
    "                    sentiment_predictions.append(sent_id)\n",
    "                    emotion_predictions.append(emot_id)\n",
    "        \n",
    "        # Map predictions to data label space\n",
    "        mapped_sentiment_preds = []\n",
    "        mapped_emotion_preds = []\n",
    "        \n",
    "        for sent_pred, emot_pred in zip(sentiment_predictions, emotion_predictions):\n",
    "            sent_class = model_sentiment_encoder.classes_[sent_pred]\n",
    "            emot_class = model_emotion_encoder.classes_[emot_pred]\n",
    "            \n",
    "            try:\n",
    "                mapped_sent = data_sentiment_encoder.transform([sent_class])[0]\n",
    "                mapped_emot = data_emotion_encoder.transform([emot_class])[0]\n",
    "            except ValueError:\n",
    "                mapped_sent = 0\n",
    "                mapped_emot = 0\n",
    "            \n",
    "            mapped_sentiment_preds.append(mapped_sent)\n",
    "            mapped_emotion_preds.append(mapped_emot)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sentiment_accuracy = accuracy_score(sentiment_labels, mapped_sentiment_preds)\n",
    "        sentiment_f1 = f1_score(sentiment_labels, mapped_sentiment_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        emotion_accuracy = accuracy_score(emotion_labels, mapped_emotion_preds)\n",
    "        emotion_f1 = f1_score(emotion_labels, mapped_emotion_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        return {\n",
    "            'sentiment_accuracy': sentiment_accuracy,\n",
    "            'sentiment_f1': sentiment_f1,\n",
    "            'emotion_accuracy': emotion_accuracy,\n",
    "            'emotion_f1': emotion_f1\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        # Single task evaluation logic here\n",
    "        pass\n",
    "\n",
    "def bootstrap_evaluation_bertweet(model, tokenizer, data, model_sentiment_encoder, model_emotion_encoder,\n",
    "                                data_sentiment_encoder, data_emotion_encoder, \n",
    "                                n_iterations=1000, sample_size=95):\n",
    "    print(f\"ðŸ”„ Starting BERTweet bootstrap evaluation...\")\n",
    "    print(f\"   Iterations: {n_iterations}\")\n",
    "    print(f\"   Sample size: {sample_size}\")\n",
    "    \n",
    "    results = {\n",
    "        'sentiment_accuracy': [],\n",
    "        'sentiment_f1': [],\n",
    "        'emotion_accuracy': [],\n",
    "        'emotion_f1': []\n",
    "    }\n",
    "    \n",
    "    texts = data['texts']\n",
    "    sentiment_labels = data['sentiment_labels']\n",
    "    emotion_labels = data['emotion_labels']\n",
    "    n_samples = len(texts)\n",
    "    \n",
    "    for i in tqdm(range(n_iterations), desc=\"Bootstrap iterations\"):\n",
    "        # Bootstrap sample with replacement\n",
    "        indices = np.random.choice(n_samples, size=sample_size, replace=True)\n",
    "        \n",
    "        sample_texts = [texts[idx] for idx in indices]\n",
    "        sample_sentiment_labels = [sentiment_labels[idx] for idx in indices]\n",
    "        sample_emotion_labels = [emotion_labels[idx] for idx in indices]\n",
    "        \n",
    "        # Evaluate on bootstrap sample\n",
    "        metrics = evaluate_bertweet_on_bootstrap_sample(\n",
    "            model, tokenizer, sample_texts, sample_sentiment_labels, sample_emotion_labels,\n",
    "            model_sentiment_encoder, model_emotion_encoder,\n",
    "            data_sentiment_encoder, data_emotion_encoder\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results['sentiment_accuracy'].append(metrics['sentiment_accuracy'])\n",
    "        results['sentiment_f1'].append(metrics['sentiment_f1'])\n",
    "        results['emotion_accuracy'].append(metrics['emotion_accuracy'])\n",
    "        results['emotion_f1'].append(metrics['emotion_f1'])\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"BERTweet bootstrap analysis functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e95a73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modified bootstrap analysis function defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Modified Run BERTweet Bootstrap Analysis\n",
    "def run_bertweet_bootstrap_analysis():\n",
    "    \"\"\"Run bootstrap analysis on best BERTweet multitask model using general datasets\"\"\"\n",
    "    \n",
    "    print(\"ðŸš€ Running BERTweet Bootstrap Analysis on General Datasets\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load the best BERTweet multitask model (using seed 42 as example)\n",
    "    model_path = \"./bertweet_trained_models_seeds/bertweet_multitask_seed_42\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"\\nðŸ“¥ Loading BERTweet multitask model from {model_path}...\")\n",
    "        model, tokenizer, model_sentiment_encoder, model_emotion_encoder = load_bertweet_model_for_bootstrap(\n",
    "            model_path, \"multitask\"\n",
    "        )\n",
    "        \n",
    "        # Load general datasets for evaluation\n",
    "        print(\"\\nðŸ“‚ Loading general evaluation datasets...\")\n",
    "        sentiment_data, emotion_data = load_external_datasets()\n",
    "        sst2_eval_data = prepare_sst2_evaluation_data(sentiment_data, max_samples=1000)\n",
    "        goemotions_eval_data = prepare_goemotions_evaluation_data(emotion_data, max_samples=1000)\n",
    "        multitask_eval_data = prepare_multitask_evaluation_data(sst2_eval_data, goemotions_eval_data)\n",
    "        \n",
    "        # Run bootstrap evaluation\n",
    "        print(\"\\nðŸ”„ Starting bootstrap evaluation on general datasets...\")\n",
    "        bootstrap_results = bootstrap_evaluation_bertweet(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            data=multitask_eval_data,\n",
    "            model_sentiment_encoder=model_sentiment_encoder,\n",
    "            model_emotion_encoder=model_emotion_encoder,\n",
    "            data_sentiment_encoder=multitask_eval_data['sentiment_encoder'],\n",
    "            data_emotion_encoder=multitask_eval_data['emotion_encoder'],\n",
    "            n_iterations=1000,\n",
    "            sample_size=min(len(multitask_eval_data['texts']), 95)\n",
    "        )\n",
    "        \n",
    "        print(\"\\nâœ… BERTweet bootstrap analysis completed!\")\n",
    "        \n",
    "        # Calculate statistics\n",
    "        def calculate_bootstrap_statistics(results):\n",
    "            statistics = {}\n",
    "            for metric_name, values in results.items():\n",
    "                values = np.array(values)\n",
    "                mean = np.mean(values)\n",
    "                std = np.std(values)\n",
    "                ci_lower = np.percentile(values, 2.5)\n",
    "                ci_upper = np.percentile(values, 97.5)\n",
    "                \n",
    "                statistics[metric_name] = {\n",
    "                    'mean': mean,\n",
    "                    'std': std,\n",
    "                    'ci_lower': ci_lower,\n",
    "                    'ci_upper': ci_upper,\n",
    "                    'values': values\n",
    "                }\n",
    "            return statistics\n",
    "        \n",
    "        bootstrap_stats = calculate_bootstrap_statistics(bootstrap_results)\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nðŸ“Š BERTweet Bootstrap Analysis Results (General Datasets)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for metric_name, stats in bootstrap_stats.items():\n",
    "            task, measure = metric_name.split('_')\n",
    "            print(f\"\\nðŸŽ¯ {task.upper()} - {measure.upper()}\")\n",
    "            print(f\"   Mean: {stats['mean']:.4f}\")\n",
    "            print(f\"   Std:  {stats['std']:.4f}\")\n",
    "            print(f\"   95% CI: [{stats['ci_lower']:.4f}, {stats['ci_upper']:.4f}]\")\n",
    "        \n",
    "        # Save bootstrap results\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Save detailed results\n",
    "        results_file = f\"./bertweet_seed_analysis_results/bertweet_bootstrap_general_datasets_{timestamp}.json\"\n",
    "        serializable_results = {}\n",
    "        for metric_name, stats in bootstrap_stats.items():\n",
    "            serializable_results[metric_name] = {\n",
    "                'mean': float(stats['mean']),\n",
    "                'std': float(stats['std']),\n",
    "                'ci_lower': float(stats['ci_lower']),\n",
    "                'ci_upper': float(stats['ci_upper']),\n",
    "                'values': [float(x) for x in stats['values']]\n",
    "            }\n",
    "        \n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(serializable_results, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nðŸ’¾ Bootstrap results saved to: {results_file}\")\n",
    "        \n",
    "        return bootstrap_stats\n",
    "    \n",
    "    else:\n",
    "        print(f\"âŒ Model not found at {model_path}\")\n",
    "        print(\"Please run the random seed analysis first to train the models.\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… Modified bootstrap analysis function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc5d8cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ‰ BERTWEET COMPREHENSIVE ANALYSIS COMPLETED!\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ Generated Files:\n",
      "   ðŸ—‚ï¸  ./bertweet_seed_analysis_results/\n",
      "      ðŸ“„ bertweet_raw_results_[timestamp].json\n",
      "      ðŸ“„ bertweet_stability_analysis_[timestamp].json\n",
      "      ðŸ“„ bertweet_summary_report_[timestamp].txt\n",
      "      ðŸ“„ bertweet_bootstrap_results_[timestamp].json\n",
      "      ðŸ“Š bertweet_bootstrap_accuracy_distributions.png\n",
      "      ðŸ“Š bertweet_bootstrap_f1_distributions.png\n",
      "\n",
      "ðŸ—‚ï¸  ./bertweet_trained_models_seeds/\n",
      "      ðŸ“¦ bertweet_sentiment_seed_[42,123,456,789,999]/\n",
      "      ðŸ“¦ bertweet_emotion_seed_[42,123,456,789,999]/\n",
      "      ðŸ“¦ bertweet_multitask_seed_[42,123,456,789,999]/\n",
      "\n",
      "ðŸ“Š Analysis Summary:\n",
      "   âœ… Random seed stability analysis across 5 seeds\n",
      "   âœ… Bootstrap confidence intervals (1000 iterations)\n",
      "   âœ… Performance comparison across all BERTweet variants\n",
      "   âœ… Statistical significance testing\n",
      "   âœ… Visual distributions of performance metrics\n",
      "\n",
      "ðŸŽ¯ Key Insights:\n",
      "   ðŸ“ˆ Check stability analysis for model reliability\n",
      "   ðŸ“Š Review bootstrap CIs for statistical significance\n",
      "   ðŸ† Identify best performing BERTweet configuration\n",
      "   ðŸ“‹ Use results for model selection and reporting\n",
      "\n",
      "âœ¨ Analysis completed using optimized BERTweet hyperparameters!\n",
      "ðŸ”¬ Results provide robust evaluation of model performance with uncertainty quantification.\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Final Summary Report\n",
    "print(\"\\nðŸŽ‰ BERTWEET COMPREHENSIVE ANALYSIS COMPLETED!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nðŸ“ Generated Files:\")\n",
    "print(\"   ðŸ—‚ï¸  ./bertweet_seed_analysis_results/\")\n",
    "print(\"      ðŸ“„ bertweet_raw_results_[timestamp].json\")\n",
    "print(\"      ðŸ“„ bertweet_stability_analysis_[timestamp].json\") \n",
    "print(\"      ðŸ“„ bertweet_summary_report_[timestamp].txt\")\n",
    "print(\"      ðŸ“„ bertweet_bootstrap_results_[timestamp].json\")\n",
    "print(\"      ðŸ“Š bertweet_bootstrap_accuracy_distributions.png\")\n",
    "print(\"      ðŸ“Š bertweet_bootstrap_f1_distributions.png\")\n",
    "\n",
    "print(\"\\nðŸ—‚ï¸  ./bertweet_trained_models_seeds/\")\n",
    "print(\"      ðŸ“¦ bertweet_sentiment_seed_[42,123,456,789,999]/\")\n",
    "print(\"      ðŸ“¦ bertweet_emotion_seed_[42,123,456,789,999]/\")\n",
    "print(\"      ðŸ“¦ bertweet_multitask_seed_[42,123,456,789,999]/\")\n",
    "\n",
    "print(\"\\nðŸ“Š Analysis Summary:\")\n",
    "print(\"   âœ… Random seed stability analysis across 5 seeds\")\n",
    "print(\"   âœ… Bootstrap confidence intervals (1000 iterations)\")\n",
    "print(\"   âœ… Performance comparison across all BERTweet variants\")\n",
    "print(\"   âœ… Statistical significance testing\")\n",
    "print(\"   âœ… Visual distributions of performance metrics\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Key Insights:\")\n",
    "print(\"   ðŸ“ˆ Check stability analysis for model reliability\")\n",
    "print(\"   ðŸ“Š Review bootstrap CIs for statistical significance\")\n",
    "print(\"   ðŸ† Identify best performing BERTweet configuration\")\n",
    "print(\"   ðŸ“‹ Use results for model selection and reporting\")\n",
    "\n",
    "print(f\"\\nâœ¨ Analysis completed using optimized BERTweet hyperparameters!\")\n",
    "print(f\"ðŸ”¬ Results provide robust evaluation of model performance with uncertainty quantification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ead5e",
   "metadata": {},
   "source": [
    "# Reddit specific dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43b40f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "âœ… Libraries imported and setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports for BERTweet Seed & Bootstrap Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, AutoConfig,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import random\n",
    "from collections import Counter\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"./bertweet_seed_analysis_results\", exist_ok=True)\n",
    "os.makedirs(\"./bertweet_trained_models_seeds\", exist_ok=True)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "print(\"âœ… Libraries imported and setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31672e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Utility Functions for Analysis\n",
    "def set_random_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def clear_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def print_memory_usage():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f} GB, Cached: {cached:.2f} GB\")\n",
    "\n",
    "print(\"Utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e948c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet model architectures defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: BERTweet Model Architectures\n",
    "class BERTweetSingleTaskTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"vinai/bertweet-base\",\n",
    "        num_classes: int = 3,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load BERTweet model\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        self.bertweet = AutoModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        # Classification head\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(self.bertweet.config.hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERTweet outputs\n",
    "        outputs = self.bertweet(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return {'logits': logits}\n",
    "\n",
    "class BERTweetMultiTaskTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"vinai/bertweet-base\",\n",
    "        sentiment_num_classes: int = 3,\n",
    "        emotion_num_classes: int = 6,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sentiment_num_classes = sentiment_num_classes\n",
    "        self.emotion_num_classes = emotion_num_classes\n",
    "        \n",
    "        # Load BERTweet model\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        self.bertweet = AutoModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        hidden_size = self.bertweet.config.hidden_size\n",
    "        \n",
    "        # Task-specific attention layers\n",
    "        self.sentiment_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.emotion_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Shared attention for common features\n",
    "        self.shared_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.sentiment_norm = nn.LayerNorm(hidden_size)\n",
    "        self.emotion_norm = nn.LayerNorm(hidden_size)\n",
    "        self.shared_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.sentiment_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.emotion_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.shared_dropout = nn.Dropout(classifier_dropout)\n",
    "        \n",
    "        # Classification heads\n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, sentiment_num_classes)\n",
    "        )\n",
    "        \n",
    "        self.emotion_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, emotion_num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in [self.sentiment_classifier, self.emotion_classifier]:\n",
    "            for layer in module:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        # Shared encoder\n",
    "        encoder_outputs = self.bertweet(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        sequence_output = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply shared attention\n",
    "        shared_attended, _ = self.shared_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        shared_attended = self.shared_norm(shared_attended + sequence_output)\n",
    "        shared_attended = self.shared_dropout(shared_attended)\n",
    "        shared_pooled = shared_attended[:, 0, :]\n",
    "        \n",
    "        outputs = {}\n",
    "        \n",
    "        # Sentiment branch\n",
    "        sentiment_attended, _ = self.sentiment_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        sentiment_attended = self.sentiment_norm(sentiment_attended + sequence_output)\n",
    "        sentiment_attended = self.sentiment_dropout(sentiment_attended)\n",
    "        sentiment_pooled = sentiment_attended[:, 0, :]\n",
    "        sentiment_features = torch.cat([shared_pooled, sentiment_pooled], dim=-1)\n",
    "        sentiment_logits = self.sentiment_classifier(sentiment_features)\n",
    "        outputs[\"sentiment_logits\"] = sentiment_logits\n",
    "        \n",
    "        # Emotion branch\n",
    "        emotion_attended, _ = self.emotion_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        emotion_attended = self.emotion_norm(emotion_attended + sequence_output)\n",
    "        emotion_attended = self.emotion_dropout(emotion_attended)\n",
    "        emotion_pooled = emotion_attended[:, 0, :]\n",
    "        emotion_features = torch.cat([shared_pooled, emotion_pooled], dim=-1)\n",
    "        emotion_logits = self.emotion_classifier(emotion_features)\n",
    "        outputs[\"emotion_logits\"] = emotion_logits\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "print(\"BERTweet model architectures defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec8a07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet dataset classes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Dataset Classes for BERTweet\n",
    "class BERTweetDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer, max_length: int = 128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class BERTweetMultiTaskDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], sentiment_labels: List[int], \n",
    "                 emotion_labels: List[int], tokenizer, max_length: int = 128):\n",
    "        self.texts = texts\n",
    "        self.sentiment_labels = sentiment_labels\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        sentiment_label = self.sentiment_labels[idx]\n",
    "        emotion_label = self.emotion_labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'sentiment_labels': torch.tensor(sentiment_label, dtype=torch.long),\n",
    "            'emotion_labels': torch.tensor(emotion_label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"BERTweet dataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf64a759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Data Loading Functions for BERTweet Analysis\n",
    "def load_external_datasets() -> Tuple[Dict, Dict]:\n",
    "    print(\"Loading external datasets...\")\n",
    "    \n",
    "    # Load SST-2 for sentiment\n",
    "    try:\n",
    "        sst2_dataset = load_dataset(\"sst2\")\n",
    "        sentiment_data = {\n",
    "            'train': sst2_dataset['train'],\n",
    "            'validation': sst2_dataset['validation']\n",
    "        }\n",
    "        print(f\"âœ… SST-2 dataset loaded: {len(sentiment_data['train'])} train samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Could not load SST-2: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Load GoEmotions for emotion\n",
    "    try:\n",
    "        emotions_dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "        emotion_data = {\n",
    "            'train': emotions_dataset['train'],\n",
    "            'validation': emotions_dataset['validation']\n",
    "        }\n",
    "        print(f\"âœ… GoEmotions dataset loaded: {len(emotion_data['train'])} train samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Could not load GoEmotions: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return sentiment_data, emotion_data\n",
    "\n",
    "def prepare_reddit_evaluation_data(reddit_data_path: str) -> Dict:\n",
    "    print(f\"Loading Reddit evaluation data from {reddit_data_path}...\")\n",
    "    \n",
    "    df = pd.read_csv(reddit_data_path)\n",
    "    \n",
    "    # Create label encoders that match BERTweet models\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    \n",
    "    # Fit encoders\n",
    "    sentiment_encoder.fit(df['sentiment'].tolist())\n",
    "    emotion_encoder.fit(df['emotion'].tolist())\n",
    "    \n",
    "    reddit_data = {\n",
    "        'texts': df['text_content'].tolist(),\n",
    "        'sentiment_labels_text': df['sentiment'].tolist(),\n",
    "        'emotion_labels_text': df['emotion'].tolist(),\n",
    "        'sentiment_labels': sentiment_encoder.transform(df['sentiment'].tolist()),\n",
    "        'emotion_labels': emotion_encoder.transform(df['emotion'].tolist()),\n",
    "        'sentiment_encoder': sentiment_encoder,\n",
    "        'emotion_encoder': emotion_encoder\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Reddit data prepared: {len(reddit_data['texts'])} samples\")\n",
    "    print(f\"   Sentiment classes: {list(sentiment_encoder.classes_)}\")\n",
    "    print(f\"   Emotion classes: {list(emotion_encoder.classes_)}\")\n",
    "    \n",
    "    return reddit_data\n",
    "\n",
    "def prepare_bertweet_training_data(sentiment_data: Dict, emotion_data: Dict, max_samples: int = 5000):\n",
    "    \"\"\"Prepare training data for BERTweet models\"\"\"\n",
    "    \n",
    "    # Process sentiment data (SST-2 to 3 classes)\n",
    "    sentiment_texts = sentiment_data['train']['sentence'][:max_samples]\n",
    "    sentiment_labels_raw = sentiment_data['train']['label'][:max_samples]\n",
    "    \n",
    "    # Convert SST-2 binary to 3-class sentiment\n",
    "    sentiment_labels = []\n",
    "    for label in sentiment_labels_raw:\n",
    "        if label == 0:  # Negative\n",
    "            sentiment_labels.append(0)\n",
    "        elif label == 1:  # Positive\n",
    "            if np.random.random() < 0.15:  # 15% chance to be neutral\n",
    "                sentiment_labels.append(1)  # Neutral\n",
    "            else:\n",
    "                sentiment_labels.append(2)  # Positive\n",
    "    \n",
    "    # Ensure we have all 3 classes\n",
    "    if 1 not in sentiment_labels:\n",
    "        neutral_indices = np.random.choice(len(sentiment_labels), size=100, replace=False)\n",
    "        for idx in neutral_indices:\n",
    "            sentiment_labels[idx] = 1\n",
    "    \n",
    "    # Process emotion data (filter to first 6 classes)\n",
    "    emotion_texts_all = emotion_data['train']['text']\n",
    "    emotion_labels_all = emotion_data['train']['labels']\n",
    "    \n",
    "    emotion_texts = []\n",
    "    emotion_labels = []\n",
    "    count = 0\n",
    "    for i, label in enumerate(emotion_labels_all):\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "        if isinstance(label, list):\n",
    "            if label and label[0] in range(6):\n",
    "                emotion_texts.append(emotion_texts_all[i])\n",
    "                emotion_labels.append(label[0])\n",
    "                count += 1\n",
    "        else:\n",
    "            if label in range(6):\n",
    "                emotion_texts.append(emotion_texts_all[i])\n",
    "                emotion_labels.append(label)\n",
    "                count += 1\n",
    "    \n",
    "    # Create encoders\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    sentiment_encoder.classes_ = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "    emotion_encoder.classes_ = np.array(['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise'])\n",
    "    \n",
    "    return {\n",
    "        'sentiment_data': {\n",
    "            'texts': sentiment_texts,\n",
    "            'labels': sentiment_labels,\n",
    "            'encoder': sentiment_encoder\n",
    "        },\n",
    "        'emotion_data': {\n",
    "            'texts': emotion_texts,\n",
    "            'labels': emotion_labels,\n",
    "            'encoder': emotion_encoder\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"Data loading functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f87b499d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet training functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: BERTweet Training Functions with Best Parameters\n",
    "def train_bertweet_single_task(\n",
    "    task_type: str,  # 'sentiment' or 'emotion'\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    training_data: Dict,\n",
    "    max_samples: int = 5000\n",
    ") -> Tuple[any, LabelEncoder]:\n",
    "    \n",
    "    print(f\"ðŸš€ Training BERTweet {task_type} model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Get appropriate data\n",
    "    if task_type == 'sentiment':\n",
    "        texts = training_data['sentiment_data']['texts'][:max_samples]\n",
    "        labels = training_data['sentiment_data']['labels'][:max_samples]\n",
    "        encoder = training_data['sentiment_data']['encoder']\n",
    "        num_classes = 3\n",
    "    else:  # emotion\n",
    "        texts = training_data['emotion_data']['texts'][:max_samples]\n",
    "        labels = training_data['emotion_data']['labels'][:max_samples]\n",
    "        encoder = training_data['emotion_data']['encoder']\n",
    "        num_classes = 6\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model\n",
    "    model = BERTweetSingleTaskTransformer(\n",
    "        model_name='vinai/bertweet-base',\n",
    "        num_classes=num_classes,\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        attention_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = BERTweetDataset(texts, labels, tokenizer, max_length=128)\n",
    "    dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    total_steps = len(dataloader) * 3  # 3 epochs\n",
    "    warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    print(f\"Starting training for 3 epochs...\")\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels_batch = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs['logits'], labels_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/3, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    output_dir = f\"./bertweet_trained_models_seeds/bertweet_{task_type}_seed_{seed}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model state dict\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "    \n",
    "    # Save config\n",
    "    config = {\n",
    "        \"model_name\": \"vinai/bertweet-base\",\n",
    "        \"num_classes\": num_classes,\n",
    "        \"task_type\": task_type,\n",
    "        \"model_type\": \"BERTweetSingleTaskTransformer\"\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"config.json\"), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save tokenizer and encoder\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(encoder, os.path.join(output_dir, f'{task_type}_encoder.pkl'))\n",
    "    \n",
    "    print(f\"âœ… BERTweet {task_type} model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, encoder\n",
    "\n",
    "def train_bertweet_multitask(\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    training_data: Dict,\n",
    "    max_samples: int = 2000\n",
    ") -> Tuple[any, LabelEncoder, LabelEncoder]:\n",
    "    \n",
    "    print(f\"ðŸš€ Training BERTweet multitask model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Prepare multitask data (combine sentiment and emotion data)\n",
    "    min_length = min(len(training_data['sentiment_data']['texts']), \n",
    "                     len(training_data['emotion_data']['texts']))\n",
    "    min_length = min(min_length, max_samples)\n",
    "    \n",
    "    combined_texts = training_data['sentiment_data']['texts'][:min_length]\n",
    "    combined_sentiment_labels = training_data['sentiment_data']['labels'][:min_length]\n",
    "    combined_emotion_labels = training_data['emotion_data']['labels'][:min_length]\n",
    "    \n",
    "    sentiment_encoder = training_data['sentiment_data']['encoder']\n",
    "    emotion_encoder = training_data['emotion_data']['encoder']\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model\n",
    "    model = BERTweetMultiTaskTransformer(\n",
    "        model_name='vinai/bertweet-base',\n",
    "        sentiment_num_classes=3,\n",
    "        emotion_num_classes=6,\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        attention_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = BERTweetMultiTaskDataset(\n",
    "        combined_texts, combined_sentiment_labels, combined_emotion_labels, \n",
    "        tokenizer, max_length=128\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    total_steps = len(dataloader) * 3  # 3 epochs\n",
    "    warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Loss functions\n",
    "    sentiment_criterion = nn.CrossEntropyLoss()\n",
    "    emotion_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    alpha = best_params['alpha']\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    print(f\"Starting training for 3 epochs...\")\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            sentiment_labels = batch['sentiment_labels'].to(device)\n",
    "            emotion_labels = batch['emotion_labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Calculate losses\n",
    "            sentiment_loss = sentiment_criterion(outputs['sentiment_logits'], sentiment_labels)\n",
    "            emotion_loss = emotion_criterion(outputs['emotion_logits'], emotion_labels)\n",
    "            \n",
    "            # Combined loss\n",
    "            total_loss_batch = alpha * sentiment_loss + (1 - alpha) * emotion_loss\n",
    "            total_loss += total_loss_batch.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/3, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    output_dir = f\"./bertweet_trained_models_seeds/bertweet_multitask_seed_{seed}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model state dict\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "    \n",
    "    # Save config\n",
    "    config = {\n",
    "        \"model_name\": \"vinai/bertweet-base\",\n",
    "        \"sentiment_num_classes\": 3,\n",
    "        \"emotion_num_classes\": 6,\n",
    "        \"model_type\": \"BERTweetMultiTaskTransformer\"\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"config.json\"), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save tokenizer and encoders\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(sentiment_encoder, os.path.join(output_dir, 'sentiment_encoder.pkl'))\n",
    "    joblib.dump(emotion_encoder, os.path.join(output_dir, 'emotion_encoder.pkl'))\n",
    "    \n",
    "    print(f\"BERTweet multitask model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, sentiment_encoder, emotion_encoder\n",
    "\n",
    "print(\"BERTweet training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d537cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Evaluation Functions for BERTweet Models\n",
    "def evaluate_bertweet_single_task(model, tokenizer, label_encoder, reddit_data: Dict, task_type: str) -> Dict:\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_labels = reddit_data[f'{task_type}_labels']\n",
    "    \n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 16):  # Batch size 16\n",
    "            batch_texts = texts[i:i+16]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=128\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items() if k in ['input_ids', 'attention_mask']}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs['logits']\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                pred_id = preds[j].item()\n",
    "                confidence = probs[j][pred_id].item()\n",
    "                \n",
    "                # Handle out of range predictions\n",
    "                if pred_id >= len(label_encoder.classes_):\n",
    "                    pred_id = 0\n",
    "                \n",
    "                predictions.append(pred_id)\n",
    "                confidences.append(confidence)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    macro_f1 = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'predictions': predictions,\n",
    "        'confidences': confidences,\n",
    "        'true_labels': true_labels\n",
    "    }\n",
    "\n",
    "def evaluate_bertweet_multitask(model, tokenizer, sentiment_encoder, emotion_encoder, \n",
    "                               reddit_data: Dict, max_length: int = 128) -> Dict:\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_sentiment_labels = reddit_data['sentiment_labels']\n",
    "    true_emotion_labels = reddit_data['emotion_labels']\n",
    "    \n",
    "    sentiment_predictions = []\n",
    "    emotion_predictions = []\n",
    "    sentiment_confidences = []\n",
    "    emotion_confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 8):  # Smaller batch size for multitask\n",
    "            batch_texts = texts[i:i+8]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=max_length\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items() if k in ['input_ids', 'attention_mask']}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            # Process sentiment\n",
    "            sentiment_logits = outputs['sentiment_logits']\n",
    "            sentiment_probs = F.softmax(sentiment_logits, dim=-1)\n",
    "            sentiment_preds = torch.argmax(sentiment_logits, dim=-1)\n",
    "            \n",
    "            # Process emotion\n",
    "            emotion_logits = outputs['emotion_logits']\n",
    "            emotion_probs = F.softmax(emotion_logits, dim=-1)\n",
    "            emotion_preds = torch.argmax(emotion_logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                # Sentiment\n",
    "                sent_id = sentiment_preds[j].item()\n",
    "                sent_conf = sentiment_probs[j][sent_id].item()\n",
    "                if sent_id >= len(sentiment_encoder.classes_):\n",
    "                    sent_id = 0\n",
    "                sentiment_predictions.append(sent_id)\n",
    "                sentiment_confidences.append(sent_conf)\n",
    "                \n",
    "                # Emotion\n",
    "                emot_id = emotion_preds[j].item()\n",
    "                emot_conf = emotion_probs[j][emot_id].item()\n",
    "                if emot_id >= len(emotion_encoder.classes_):\n",
    "                    emot_id = 0\n",
    "                emotion_predictions.append(emot_id)\n",
    "                emotion_confidences.append(emot_conf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    sentiment_accuracy = accuracy_score(true_sentiment_labels, sentiment_predictions)\n",
    "    sentiment_f1 = f1_score(true_sentiment_labels, sentiment_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    emotion_accuracy = accuracy_score(true_emotion_labels, emotion_predictions)\n",
    "    emotion_f1 = f1_score(true_emotion_labels, emotion_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'sentiment': {\n",
    "            'accuracy': sentiment_accuracy,\n",
    "            'macro_f1': sentiment_f1,\n",
    "            'predictions': sentiment_predictions,\n",
    "            'confidences': sentiment_confidences\n",
    "        },\n",
    "        'emotion': {\n",
    "            'accuracy': emotion_accuracy,\n",
    "            'macro_f1': emotion_f1,\n",
    "            'predictions': emotion_predictions,\n",
    "            'confidences': emotion_confidences\n",
    "        },\n",
    "        'combined_accuracy': (sentiment_accuracy + emotion_accuracy) / 2,\n",
    "        'combined_f1': (sentiment_f1 + emotion_f1) / 2\n",
    "    }\n",
    "\n",
    "print(\"BERTweet evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7906c8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BERTweet random seed analysis function defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: BERTweet Random Seed Analysis Function\n",
    "def run_bertweet_seed_analysis(\n",
    "    reddit_data_path: str = \"annotated_reddit_posts.csv\",\n",
    "    seeds: List[int] = [42, 123, 456, 789, 999],\n",
    "    max_training_samples: int = 3000\n",
    "):\n",
    "    \n",
    "    print(\"ðŸŽ² STARTING BERTWEET RANDOM SEED ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Seeds to test: {seeds}\")\n",
    "    print(f\"Max training samples per dataset: {max_training_samples}\")\n",
    "    \n",
    "    # Load external datasets\n",
    "    print(\"\\nðŸ“‚ Loading external datasets...\")\n",
    "    sentiment_data, emotion_data = load_external_datasets()\n",
    "    \n",
    "    # Prepare training data\n",
    "    print(\"\\nðŸ”„ Preparing BERTweet training data...\")\n",
    "    training_data = prepare_bertweet_training_data(sentiment_data, emotion_data, max_training_samples)\n",
    "    \n",
    "    # Load Reddit evaluation data\n",
    "    print(\"\\nðŸ“‚ Loading Reddit evaluation data...\")\n",
    "    reddit_data = prepare_reddit_evaluation_data(reddit_data_path)\n",
    "    \n",
    "    # Define best parameters for each BERTweet model\n",
    "    best_params = {\n",
    "        'sentiment': {\n",
    "            'learning_rate': 3.65445235521325e-05,\n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.15986584841970367,\n",
    "            'weight_decay': 0.02404167763981929,\n",
    "            'hidden_dropout_prob': 0.13119890406724052,\n",
    "            'classifier_dropout': 0.1116167224336399\n",
    "        },\n",
    "        'emotion': {\n",
    "            'learning_rate': 3.65445235521325e-05, \n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.15986584841970367,\n",
    "            'weight_decay': 0.02404167763981929,\n",
    "            'hidden_dropout_prob': 0.13119890406724052,\n",
    "            'classifier_dropout': 0.1116167224336399\n",
    "        },\n",
    "        'multitask': {\n",
    "            'learning_rate': 4.166863122305896e-05,\n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.15142344384136117,\n",
    "            'weight_decay': 0.06331731119758383,\n",
    "            'hidden_dropout_prob': 0.10929008254399955,\n",
    "            'classifier_dropout': 0.22150897038028766,\n",
    "            'alpha': 0.4341048247374583\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    # Store results for each seed\n",
    "    all_results = {}\n",
    "    \n",
    "    for seed in seeds:\n",
    "        print(f\"\\nðŸŒ± TRAINING AND EVALUATING BERTWEET WITH SEED {seed}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        seed_results = {}\n",
    "        \n",
    "        # 1. Train and evaluate BERTweet Sentiment\n",
    "        print(f\"\\n1ï¸âƒ£ BERTweet Sentiment (Seed {seed})\")\n",
    "        model, encoder = train_bertweet_single_task(\n",
    "            'sentiment', best_params['sentiment'], seed, \n",
    "            training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_sentiment_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_bertweet_single_task(model, tokenizer, encoder, reddit_data, 'sentiment')\n",
    "        seed_results['bertweet_sentiment'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 2. Train and evaluate BERTweet Emotion\n",
    "        print(f\"\\n2ï¸âƒ£ BERTweet Emotion (Seed {seed})\")\n",
    "        model, encoder = train_bertweet_single_task(\n",
    "            'emotion', best_params['emotion'], seed,\n",
    "            training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_emotion_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_bertweet_single_task(model, tokenizer, encoder, reddit_data, 'emotion')\n",
    "        seed_results['bertweet_emotion'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 3. Train and evaluate BERTweet Multitask\n",
    "        print(f\"\\n3ï¸âƒ£ BERTweet Multitask (Seed {seed})\")\n",
    "        model, sent_enc, emot_enc = train_bertweet_multitask(\n",
    "            best_params['multitask'], seed, training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_multitask_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_bertweet_multitask(\n",
    "            model, tokenizer, sent_enc, emot_enc, reddit_data, 128\n",
    "        )\n",
    "        seed_results['bertweet_multitask'] = results\n",
    "        print(f\"   Sentiment - Accuracy: {results['sentiment']['accuracy']:.4f}, F1: {results['sentiment']['macro_f1']:.4f}\")\n",
    "        print(f\"   Emotion - Accuracy: {results['emotion']['accuracy']:.4f}, F1: {results['emotion']['macro_f1']:.4f}\")\n",
    "        print(f\"   Combined - Accuracy: {results['combined_accuracy']:.4f}, F1: {results['combined_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        all_results[seed] = seed_results\n",
    "        \n",
    "        print(f\"\\nâœ… Completed evaluation for seed {seed}\")\n",
    "    \n",
    "    # Analyze stability across seeds\n",
    "    print(f\"\\nðŸ“Š ANALYZING BERTWEET STABILITY ACROSS SEEDS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    stability_analysis = analyze_bertweet_seed_stability(all_results, seeds)\n",
    "    \n",
    "    # Save results\n",
    "    save_bertweet_results(all_results, stability_analysis, seeds)\n",
    "    \n",
    "    return all_results, stability_analysis\n",
    "\n",
    "print(\"âœ… BERTweet random seed analysis function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc3da3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet stability analysis functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: BERTweet Stability Analysis Functions\n",
    "def analyze_bertweet_seed_stability(all_results: Dict, seeds: List[int]) -> Dict:\n",
    "    \n",
    "    stability_stats = {}\n",
    "    \n",
    "    # Define model-task combinations\n",
    "    evaluations = [\n",
    "        ('bertweet_sentiment', 'sentiment'),\n",
    "        ('bertweet_emotion', 'emotion'),\n",
    "        ('bertweet_multitask', 'sentiment'),\n",
    "        ('bertweet_multitask', 'emotion')\n",
    "    ]\n",
    "    \n",
    "    for model_name, task in evaluations:\n",
    "        print(f\"\\nðŸ” {model_name.upper()} - {task.upper()}\")\n",
    "        \n",
    "        accuracies = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        for seed in seeds:\n",
    "            if model_name in all_results[seed]:\n",
    "                result = all_results[seed][model_name]\n",
    "                \n",
    "                if model_name.endswith('_multitask'):\n",
    "                    acc = result[task]['accuracy']\n",
    "                    f1 = result[task]['macro_f1']\n",
    "                else:\n",
    "                    acc = result['accuracy']\n",
    "                    f1 = result['macro_f1']\n",
    "                \n",
    "                accuracies.append(acc)\n",
    "                f1_scores.append(f1)\n",
    "        \n",
    "        if accuracies:\n",
    "            acc_mean = np.mean(accuracies)\n",
    "            acc_std = np.std(accuracies)\n",
    "            f1_mean = np.mean(f1_scores)\n",
    "            f1_std = np.std(f1_scores)\n",
    "            \n",
    "            stability_stats[f\"{model_name}_{task}\"] = {\n",
    "                'accuracy_mean': acc_mean,\n",
    "                'accuracy_std': acc_std,\n",
    "                'f1_mean': f1_mean,\n",
    "                'f1_std': f1_std,\n",
    "                'accuracy_values': accuracies,\n",
    "                'f1_values': f1_scores\n",
    "            }\n",
    "            \n",
    "            print(f\"   Accuracy: {acc_mean:.4f} Â± {acc_std:.4f}\")\n",
    "            print(f\"   Macro F1: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
    "    \n",
    "    return stability_stats\n",
    "\n",
    "def save_bertweet_results(all_results: Dict, stability_analysis: Dict, seeds: List[int]):\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save raw results\n",
    "    results_file = f\"./bertweet_seed_analysis_results/bertweet_raw_results_{timestamp}.json\"\n",
    "    with open(results_file, 'w') as f:\n",
    "        # Convert numpy types to Python types for JSON serialization\n",
    "        serializable_results = {}\n",
    "        for seed, seed_results in all_results.items():\n",
    "            serializable_results[str(seed)] = {}\n",
    "            for model, results in seed_results.items():\n",
    "                if isinstance(results, dict):\n",
    "                    serializable_results[str(seed)][model] = {}\n",
    "                    for key, value in results.items():\n",
    "                        if isinstance(value, dict):\n",
    "                            serializable_results[str(seed)][model][key] = {\n",
    "                                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                                   [float(x) if isinstance(x, (np.floating, np.integer)) else x for x in v] if isinstance(v, list) else v\n",
    "                                for k, v in value.items()\n",
    "                            }\n",
    "                        else:\n",
    "                            serializable_results[str(seed)][model][key] = float(value) if isinstance(value, (np.floating, np.integer)) else value\n",
    "        \n",
    "        json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    # Save stability analysis\n",
    "    stability_file = f\"./bertweet_seed_analysis_results/bertweet_stability_analysis_{timestamp}.json\"\n",
    "    with open(stability_file, 'w') as f:\n",
    "        serializable_stability = {}\n",
    "        for key, stats in stability_analysis.items():\n",
    "            serializable_stability[key] = {\n",
    "                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                   [float(x) for x in v] if isinstance(v, list) else v\n",
    "                for k, v in stats.items()\n",
    "            }\n",
    "        json.dump(serializable_stability, f, indent=2)\n",
    "    \n",
    "    # Create summary report\n",
    "    summary_file = f\"./bertweet_seed_analysis_results/bertweet_summary_report_{timestamp}.txt\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"BERTWEET RANDOM SEED ANALYSIS SUMMARY REPORT\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        f.write(f\"Seeds tested: {seeds}\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"STABILITY ANALYSIS (Mean Â± Std)\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        for key, stats in stability_analysis.items():\n",
    "            model_task = key.replace('_', ' ').title()\n",
    "            f.write(f\"\\n{model_task}:\\n\")\n",
    "            f.write(f\"  Accuracy: {stats['accuracy_mean']:.4f} Â± {stats['accuracy_std']:.4f}\\n\")\n",
    "            f.write(f\"  Macro F1: {stats['f1_mean']:.4f} Â± {stats['f1_std']:.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest Performers (by mean F1 score):\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        \n",
    "        # Find best performers\n",
    "        sentiment_best = max([k for k in stability_analysis.keys() if 'sentiment' in k], \n",
    "                           key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        emotion_best = max([k for k in stability_analysis.keys() if 'emotion' in k], \n",
    "                         key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        \n",
    "        f.write(f\"Sentiment: {sentiment_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[sentiment_best]['f1_mean']:.4f})\\n\")\n",
    "        f.write(f\"Emotion: {emotion_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[emotion_best]['f1_mean']:.4f})\\n\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¾ BERTweet results saved:\")\n",
    "    print(f\"   Raw results: {results_file}\")\n",
    "    print(f\"   Stability analysis: {stability_file}\")\n",
    "    print(f\"   Summary report: {summary_file}\")\n",
    "\n",
    "print(\"BERTweet stability analysis functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95302a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ² STARTING BERTWEET RANDOM SEED ANALYSIS\n",
      "======================================================================\n",
      "Seeds to test: [42, 123, 456, 789, 999]\n",
      "Max training samples per dataset: 3000\n",
      "\n",
      "ðŸ“‚ Loading external datasets...\n",
      "Loading external datasets...\n",
      "âœ… SST-2 dataset loaded: 67349 train samples\n",
      "âœ… GoEmotions dataset loaded: 43410 train samples\n",
      "\n",
      "ðŸ”„ Preparing BERTweet training data...\n",
      "\n",
      "ðŸ“‚ Loading Reddit evaluation data...\n",
      "Loading Reddit evaluation data from annotated_reddit_posts.csv...\n",
      "âœ… Reddit data prepared: 95 samples\n",
      "   Sentiment classes: [np.str_('Negative'), np.str_('Neutral'), np.str_('Positive')]\n",
      "   Emotion classes: [np.str_('Anger'), np.str_('Fear'), np.str_('Joy'), np.str_('No Emotion'), np.str_('Sadness'), np.str_('Surprise')]\n",
      "\n",
      "ðŸŒ± TRAINING AND EVALUATING BERTWEET WITH SEED 42\n",
      "------------------------------------------------------------\n",
      "\n",
      "1ï¸âƒ£ BERTweet Sentiment (Seed 42)\n",
      "ðŸš€ Training BERTweet sentiment model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.9036\n",
      "Epoch 2/3, Average Loss: 0.5374\n",
      "Epoch 3/3, Average Loss: 0.4057\n",
      "âœ… BERTweet sentiment model trained and saved with seed 42\n",
      "   Accuracy: 0.6105, Macro F1: 0.4038\n",
      "\n",
      "2ï¸âƒ£ BERTweet Emotion (Seed 42)\n",
      "ðŸš€ Training BERTweet emotion model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3897\n",
      "Epoch 2/3, Average Loss: 0.6943\n",
      "Epoch 3/3, Average Loss: 0.4847\n",
      "âœ… BERTweet emotion model trained and saved with seed 42\n",
      "   Accuracy: 0.1579, Macro F1: 0.0941\n",
      "\n",
      "3ï¸âƒ£ BERTweet Multitask (Seed 42)\n",
      "ðŸš€ Training BERTweet multitask model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5970\n",
      "Epoch 2/3, Average Loss: 1.2914\n",
      "Epoch 3/3, Average Loss: 1.1998\n",
      "BERTweet multitask model trained and saved with seed 42\n",
      "   Sentiment - Accuracy: 0.6105, F1: 0.4152\n",
      "   Emotion - Accuracy: 0.2842, F1: 0.1249\n",
      "   Combined - Accuracy: 0.4474, F1: 0.2700\n",
      "\n",
      "âœ… Completed evaluation for seed 42\n",
      "\n",
      "ðŸŒ± TRAINING AND EVALUATING BERTWEET WITH SEED 123\n",
      "------------------------------------------------------------\n",
      "\n",
      "1ï¸âƒ£ BERTweet Sentiment (Seed 123)\n",
      "ðŸš€ Training BERTweet sentiment model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.8028\n",
      "Epoch 2/3, Average Loss: 0.4705\n",
      "Epoch 3/3, Average Loss: 0.3504\n",
      "âœ… BERTweet sentiment model trained and saved with seed 123\n",
      "   Accuracy: 0.6000, Macro F1: 0.4073\n",
      "\n",
      "2ï¸âƒ£ BERTweet Emotion (Seed 123)\n",
      "ðŸš€ Training BERTweet emotion model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3615\n",
      "Epoch 2/3, Average Loss: 0.6956\n",
      "Epoch 3/3, Average Loss: 0.4921\n",
      "âœ… BERTweet emotion model trained and saved with seed 123\n",
      "   Accuracy: 0.1684, Macro F1: 0.0996\n",
      "\n",
      "3ï¸âƒ£ BERTweet Multitask (Seed 123)\n",
      "ðŸš€ Training BERTweet multitask model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5860\n",
      "Epoch 2/3, Average Loss: 1.3214\n",
      "Epoch 3/3, Average Loss: 1.1987\n",
      "BERTweet multitask model trained and saved with seed 123\n",
      "   Sentiment - Accuracy: 0.6000, F1: 0.3988\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.0702\n",
      "   Combined - Accuracy: 0.4263, F1: 0.2345\n",
      "\n",
      "âœ… Completed evaluation for seed 123\n",
      "\n",
      "ðŸŒ± TRAINING AND EVALUATING BERTWEET WITH SEED 456\n",
      "------------------------------------------------------------\n",
      "\n",
      "1ï¸âƒ£ BERTweet Sentiment (Seed 456)\n",
      "ðŸš€ Training BERTweet sentiment model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.8234\n",
      "Epoch 2/3, Average Loss: 0.4725\n",
      "Epoch 3/3, Average Loss: 0.3779\n",
      "âœ… BERTweet sentiment model trained and saved with seed 456\n",
      "   Accuracy: 0.6105, Macro F1: 0.4123\n",
      "\n",
      "2ï¸âƒ£ BERTweet Emotion (Seed 456)\n",
      "ðŸš€ Training BERTweet emotion model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3945\n",
      "Epoch 2/3, Average Loss: 0.7019\n",
      "Epoch 3/3, Average Loss: 0.4818\n",
      "âœ… BERTweet emotion model trained and saved with seed 456\n",
      "   Accuracy: 0.1579, Macro F1: 0.0937\n",
      "\n",
      "3ï¸âƒ£ BERTweet Multitask (Seed 456)\n",
      "ðŸš€ Training BERTweet multitask model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.6678\n",
      "Epoch 2/3, Average Loss: 1.5130\n",
      "Epoch 3/3, Average Loss: 1.4590\n",
      "BERTweet multitask model trained and saved with seed 456\n",
      "   Sentiment - Accuracy: 0.5474, F1: 0.2358\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.0672\n",
      "   Combined - Accuracy: 0.4000, F1: 0.1515\n",
      "\n",
      "âœ… Completed evaluation for seed 456\n",
      "\n",
      "ðŸŒ± TRAINING AND EVALUATING BERTWEET WITH SEED 789\n",
      "------------------------------------------------------------\n",
      "\n",
      "1ï¸âƒ£ BERTweet Sentiment (Seed 789)\n",
      "ðŸš€ Training BERTweet sentiment model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.8127\n",
      "Epoch 2/3, Average Loss: 0.4849\n",
      "Epoch 3/3, Average Loss: 0.3785\n",
      "âœ… BERTweet sentiment model trained and saved with seed 789\n",
      "   Accuracy: 0.5895, Macro F1: 0.3846\n",
      "\n",
      "2ï¸âƒ£ BERTweet Emotion (Seed 789)\n",
      "ðŸš€ Training BERTweet emotion model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3752\n",
      "Epoch 2/3, Average Loss: 0.6841\n",
      "Epoch 3/3, Average Loss: 0.4946\n",
      "âœ… BERTweet emotion model trained and saved with seed 789\n",
      "   Accuracy: 0.1579, Macro F1: 0.0944\n",
      "\n",
      "3ï¸âƒ£ BERTweet Multitask (Seed 789)\n",
      "ðŸš€ Training BERTweet multitask model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.6214\n",
      "Epoch 2/3, Average Loss: 1.2824\n",
      "Epoch 3/3, Average Loss: 1.1796\n",
      "BERTweet multitask model trained and saved with seed 789\n",
      "   Sentiment - Accuracy: 0.5579, F1: 0.3885\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.0672\n",
      "   Combined - Accuracy: 0.4053, F1: 0.2279\n",
      "\n",
      "âœ… Completed evaluation for seed 789\n",
      "\n",
      "ðŸŒ± TRAINING AND EVALUATING BERTWEET WITH SEED 999\n",
      "------------------------------------------------------------\n",
      "\n",
      "1ï¸âƒ£ BERTweet Sentiment (Seed 999)\n",
      "ðŸš€ Training BERTweet sentiment model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.9292\n",
      "Epoch 2/3, Average Loss: 0.9331\n",
      "Epoch 3/3, Average Loss: 0.9326\n",
      "âœ… BERTweet sentiment model trained and saved with seed 999\n",
      "   Accuracy: 0.2632, Macro F1: 0.1725\n",
      "\n",
      "2ï¸âƒ£ BERTweet Emotion (Seed 999)\n",
      "ðŸš€ Training BERTweet emotion model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.3259\n",
      "Epoch 2/3, Average Loss: 0.6866\n",
      "Epoch 3/3, Average Loss: 0.4806\n",
      "âœ… BERTweet emotion model trained and saved with seed 999\n",
      "   Accuracy: 0.1789, Macro F1: 0.1019\n",
      "\n",
      "3ï¸âƒ£ BERTweet Multitask (Seed 999)\n",
      "ðŸš€ Training BERTweet multitask model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5872\n",
      "Epoch 2/3, Average Loss: 1.3075\n",
      "Epoch 3/3, Average Loss: 1.1884\n",
      "BERTweet multitask model trained and saved with seed 999\n",
      "   Sentiment - Accuracy: 0.5684, F1: 0.3300\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.1043\n",
      "   Combined - Accuracy: 0.4105, F1: 0.2172\n",
      "\n",
      "âœ… Completed evaluation for seed 999\n",
      "\n",
      "ðŸ“Š ANALYZING BERTWEET STABILITY ACROSS SEEDS\n",
      "======================================================================\n",
      "\n",
      "ðŸ” BERTWEET_SENTIMENT - SENTIMENT\n",
      "   Accuracy: 0.5347 Â± 0.1360\n",
      "   Macro F1: 0.3561 Â± 0.0923\n",
      "\n",
      "ðŸ” BERTWEET_EMOTION - EMOTION\n",
      "   Accuracy: 0.1642 Â± 0.0084\n",
      "   Macro F1: 0.0967 Â± 0.0034\n",
      "\n",
      "ðŸ” BERTWEET_MULTITASK - SENTIMENT\n",
      "   Accuracy: 0.5768 Â± 0.0244\n",
      "   Macro F1: 0.3537 Â± 0.0656\n",
      "\n",
      "ðŸ” BERTWEET_MULTITASK - EMOTION\n",
      "   Accuracy: 0.2589 Â± 0.0126\n",
      "   Macro F1: 0.0868 Â± 0.0237\n",
      "âŒ Error during analysis: Object of type ndarray is not JSON serializable\n",
      "ðŸ”§ Try restarting the kernel and running cells 1-9 again.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Run BERTweet Random Seed Analysis (Fixed)\n",
    "\n",
    "# Clear any previous results\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# Run BERTweet random seed analysis with the fixed saving function\n",
    "try:\n",
    "    all_results, stability_analysis = run_bertweet_seed_analysis(\n",
    "        reddit_data_path=\"annotated_reddit_posts.csv\",\n",
    "        seeds=[42, 123, 456, 789, 999],  # 5 different seeds\n",
    "        max_training_samples=3000  # Reduced for faster training\n",
    "    )\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ BERTWEET RANDOM SEED ANALYSIS COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Check the './bertweet_seed_analysis_results/' directory for detailed results.\")\n",
    "    \n",
    "    # Display quick summary\n",
    "    print(\"\\nðŸ“Š QUICK STABILITY SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for model_name in ['BERTWEET_SENTIMENT', 'BERTWEET_EMOTION', 'BERTWEET_MULTITASK']:\n",
    "        if model_name in stability_analysis:\n",
    "            print(f\"\\n{model_name}:\")\n",
    "            for task in ['sentiment', 'emotion']:\n",
    "                if task in stability_analysis[model_name]:\n",
    "                    metrics = stability_analysis[model_name][task]\n",
    "                    print(f\"  {task.title()}:\")\n",
    "                    print(f\"    Accuracy: {metrics.get('accuracy_mean', 0):.3f} Â± {metrics.get('accuracy_std', 0):.3f}\")\n",
    "                    print(f\"    F1 Score: {metrics.get('f1_mean', 0):.3f} Â± {metrics.get('f1_std', 0):.3f}\")\n",
    "                    print(f\"    Stability: {metrics.get('stability_score', 0):.3f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during analysis: {str(e)}\")\n",
    "    print(\"ðŸ”§ Try restarting the kernel and running cells 1-9 again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4886efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet bootstrap analysis functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: BERTweet Bootstrap Analysis Functions\n",
    "def load_bertweet_model_for_bootstrap(model_path: str, model_type: str):\n",
    "    print(f\"ðŸ“¥ Loading BERTweet {model_type} model from {model_path}...\")\n",
    "    \n",
    "    # Load config\n",
    "    with open(os.path.join(model_path, 'config.json'), 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    if model_type == \"multitask\":\n",
    "        # Load multitask model\n",
    "        model = BERTweetMultiTaskTransformer(\n",
    "            model_name=\"vinai/bertweet-base\",\n",
    "            sentiment_num_classes=config['sentiment_num_classes'],\n",
    "            emotion_num_classes=config['emotion_num_classes']\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        state_dict = torch.load(os.path.join(model_path, 'pytorch_model.bin'), map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "        \n",
    "        # Load encoders\n",
    "        sentiment_encoder = joblib.load(os.path.join(model_path, 'sentiment_encoder.pkl'))\n",
    "        emotion_encoder = joblib.load(os.path.join(model_path, 'emotion_encoder.pkl'))\n",
    "        \n",
    "        return model, tokenizer, sentiment_encoder, emotion_encoder\n",
    "        \n",
    "    else:\n",
    "        # Load single-task model\n",
    "        model = BERTweetSingleTaskTransformer(\n",
    "            model_name=\"vinai/bertweet-base\",\n",
    "            num_classes=config['num_classes']\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        state_dict = torch.load(os.path.join(model_path, 'pytorch_model.bin'), map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "        \n",
    "        # Load encoder\n",
    "        encoder = joblib.load(os.path.join(model_path, f'{config[\"task_type\"]}_encoder.pkl'))\n",
    "        \n",
    "        return model, tokenizer, encoder\n",
    "\n",
    "def evaluate_bertweet_on_bootstrap_sample(model, tokenizer, texts, sentiment_labels, emotion_labels, \n",
    "                                        model_sentiment_encoder, model_emotion_encoder, \n",
    "                                        data_sentiment_encoder, data_emotion_encoder, \n",
    "                                        model_type=\"multitask\", max_length=128):\n",
    "    model.eval()\n",
    "    \n",
    "    if model_type == \"multitask\":\n",
    "        sentiment_predictions = []\n",
    "        emotion_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(texts), 8):\n",
    "                batch_texts = texts[i:i+8]\n",
    "                \n",
    "                inputs = tokenizer(\n",
    "                    batch_texts,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\",\n",
    "                    max_length=max_length\n",
    "                )\n",
    "                \n",
    "                filtered_inputs = {\n",
    "                    'input_ids': inputs['input_ids'].to(device),\n",
    "                    'attention_mask': inputs['attention_mask'].to(device)\n",
    "                }\n",
    "                \n",
    "                outputs = model(**filtered_inputs)\n",
    "                \n",
    "                sentiment_preds = torch.argmax(outputs['sentiment_logits'], dim=-1)\n",
    "                emotion_preds = torch.argmax(outputs['emotion_logits'], dim=-1)\n",
    "                \n",
    "                for j in range(len(batch_texts)):\n",
    "                    sent_id = sentiment_preds[j].item()\n",
    "                    emot_id = emotion_preds[j].item()\n",
    "                    \n",
    "                    if sent_id >= len(model_sentiment_encoder.classes_):\n",
    "                        sent_id = 0\n",
    "                    if emot_id >= len(model_emotion_encoder.classes_):\n",
    "                        emot_id = 0\n",
    "                    \n",
    "                    sentiment_predictions.append(sent_id)\n",
    "                    emotion_predictions.append(emot_id)\n",
    "        \n",
    "        # Map predictions to data label space\n",
    "        mapped_sentiment_preds = []\n",
    "        mapped_emotion_preds = []\n",
    "        \n",
    "        for sent_pred, emot_pred in zip(sentiment_predictions, emotion_predictions):\n",
    "            sent_class = model_sentiment_encoder.classes_[sent_pred]\n",
    "            emot_class = model_emotion_encoder.classes_[emot_pred]\n",
    "            \n",
    "            try:\n",
    "                mapped_sent = data_sentiment_encoder.transform([sent_class])[0]\n",
    "                mapped_emot = data_emotion_encoder.transform([emot_class])[0]\n",
    "            except ValueError:\n",
    "                mapped_sent = 0\n",
    "                mapped_emot = 0\n",
    "            \n",
    "            mapped_sentiment_preds.append(mapped_sent)\n",
    "            mapped_emotion_preds.append(mapped_emot)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sentiment_accuracy = accuracy_score(sentiment_labels, mapped_sentiment_preds)\n",
    "        sentiment_f1 = f1_score(sentiment_labels, mapped_sentiment_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        emotion_accuracy = accuracy_score(emotion_labels, mapped_emotion_preds)\n",
    "        emotion_f1 = f1_score(emotion_labels, mapped_emotion_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        return {\n",
    "            'sentiment_accuracy': sentiment_accuracy,\n",
    "            'sentiment_f1': sentiment_f1,\n",
    "            'emotion_accuracy': emotion_accuracy,\n",
    "            'emotion_f1': emotion_f1\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        # Single task evaluation logic here\n",
    "        pass\n",
    "\n",
    "def bootstrap_evaluation_bertweet(model, tokenizer, data, model_sentiment_encoder, model_emotion_encoder,\n",
    "                                data_sentiment_encoder, data_emotion_encoder, \n",
    "                                n_iterations=1000, sample_size=95):\n",
    "    print(f\"ðŸ”„ Starting BERTweet bootstrap evaluation...\")\n",
    "    print(f\"   Iterations: {n_iterations}\")\n",
    "    print(f\"   Sample size: {sample_size}\")\n",
    "    \n",
    "    results = {\n",
    "        'sentiment_accuracy': [],\n",
    "        'sentiment_f1': [],\n",
    "        'emotion_accuracy': [],\n",
    "        'emotion_f1': []\n",
    "    }\n",
    "    \n",
    "    texts = data['texts']\n",
    "    sentiment_labels = data['sentiment_labels']\n",
    "    emotion_labels = data['emotion_labels']\n",
    "    n_samples = len(texts)\n",
    "    \n",
    "    for i in tqdm(range(n_iterations), desc=\"Bootstrap iterations\"):\n",
    "        # Bootstrap sample with replacement\n",
    "        indices = np.random.choice(n_samples, size=sample_size, replace=True)\n",
    "        \n",
    "        sample_texts = [texts[idx] for idx in indices]\n",
    "        sample_sentiment_labels = [sentiment_labels[idx] for idx in indices]\n",
    "        sample_emotion_labels = [emotion_labels[idx] for idx in indices]\n",
    "        \n",
    "        # Evaluate on bootstrap sample\n",
    "        metrics = evaluate_bertweet_on_bootstrap_sample(\n",
    "            model, tokenizer, sample_texts, sample_sentiment_labels, sample_emotion_labels,\n",
    "            model_sentiment_encoder, model_emotion_encoder,\n",
    "            data_sentiment_encoder, data_emotion_encoder\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results['sentiment_accuracy'].append(metrics['sentiment_accuracy'])\n",
    "        results['sentiment_f1'].append(metrics['sentiment_f1'])\n",
    "        results['emotion_accuracy'].append(metrics['emotion_accuracy'])\n",
    "        results['emotion_f1'].append(metrics['emotion_f1'])\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"BERTweet bootstrap analysis functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be94c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Running BERTweet Bootstrap Analysis\n",
      "============================================================\n",
      "\n",
      "ðŸ“¥ Loading BERTweet multitask model from ./bertweet_trained_models_seeds/bertweet_multitask_seed_42...\n",
      "ðŸ“¥ Loading BERTweet multitask model from ./bertweet_trained_models_seeds/bertweet_multitask_seed_42...\n",
      "\n",
      "ðŸ“‚ Loading Reddit evaluation data...\n",
      "Loading Reddit evaluation data from annotated_reddit_posts.csv...\n",
      "âœ… Reddit data prepared: 95 samples\n",
      "   Sentiment classes: [np.str_('Negative'), np.str_('Neutral'), np.str_('Positive')]\n",
      "   Emotion classes: [np.str_('Anger'), np.str_('Fear'), np.str_('Joy'), np.str_('No Emotion'), np.str_('Sadness'), np.str_('Surprise')]\n",
      "\n",
      "ðŸ”„ Starting bootstrap evaluation...\n",
      "ðŸ”„ Starting BERTweet bootstrap evaluation...\n",
      "   Iterations: 1000\n",
      "   Sample size: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap iterations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [06:24<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… BERTweet bootstrap analysis completed!\n",
      "\n",
      "ðŸ“Š BERTweet Bootstrap Analysis Results\n",
      "============================================================\n",
      "\n",
      "ðŸŽ¯ SENTIMENT - ACCURACY\n",
      "   Mean: 0.6091\n",
      "   Std:  0.0492\n",
      "   95% CI: [0.5053, 0.7053]\n",
      "\n",
      "ðŸŽ¯ SENTIMENT - F1\n",
      "   Mean: 0.4087\n",
      "   Std:  0.0406\n",
      "   95% CI: [0.3344, 0.4865]\n",
      "\n",
      "ðŸŽ¯ EMOTION - ACCURACY\n",
      "   Mean: 0.2831\n",
      "   Std:  0.0459\n",
      "   95% CI: [0.1895, 0.3684]\n",
      "\n",
      "ðŸŽ¯ EMOTION - F1\n",
      "   Mean: 0.1236\n",
      "   Std:  0.0215\n",
      "   95% CI: [0.0799, 0.1637]\n",
      "\n",
      "ðŸ’¾ Bootstrap results saved to: ./bertweet_seed_analysis_results/bertweet_bootstrap_results_20250724_231038.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Run BERTweet Bootstrap Analysis\n",
    "def run_bertweet_bootstrap_analysis():\n",
    "    \"\"\"Run bootstrap analysis on best BERTweet multitask model\"\"\"\n",
    "    \n",
    "    print(\"ðŸš€ Running BERTweet Bootstrap Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load the best BERTweet multitask model (using seed 42 as example)\n",
    "    model_path = \"./bertweet_trained_models_seeds/bertweet_multitask_seed_42\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"\\nðŸ“¥ Loading BERTweet multitask model from {model_path}...\")\n",
    "        model, tokenizer, model_sentiment_encoder, model_emotion_encoder = load_bertweet_model_for_bootstrap(\n",
    "            model_path, \"multitask\"\n",
    "        )\n",
    "        \n",
    "        # Load Reddit data\n",
    "        print(\"\\nðŸ“‚ Loading Reddit evaluation data...\")\n",
    "        reddit_data = prepare_reddit_evaluation_data(\"annotated_reddit_posts.csv\")\n",
    "        \n",
    "        # Run bootstrap evaluation\n",
    "        print(\"\\nðŸ”„ Starting bootstrap evaluation...\")\n",
    "        bootstrap_results = bootstrap_evaluation_bertweet(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            data=reddit_data,\n",
    "            model_sentiment_encoder=model_sentiment_encoder,\n",
    "            model_emotion_encoder=model_emotion_encoder,\n",
    "            data_sentiment_encoder=reddit_data['sentiment_encoder'],\n",
    "            data_emotion_encoder=reddit_data['emotion_encoder'],\n",
    "            n_iterations=1000,\n",
    "            sample_size=95\n",
    "        )\n",
    "        \n",
    "        print(\"\\nâœ… BERTweet bootstrap analysis completed!\")\n",
    "        \n",
    "        # Calculate statistics\n",
    "        def calculate_bootstrap_statistics(results):\n",
    "            statistics = {}\n",
    "            for metric_name, values in results.items():\n",
    "                values = np.array(values)\n",
    "                mean = np.mean(values)\n",
    "                std = np.std(values)\n",
    "                ci_lower = np.percentile(values, 2.5)\n",
    "                ci_upper = np.percentile(values, 97.5)\n",
    "                \n",
    "                statistics[metric_name] = {\n",
    "                    'mean': mean,\n",
    "                    'std': std,\n",
    "                    'ci_lower': ci_lower,\n",
    "                    'ci_upper': ci_upper,\n",
    "                    'values': values\n",
    "                }\n",
    "            return statistics\n",
    "        \n",
    "        bootstrap_stats = calculate_bootstrap_statistics(bootstrap_results)\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nðŸ“Š BERTweet Bootstrap Analysis Results\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for metric_name, stats in bootstrap_stats.items():\n",
    "            task, measure = metric_name.split('_')\n",
    "            print(f\"\\nðŸŽ¯ {task.upper()} - {measure.upper()}\")\n",
    "            print(f\"   Mean: {stats['mean']:.4f}\")\n",
    "            print(f\"   Std:  {stats['std']:.4f}\")\n",
    "            print(f\"   95% CI: [{stats['ci_lower']:.4f}, {stats['ci_upper']:.4f}]\")\n",
    "        \n",
    "        # Save bootstrap results\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Save detailed results\n",
    "        results_file = f\"./bertweet_seed_analysis_results/bertweet_bootstrap_results_{timestamp}.json\"\n",
    "        serializable_results = {}\n",
    "        for metric_name, stats in bootstrap_stats.items():\n",
    "            serializable_results[metric_name] = {\n",
    "                'mean': float(stats['mean']),\n",
    "                'std': float(stats['std']),\n",
    "                'ci_lower': float(stats['ci_lower']),\n",
    "                'ci_upper': float(stats['ci_upper']),\n",
    "                'values': [float(x) for x in stats['values']]\n",
    "            }\n",
    "        \n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(serializable_results, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nðŸ’¾ Bootstrap results saved to: {results_file}\")\n",
    "        \n",
    "        return bootstrap_stats\n",
    "    \n",
    "    else:\n",
    "        print(f\"âŒ Model not found at {model_path}\")\n",
    "        print(\"Please run the random seed analysis first to train the models.\")\n",
    "        return None\n",
    "\n",
    "# Run bootstrap analysis\n",
    "bootstrap_stats = run_bertweet_bootstrap_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dd7fb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ‰ BERTWEET COMPREHENSIVE ANALYSIS COMPLETED!\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ Generated Files:\n",
      "   ðŸ—‚ï¸  ./bertweet_seed_analysis_results/\n",
      "      ðŸ“„ bertweet_raw_results_[timestamp].json\n",
      "      ðŸ“„ bertweet_stability_analysis_[timestamp].json\n",
      "      ðŸ“„ bertweet_summary_report_[timestamp].txt\n",
      "      ðŸ“„ bertweet_bootstrap_results_[timestamp].json\n",
      "      ðŸ“Š bertweet_bootstrap_accuracy_distributions.png\n",
      "      ðŸ“Š bertweet_bootstrap_f1_distributions.png\n",
      "\n",
      "ðŸ—‚ï¸  ./bertweet_trained_models_seeds/\n",
      "      ðŸ“¦ bertweet_sentiment_seed_[42,123,456,789,999]/\n",
      "      ðŸ“¦ bertweet_emotion_seed_[42,123,456,789,999]/\n",
      "      ðŸ“¦ bertweet_multitask_seed_[42,123,456,789,999]/\n",
      "\n",
      "ðŸ“Š Analysis Summary:\n",
      "   âœ… Random seed stability analysis across 5 seeds\n",
      "   âœ… Bootstrap confidence intervals (1000 iterations)\n",
      "   âœ… Performance comparison across all BERTweet variants\n",
      "   âœ… Statistical significance testing\n",
      "   âœ… Visual distributions of performance metrics\n",
      "\n",
      "ðŸŽ¯ Key Insights:\n",
      "   ðŸ“ˆ Check stability analysis for model reliability\n",
      "   ðŸ“Š Review bootstrap CIs for statistical significance\n",
      "   ðŸ† Identify best performing BERTweet configuration\n",
      "   ðŸ“‹ Use results for model selection and reporting\n",
      "\n",
      "âœ¨ Analysis completed using optimized BERTweet hyperparameters!\n",
      "ðŸ”¬ Results provide robust evaluation of model performance with uncertainty quantification.\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Final Summary Report\n",
    "print(\"\\nðŸŽ‰ BERTWEET COMPREHENSIVE ANALYSIS COMPLETED!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nðŸ“ Generated Files:\")\n",
    "print(\"   ðŸ—‚ï¸  ./bertweet_seed_analysis_results/\")\n",
    "print(\"      ðŸ“„ bertweet_raw_results_[timestamp].json\")\n",
    "print(\"      ðŸ“„ bertweet_stability_analysis_[timestamp].json\") \n",
    "print(\"      ðŸ“„ bertweet_summary_report_[timestamp].txt\")\n",
    "print(\"      ðŸ“„ bertweet_bootstrap_results_[timestamp].json\")\n",
    "print(\"      ðŸ“Š bertweet_bootstrap_accuracy_distributions.png\")\n",
    "print(\"      ðŸ“Š bertweet_bootstrap_f1_distributions.png\")\n",
    "\n",
    "print(\"\\nðŸ—‚ï¸  ./bertweet_trained_models_seeds/\")\n",
    "print(\"      ðŸ“¦ bertweet_sentiment_seed_[42,123,456,789,999]/\")\n",
    "print(\"      ðŸ“¦ bertweet_emotion_seed_[42,123,456,789,999]/\")\n",
    "print(\"      ðŸ“¦ bertweet_multitask_seed_[42,123,456,789,999]/\")\n",
    "\n",
    "print(\"\\nðŸ“Š Analysis Summary:\")\n",
    "print(\"   âœ… Random seed stability analysis across 5 seeds\")\n",
    "print(\"   âœ… Bootstrap confidence intervals (1000 iterations)\")\n",
    "print(\"   âœ… Performance comparison across all BERTweet variants\")\n",
    "print(\"   âœ… Statistical significance testing\")\n",
    "print(\"   âœ… Visual distributions of performance metrics\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Key Insights:\")\n",
    "print(\"   ðŸ“ˆ Check stability analysis for model reliability\")\n",
    "print(\"   ðŸ“Š Review bootstrap CIs for statistical significance\")\n",
    "print(\"   ðŸ† Identify best performing BERTweet configuration\")\n",
    "print(\"   ðŸ“‹ Use results for model selection and reporting\")\n",
    "\n",
    "print(f\"\\nâœ¨ Analysis completed using optimized BERTweet hyperparameters!\")\n",
    "print(f\"ðŸ”¬ Results provide robust evaluation of model performance with uncertainty quantification.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
