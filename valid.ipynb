{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e5dbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✅ Libraries imported and setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports for BERTweet Seed & Bootstrap Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, AutoConfig,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import random\n",
    "from collections import Counter\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"./bertweet_seed_analysis_results\", exist_ok=True)\n",
    "os.makedirs(\"./bertweet_trained_models_seeds\", exist_ok=True)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "print(\"✅ Libraries imported and setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95fc10fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Utility functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Utility Functions for BERTweet Analysis\n",
    "def set_random_seed(seed: int):\n",
    "    \"\"\"Set random seed for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def print_memory_usage():\n",
    "    \"\"\"Print current GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f} GB, Cached: {cached:.2f} GB\")\n",
    "\n",
    "print(\"✅ Utility functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee15564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BERTweet model architectures defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: BERTweet Model Architectures\n",
    "class BERTweetSingleTaskTransformer(nn.Module):\n",
    "    \"\"\"Single-task BERTweet model for sentiment OR emotion classification\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"vinai/bertweet-base\",\n",
    "        num_classes: int = 3,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load BERTweet model\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        self.bertweet = AutoModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        # Classification head\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(self.bertweet.config.hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERTweet outputs\n",
    "        outputs = self.bertweet(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return {'logits': logits}\n",
    "\n",
    "class BERTweetMultiTaskTransformer(nn.Module):\n",
    "    \"\"\"Multi-task BERTweet model for sentiment AND emotion classification\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"vinai/bertweet-base\",\n",
    "        sentiment_num_classes: int = 3,\n",
    "        emotion_num_classes: int = 6,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sentiment_num_classes = sentiment_num_classes\n",
    "        self.emotion_num_classes = emotion_num_classes\n",
    "        \n",
    "        # Load BERTweet model\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        self.bertweet = AutoModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        hidden_size = self.bertweet.config.hidden_size\n",
    "        \n",
    "        # Task-specific attention layers\n",
    "        self.sentiment_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.emotion_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Shared attention for common features\n",
    "        self.shared_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.sentiment_norm = nn.LayerNorm(hidden_size)\n",
    "        self.emotion_norm = nn.LayerNorm(hidden_size)\n",
    "        self.shared_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.sentiment_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.emotion_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.shared_dropout = nn.Dropout(classifier_dropout)\n",
    "        \n",
    "        # Classification heads\n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, sentiment_num_classes)\n",
    "        )\n",
    "        \n",
    "        self.emotion_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, emotion_num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in [self.sentiment_classifier, self.emotion_classifier]:\n",
    "            for layer in module:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        # Shared encoder\n",
    "        encoder_outputs = self.bertweet(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        sequence_output = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply shared attention\n",
    "        shared_attended, _ = self.shared_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        shared_attended = self.shared_norm(shared_attended + sequence_output)\n",
    "        shared_attended = self.shared_dropout(shared_attended)\n",
    "        shared_pooled = shared_attended[:, 0, :]\n",
    "        \n",
    "        outputs = {}\n",
    "        \n",
    "        # Sentiment branch\n",
    "        sentiment_attended, _ = self.sentiment_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        sentiment_attended = self.sentiment_norm(sentiment_attended + sequence_output)\n",
    "        sentiment_attended = self.sentiment_dropout(sentiment_attended)\n",
    "        sentiment_pooled = sentiment_attended[:, 0, :]\n",
    "        sentiment_features = torch.cat([shared_pooled, sentiment_pooled], dim=-1)\n",
    "        sentiment_logits = self.sentiment_classifier(sentiment_features)\n",
    "        outputs[\"sentiment_logits\"] = sentiment_logits\n",
    "        \n",
    "        # Emotion branch\n",
    "        emotion_attended, _ = self.emotion_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        emotion_attended = self.emotion_norm(emotion_attended + sequence_output)\n",
    "        emotion_attended = self.emotion_dropout(emotion_attended)\n",
    "        emotion_pooled = emotion_attended[:, 0, :]\n",
    "        emotion_features = torch.cat([shared_pooled, emotion_pooled], dim=-1)\n",
    "        emotion_logits = self.emotion_classifier(emotion_features)\n",
    "        outputs[\"emotion_logits\"] = emotion_logits\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "print(\"✅ BERTweet model architectures defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84190c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BERTweet dataset classes defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Dataset Classes for BERTweet\n",
    "class BERTweetDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer, max_length: int = 128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class BERTweetMultiTaskDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], sentiment_labels: List[int], \n",
    "                 emotion_labels: List[int], tokenizer, max_length: int = 128):\n",
    "        self.texts = texts\n",
    "        self.sentiment_labels = sentiment_labels\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        sentiment_label = self.sentiment_labels[idx]\n",
    "        emotion_label = self.emotion_labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'sentiment_labels': torch.tensor(sentiment_label, dtype=torch.long),\n",
    "            'emotion_labels': torch.tensor(emotion_label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"✅ BERTweet dataset classes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbceadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loading functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Data Loading Functions for BERTweet Analysis\n",
    "def load_external_datasets() -> Tuple[Dict, Dict]:\n",
    "    \"\"\"Load SST-2 and GoEmotions datasets\"\"\"\n",
    "    print(\"Loading external datasets...\")\n",
    "    \n",
    "    # Load SST-2 for sentiment\n",
    "    try:\n",
    "        sst2_dataset = load_dataset(\"sst2\")\n",
    "        sentiment_data = {\n",
    "            'train': sst2_dataset['train'],\n",
    "            'validation': sst2_dataset['validation']\n",
    "        }\n",
    "        print(f\"✅ SST-2 dataset loaded: {len(sentiment_data['train'])} train samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Could not load SST-2: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Load GoEmotions for emotion\n",
    "    try:\n",
    "        emotions_dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "        emotion_data = {\n",
    "            'train': emotions_dataset['train'],\n",
    "            'validation': emotions_dataset['validation']\n",
    "        }\n",
    "        print(f\"✅ GoEmotions dataset loaded: {len(emotion_data['train'])} train samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Could not load GoEmotions: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return sentiment_data, emotion_data\n",
    "\n",
    "def prepare_reddit_evaluation_data(reddit_data_path: str) -> Dict:\n",
    "    \"\"\"Load and prepare Reddit data for evaluation\"\"\"\n",
    "    print(f\"Loading Reddit evaluation data from {reddit_data_path}...\")\n",
    "    \n",
    "    df = pd.read_csv(reddit_data_path)\n",
    "    \n",
    "    # Create label encoders that match BERTweet models\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    \n",
    "    # Fit encoders\n",
    "    sentiment_encoder.fit(df['sentiment'].tolist())\n",
    "    emotion_encoder.fit(df['emotion'].tolist())\n",
    "    \n",
    "    reddit_data = {\n",
    "        'texts': df['text_content'].tolist(),\n",
    "        'sentiment_labels_text': df['sentiment'].tolist(),\n",
    "        'emotion_labels_text': df['emotion'].tolist(),\n",
    "        'sentiment_labels': sentiment_encoder.transform(df['sentiment'].tolist()),\n",
    "        'emotion_labels': emotion_encoder.transform(df['emotion'].tolist()),\n",
    "        'sentiment_encoder': sentiment_encoder,\n",
    "        'emotion_encoder': emotion_encoder\n",
    "    }\n",
    "    \n",
    "    print(f\"✅ Reddit data prepared: {len(reddit_data['texts'])} samples\")\n",
    "    print(f\"   Sentiment classes: {list(sentiment_encoder.classes_)}\")\n",
    "    print(f\"   Emotion classes: {list(emotion_encoder.classes_)}\")\n",
    "    \n",
    "    return reddit_data\n",
    "\n",
    "def prepare_bertweet_training_data(sentiment_data: Dict, emotion_data: Dict, max_samples: int = 5000):\n",
    "    \"\"\"Prepare training data for BERTweet models\"\"\"\n",
    "    \n",
    "    # Process sentiment data (SST-2 to 3 classes)\n",
    "    sentiment_texts = sentiment_data['train']['sentence'][:max_samples]\n",
    "    sentiment_labels_raw = sentiment_data['train']['label'][:max_samples]\n",
    "    \n",
    "    # Convert SST-2 binary to 3-class sentiment\n",
    "    sentiment_labels = []\n",
    "    for label in sentiment_labels_raw:\n",
    "        if label == 0:  # Negative\n",
    "            sentiment_labels.append(0)\n",
    "        elif label == 1:  # Positive\n",
    "            if np.random.random() < 0.15:  # 15% chance to be neutral\n",
    "                sentiment_labels.append(1)  # Neutral\n",
    "            else:\n",
    "                sentiment_labels.append(2)  # Positive\n",
    "    \n",
    "    # Ensure we have all 3 classes\n",
    "    if 1 not in sentiment_labels:\n",
    "        neutral_indices = np.random.choice(len(sentiment_labels), size=100, replace=False)\n",
    "        for idx in neutral_indices:\n",
    "            sentiment_labels[idx] = 1\n",
    "    \n",
    "    # Process emotion data (filter to first 6 classes)\n",
    "    emotion_texts_all = emotion_data['train']['text']\n",
    "    emotion_labels_all = emotion_data['train']['labels']\n",
    "    \n",
    "    emotion_texts = []\n",
    "    emotion_labels = []\n",
    "    count = 0\n",
    "    for i, label in enumerate(emotion_labels_all):\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "        if isinstance(label, list):\n",
    "            if label and label[0] in range(6):\n",
    "                emotion_texts.append(emotion_texts_all[i])\n",
    "                emotion_labels.append(label[0])\n",
    "                count += 1\n",
    "        else:\n",
    "            if label in range(6):\n",
    "                emotion_texts.append(emotion_texts_all[i])\n",
    "                emotion_labels.append(label)\n",
    "                count += 1\n",
    "    \n",
    "    # Create encoders\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    sentiment_encoder.classes_ = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "    emotion_encoder.classes_ = np.array(['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise'])\n",
    "    \n",
    "    return {\n",
    "        'sentiment_data': {\n",
    "            'texts': sentiment_texts,\n",
    "            'labels': sentiment_labels,\n",
    "            'encoder': sentiment_encoder\n",
    "        },\n",
    "        'emotion_data': {\n",
    "            'texts': emotion_texts,\n",
    "            'labels': emotion_labels,\n",
    "            'encoder': emotion_encoder\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"✅ Data loading functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82afd1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BERTweet training functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: BERTweet Training Functions with Best Parameters\n",
    "def train_bertweet_single_task(\n",
    "    task_type: str,  # 'sentiment' or 'emotion'\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    training_data: Dict,\n",
    "    max_samples: int = 5000\n",
    ") -> Tuple[any, LabelEncoder]:\n",
    "    \"\"\"Train a single-task BERTweet model with best parameters\"\"\"\n",
    "    \n",
    "    print(f\"🚀 Training BERTweet {task_type} model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Get appropriate data\n",
    "    if task_type == 'sentiment':\n",
    "        texts = training_data['sentiment_data']['texts'][:max_samples]\n",
    "        labels = training_data['sentiment_data']['labels'][:max_samples]\n",
    "        encoder = training_data['sentiment_data']['encoder']\n",
    "        num_classes = 3\n",
    "    else:  # emotion\n",
    "        texts = training_data['emotion_data']['texts'][:max_samples]\n",
    "        labels = training_data['emotion_data']['labels'][:max_samples]\n",
    "        encoder = training_data['emotion_data']['encoder']\n",
    "        num_classes = 6\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model\n",
    "    model = BERTweetSingleTaskTransformer(\n",
    "        model_name='vinai/bertweet-base',\n",
    "        num_classes=num_classes,\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        attention_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = BERTweetDataset(texts, labels, tokenizer, max_length=128)\n",
    "    dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    total_steps = len(dataloader) * 3  # 3 epochs\n",
    "    warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    print(f\"Starting training for 3 epochs...\")\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels_batch = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs['logits'], labels_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/3, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    output_dir = f\"./bertweet_trained_models_seeds/bertweet_{task_type}_seed_{seed}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model state dict\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "    \n",
    "    # Save config\n",
    "    config = {\n",
    "        \"model_name\": \"vinai/bertweet-base\",\n",
    "        \"num_classes\": num_classes,\n",
    "        \"task_type\": task_type,\n",
    "        \"model_type\": \"BERTweetSingleTaskTransformer\"\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"config.json\"), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save tokenizer and encoder\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(encoder, os.path.join(output_dir, f'{task_type}_encoder.pkl'))\n",
    "    \n",
    "    print(f\"✅ BERTweet {task_type} model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, encoder\n",
    "\n",
    "def train_bertweet_multitask(\n",
    "    best_params: Dict,\n",
    "    seed: int,\n",
    "    training_data: Dict,\n",
    "    max_samples: int = 2000\n",
    ") -> Tuple[any, LabelEncoder, LabelEncoder]:\n",
    "    \"\"\"Train a BERTweet multitask model with best parameters\"\"\"\n",
    "    \n",
    "    print(f\"🚀 Training BERTweet multitask model with seed {seed}\")\n",
    "    set_random_seed(seed)\n",
    "    clear_memory()\n",
    "    \n",
    "    # Prepare multitask data (combine sentiment and emotion data)\n",
    "    min_length = min(len(training_data['sentiment_data']['texts']), \n",
    "                     len(training_data['emotion_data']['texts']))\n",
    "    min_length = min(min_length, max_samples)\n",
    "    \n",
    "    combined_texts = training_data['sentiment_data']['texts'][:min_length]\n",
    "    combined_sentiment_labels = training_data['sentiment_data']['labels'][:min_length]\n",
    "    combined_emotion_labels = training_data['emotion_data']['labels'][:min_length]\n",
    "    \n",
    "    sentiment_encoder = training_data['sentiment_data']['encoder']\n",
    "    emotion_encoder = training_data['emotion_data']['encoder']\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model\n",
    "    model = BERTweetMultiTaskTransformer(\n",
    "        model_name='vinai/bertweet-base',\n",
    "        sentiment_num_classes=3,\n",
    "        emotion_num_classes=6,\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        attention_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = BERTweetMultiTaskDataset(\n",
    "        combined_texts, combined_sentiment_labels, combined_emotion_labels, \n",
    "        tokenizer, max_length=128\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    total_steps = len(dataloader) * 3  # 3 epochs\n",
    "    warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Loss functions\n",
    "    sentiment_criterion = nn.CrossEntropyLoss()\n",
    "    emotion_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    alpha = best_params['alpha']\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    print(f\"Starting training for 3 epochs...\")\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            sentiment_labels = batch['sentiment_labels'].to(device)\n",
    "            emotion_labels = batch['emotion_labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Calculate losses\n",
    "            sentiment_loss = sentiment_criterion(outputs['sentiment_logits'], sentiment_labels)\n",
    "            emotion_loss = emotion_criterion(outputs['emotion_logits'], emotion_labels)\n",
    "            \n",
    "            # Combined loss\n",
    "            total_loss_batch = alpha * sentiment_loss + (1 - alpha) * emotion_loss\n",
    "            total_loss += total_loss_batch.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/3, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    output_dir = f\"./bertweet_trained_models_seeds/bertweet_multitask_seed_{seed}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model state dict\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "    \n",
    "    # Save config\n",
    "    config = {\n",
    "        \"model_name\": \"vinai/bertweet-base\",\n",
    "        \"sentiment_num_classes\": 3,\n",
    "        \"emotion_num_classes\": 6,\n",
    "        \"model_type\": \"BERTweetMultiTaskTransformer\"\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"config.json\"), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save tokenizer and encoders\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    joblib.dump(sentiment_encoder, os.path.join(output_dir, 'sentiment_encoder.pkl'))\n",
    "    joblib.dump(emotion_encoder, os.path.join(output_dir, 'emotion_encoder.pkl'))\n",
    "    \n",
    "    print(f\"✅ BERTweet multitask model trained and saved with seed {seed}\")\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, sentiment_encoder, emotion_encoder\n",
    "\n",
    "print(\"✅ BERTweet training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d9d59bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BERTweet evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Evaluation Functions for BERTweet Models\n",
    "def evaluate_bertweet_single_task(model, tokenizer, label_encoder, reddit_data: Dict, task_type: str) -> Dict:\n",
    "    \"\"\"Evaluate a single-task BERTweet model on Reddit data\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_labels = reddit_data[f'{task_type}_labels']\n",
    "    \n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 16):  # Batch size 16\n",
    "            batch_texts = texts[i:i+16]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=128\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items() if k in ['input_ids', 'attention_mask']}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs['logits']\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                pred_id = preds[j].item()\n",
    "                confidence = probs[j][pred_id].item()\n",
    "                \n",
    "                # Handle out of range predictions\n",
    "                if pred_id >= len(label_encoder.classes_):\n",
    "                    pred_id = 0\n",
    "                \n",
    "                predictions.append(pred_id)\n",
    "                confidences.append(confidence)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    macro_f1 = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'predictions': predictions,\n",
    "        'confidences': confidences,\n",
    "        'true_labels': true_labels\n",
    "    }\n",
    "\n",
    "def evaluate_bertweet_multitask(model, tokenizer, sentiment_encoder, emotion_encoder, \n",
    "                               reddit_data: Dict, max_length: int = 128) -> Dict:\n",
    "    \"\"\"Evaluate a BERTweet multitask model on Reddit data\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    texts = reddit_data['texts']\n",
    "    true_sentiment_labels = reddit_data['sentiment_labels']\n",
    "    true_emotion_labels = reddit_data['emotion_labels']\n",
    "    \n",
    "    sentiment_predictions = []\n",
    "    emotion_predictions = []\n",
    "    sentiment_confidences = []\n",
    "    emotion_confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 8):  # Smaller batch size for multitask\n",
    "            batch_texts = texts[i:i+8]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=max_length\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items() if k in ['input_ids', 'attention_mask']}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            # Process sentiment\n",
    "            sentiment_logits = outputs['sentiment_logits']\n",
    "            sentiment_probs = F.softmax(sentiment_logits, dim=-1)\n",
    "            sentiment_preds = torch.argmax(sentiment_logits, dim=-1)\n",
    "            \n",
    "            # Process emotion\n",
    "            emotion_logits = outputs['emotion_logits']\n",
    "            emotion_probs = F.softmax(emotion_logits, dim=-1)\n",
    "            emotion_preds = torch.argmax(emotion_logits, dim=-1)\n",
    "            \n",
    "            # Collect results\n",
    "            for j in range(len(batch_texts)):\n",
    "                # Sentiment\n",
    "                sent_id = sentiment_preds[j].item()\n",
    "                sent_conf = sentiment_probs[j][sent_id].item()\n",
    "                if sent_id >= len(sentiment_encoder.classes_):\n",
    "                    sent_id = 0\n",
    "                sentiment_predictions.append(sent_id)\n",
    "                sentiment_confidences.append(sent_conf)\n",
    "                \n",
    "                # Emotion\n",
    "                emot_id = emotion_preds[j].item()\n",
    "                emot_conf = emotion_probs[j][emot_id].item()\n",
    "                if emot_id >= len(emotion_encoder.classes_):\n",
    "                    emot_id = 0\n",
    "                emotion_predictions.append(emot_id)\n",
    "                emotion_confidences.append(emot_conf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    sentiment_accuracy = accuracy_score(true_sentiment_labels, sentiment_predictions)\n",
    "    sentiment_f1 = f1_score(true_sentiment_labels, sentiment_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    emotion_accuracy = accuracy_score(true_emotion_labels, emotion_predictions)\n",
    "    emotion_f1 = f1_score(true_emotion_labels, emotion_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'sentiment': {\n",
    "            'accuracy': sentiment_accuracy,\n",
    "            'macro_f1': sentiment_f1,\n",
    "            'predictions': sentiment_predictions,\n",
    "            'confidences': sentiment_confidences\n",
    "        },\n",
    "        'emotion': {\n",
    "            'accuracy': emotion_accuracy,\n",
    "            'macro_f1': emotion_f1,\n",
    "            'predictions': emotion_predictions,\n",
    "            'confidences': emotion_confidences\n",
    "        },\n",
    "        'combined_accuracy': (sentiment_accuracy + emotion_accuracy) / 2,\n",
    "        'combined_f1': (sentiment_f1 + emotion_f1) / 2\n",
    "    }\n",
    "\n",
    "print(\"✅ BERTweet evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cd8e3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BERTweet random seed analysis function defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: BERTweet Random Seed Analysis Function\n",
    "def run_bertweet_seed_analysis(\n",
    "    reddit_data_path: str = \"annotated_reddit_posts.csv\",\n",
    "    seeds: List[int] = [42, 123, 456, 789, 999],\n",
    "    max_training_samples: int = 3000\n",
    "):\n",
    "    \"\"\"Run complete random seed analysis for BERTweet models\"\"\"\n",
    "    \n",
    "    print(\"🎲 STARTING BERTWEET RANDOM SEED ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Seeds to test: {seeds}\")\n",
    "    print(f\"Max training samples per dataset: {max_training_samples}\")\n",
    "    \n",
    "    # Load external datasets\n",
    "    print(\"\\n📂 Loading external datasets...\")\n",
    "    sentiment_data, emotion_data = load_external_datasets()\n",
    "    \n",
    "    # Prepare training data\n",
    "    print(\"\\n🔄 Preparing BERTweet training data...\")\n",
    "    training_data = prepare_bertweet_training_data(sentiment_data, emotion_data, max_training_samples)\n",
    "    \n",
    "    # Load Reddit evaluation data\n",
    "    print(\"\\n📂 Loading Reddit evaluation data...\")\n",
    "    reddit_data = prepare_reddit_evaluation_data(reddit_data_path)\n",
    "    \n",
    "    # Define best parameters for each BERTweet model\n",
    "    best_params = {\n",
    "        'sentiment': {\n",
    "            'learning_rate': 3.65445235521325e-05,\n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.15986584841970367,\n",
    "            'weight_decay': 0.02404167763981929,\n",
    "            'hidden_dropout_prob': 0.13119890406724052,\n",
    "            'classifier_dropout': 0.1116167224336399\n",
    "        },\n",
    "        'emotion': {\n",
    "            'learning_rate': 7.3464156009241e-05,\n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.1684233026512157,\n",
    "            'weight_decay': 0.04961372443656412,\n",
    "            'hidden_dropout_prob': 0.12440764696895577,\n",
    "            'classifier_dropout': 0.19903538202225401\n",
    "        },\n",
    "        'multitask': {\n",
    "            'learning_rate': 5.262490902114904e-05,\n",
    "            'batch_size': 16,\n",
    "            'warmup_ratio': 0.19699098521619945,\n",
    "            'weight_decay': 0.08491983767203796,\n",
    "            'hidden_dropout_prob': 0.14246782213565523,\n",
    "            'classifier_dropout': 0.1363649934414201,\n",
    "            'alpha': 0.43668090197068676\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Store results for each seed\n",
    "    all_results = {}\n",
    "    \n",
    "    for seed in seeds:\n",
    "        print(f\"\\n🌱 TRAINING AND EVALUATING BERTWEET WITH SEED {seed}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        seed_results = {}\n",
    "        \n",
    "        # 1. Train and evaluate BERTweet Sentiment\n",
    "        print(f\"\\n1️⃣ BERTweet Sentiment (Seed {seed})\")\n",
    "        model, encoder = train_bertweet_single_task(\n",
    "            'sentiment', best_params['sentiment'], seed, \n",
    "            training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_sentiment_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_bertweet_single_task(model, tokenizer, encoder, reddit_data, 'sentiment')\n",
    "        seed_results['bertweet_sentiment'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 2. Train and evaluate BERTweet Emotion\n",
    "        print(f\"\\n2️⃣ BERTweet Emotion (Seed {seed})\")\n",
    "        model, encoder = train_bertweet_single_task(\n",
    "            'emotion', best_params['emotion'], seed,\n",
    "            training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_emotion_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_bertweet_single_task(model, tokenizer, encoder, reddit_data, 'emotion')\n",
    "        seed_results['bertweet_emotion'] = results\n",
    "        print(f\"   Accuracy: {results['accuracy']:.4f}, Macro F1: {results['macro_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        # 3. Train and evaluate BERTweet Multitask\n",
    "        print(f\"\\n3️⃣ BERTweet Multitask (Seed {seed})\")\n",
    "        model, sent_enc, emot_enc = train_bertweet_multitask(\n",
    "            best_params['multitask'], seed, training_data, max_training_samples\n",
    "        )\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f\"./bertweet_trained_models_seeds/bertweet_multitask_seed_{seed}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_bertweet_multitask(\n",
    "            model, tokenizer, sent_enc, emot_enc, reddit_data, 128\n",
    "        )\n",
    "        seed_results['bertweet_multitask'] = results\n",
    "        print(f\"   Sentiment - Accuracy: {results['sentiment']['accuracy']:.4f}, F1: {results['sentiment']['macro_f1']:.4f}\")\n",
    "        print(f\"   Emotion - Accuracy: {results['emotion']['accuracy']:.4f}, F1: {results['emotion']['macro_f1']:.4f}\")\n",
    "        print(f\"   Combined - Accuracy: {results['combined_accuracy']:.4f}, F1: {results['combined_f1']:.4f}\")\n",
    "        \n",
    "        del model, tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "        all_results[seed] = seed_results\n",
    "        \n",
    "        print(f\"\\n✅ Completed evaluation for seed {seed}\")\n",
    "    \n",
    "    # Analyze stability across seeds\n",
    "    print(f\"\\n📊 ANALYZING BERTWEET STABILITY ACROSS SEEDS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    stability_analysis = analyze_bertweet_seed_stability(all_results, seeds)\n",
    "    \n",
    "    # Save results\n",
    "    save_bertweet_results(all_results, stability_analysis, seeds)\n",
    "    \n",
    "    return all_results, stability_analysis\n",
    "\n",
    "print(\"✅ BERTweet random seed analysis function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05c3b9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BERTweet stability analysis functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: BERTweet Stability Analysis Functions\n",
    "def analyze_bertweet_seed_stability(all_results: Dict, seeds: List[int]) -> Dict:\n",
    "    \"\"\"Analyze stability of BERTweet models across different seeds\"\"\"\n",
    "    \n",
    "    stability_stats = {}\n",
    "    \n",
    "    # Define model-task combinations\n",
    "    evaluations = [\n",
    "        ('bertweet_sentiment', 'sentiment'),\n",
    "        ('bertweet_emotion', 'emotion'),\n",
    "        ('bertweet_multitask', 'sentiment'),\n",
    "        ('bertweet_multitask', 'emotion')\n",
    "    ]\n",
    "    \n",
    "    for model_name, task in evaluations:\n",
    "        print(f\"\\n🔍 {model_name.upper()} - {task.upper()}\")\n",
    "        \n",
    "        accuracies = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        for seed in seeds:\n",
    "            if model_name in all_results[seed]:\n",
    "                result = all_results[seed][model_name]\n",
    "                \n",
    "                if model_name.endswith('_multitask'):\n",
    "                    acc = result[task]['accuracy']\n",
    "                    f1 = result[task]['macro_f1']\n",
    "                else:\n",
    "                    acc = result['accuracy']\n",
    "                    f1 = result['macro_f1']\n",
    "                \n",
    "                accuracies.append(acc)\n",
    "                f1_scores.append(f1)\n",
    "        \n",
    "        if accuracies:\n",
    "            acc_mean = np.mean(accuracies)\n",
    "            acc_std = np.std(accuracies)\n",
    "            f1_mean = np.mean(f1_scores)\n",
    "            f1_std = np.std(f1_scores)\n",
    "            \n",
    "            stability_stats[f\"{model_name}_{task}\"] = {\n",
    "                'accuracy_mean': acc_mean,\n",
    "                'accuracy_std': acc_std,\n",
    "                'f1_mean': f1_mean,\n",
    "                'f1_std': f1_std,\n",
    "                'accuracy_values': accuracies,\n",
    "                'f1_values': f1_scores\n",
    "            }\n",
    "            \n",
    "            print(f\"   Accuracy: {acc_mean:.4f} ± {acc_std:.4f}\")\n",
    "            print(f\"   Macro F1: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "    \n",
    "    return stability_stats\n",
    "\n",
    "def save_bertweet_results(all_results: Dict, stability_analysis: Dict, seeds: List[int]):\n",
    "    \"\"\"Save BERTweet results to files\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save raw results\n",
    "    results_file = f\"./bertweet_seed_analysis_results/bertweet_raw_results_{timestamp}.json\"\n",
    "    with open(results_file, 'w') as f:\n",
    "        # Convert numpy types to Python types for JSON serialization\n",
    "        serializable_results = {}\n",
    "        for seed, seed_results in all_results.items():\n",
    "            serializable_results[str(seed)] = {}\n",
    "            for model, results in seed_results.items():\n",
    "                if isinstance(results, dict):\n",
    "                    serializable_results[str(seed)][model] = {}\n",
    "                    for key, value in results.items():\n",
    "                        if isinstance(value, dict):\n",
    "                            serializable_results[str(seed)][model][key] = {\n",
    "                                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                                   [float(x) if isinstance(x, (np.floating, np.integer)) else x for x in v] if isinstance(v, list) else v\n",
    "                                for k, v in value.items()\n",
    "                            }\n",
    "                        else:\n",
    "                            serializable_results[str(seed)][model][key] = float(value) if isinstance(value, (np.floating, np.integer)) else value\n",
    "        \n",
    "        json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    # Save stability analysis\n",
    "    stability_file = f\"./bertweet_seed_analysis_results/bertweet_stability_analysis_{timestamp}.json\"\n",
    "    with open(stability_file, 'w') as f:\n",
    "        serializable_stability = {}\n",
    "        for key, stats in stability_analysis.items():\n",
    "            serializable_stability[key] = {\n",
    "                k: float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                   [float(x) for x in v] if isinstance(v, list) else v\n",
    "                for k, v in stats.items()\n",
    "            }\n",
    "        json.dump(serializable_stability, f, indent=2)\n",
    "    \n",
    "    # Create summary report\n",
    "    summary_file = f\"./bertweet_seed_analysis_results/bertweet_summary_report_{timestamp}.txt\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"BERTWEET RANDOM SEED ANALYSIS SUMMARY REPORT\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        f.write(f\"Seeds tested: {seeds}\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"STABILITY ANALYSIS (Mean ± Std)\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        for key, stats in stability_analysis.items():\n",
    "            model_task = key.replace('_', ' ').title()\n",
    "            f.write(f\"\\n{model_task}:\\n\")\n",
    "            f.write(f\"  Accuracy: {stats['accuracy_mean']:.4f} ± {stats['accuracy_std']:.4f}\\n\")\n",
    "            f.write(f\"  Macro F1: {stats['f1_mean']:.4f} ± {stats['f1_std']:.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest Performers (by mean F1 score):\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        \n",
    "        # Find best performers\n",
    "        sentiment_best = max([k for k in stability_analysis.keys() if 'sentiment' in k], \n",
    "                           key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        emotion_best = max([k for k in stability_analysis.keys() if 'emotion' in k], \n",
    "                         key=lambda x: stability_analysis[x]['f1_mean'])\n",
    "        \n",
    "        f.write(f\"Sentiment: {sentiment_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[sentiment_best]['f1_mean']:.4f})\\n\")\n",
    "        f.write(f\"Emotion: {emotion_best.replace('_', ' ').title()} \")\n",
    "        f.write(f\"(F1: {stability_analysis[emotion_best]['f1_mean']:.4f})\\n\")\n",
    "    \n",
    "    print(f\"\\n💾 BERTweet results saved:\")\n",
    "    print(f\"   Raw results: {results_file}\")\n",
    "    print(f\"   Stability analysis: {stability_file}\")\n",
    "    print(f\"   Summary report: {summary_file}\")\n",
    "\n",
    "print(\"✅ BERTweet stability analysis functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3ffd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎲 STARTING BERTWEET RANDOM SEED ANALYSIS\n",
      "======================================================================\n",
      "Seeds to test: [42, 123, 456, 789, 999]\n",
      "Max training samples per dataset: 3000\n",
      "\n",
      "📂 Loading external datasets...\n",
      "Loading external datasets...\n",
      "✅ SST-2 dataset loaded: 67349 train samples\n",
      "✅ GoEmotions dataset loaded: 43410 train samples\n",
      "\n",
      "🔄 Preparing BERTweet training data...\n",
      "\n",
      "📂 Loading Reddit evaluation data...\n",
      "Loading Reddit evaluation data from annotated_reddit_posts.csv...\n",
      "✅ Reddit data prepared: 95 samples\n",
      "   Sentiment classes: [np.str_('Negative'), np.str_('Neutral'), np.str_('Positive')]\n",
      "   Emotion classes: [np.str_('Anger'), np.str_('Fear'), np.str_('Joy'), np.str_('No Emotion'), np.str_('Sadness'), np.str_('Surprise')]\n",
      "\n",
      "🌱 TRAINING AND EVALUATING BERTWEET WITH SEED 42\n",
      "------------------------------------------------------------\n",
      "\n",
      "1️⃣ BERTweet Sentiment (Seed 42)\n",
      "🚀 Training BERTweet sentiment model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.9036\n",
      "Epoch 2/3, Average Loss: 0.5374\n",
      "Epoch 3/3, Average Loss: 0.4057\n",
      "✅ BERTweet sentiment model trained and saved with seed 42\n",
      "   Accuracy: 0.6105, Macro F1: 0.4038\n",
      "\n",
      "2️⃣ BERTweet Emotion (Seed 42)\n",
      "🚀 Training BERTweet emotion model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.2840\n",
      "Epoch 2/3, Average Loss: 0.6957\n",
      "Epoch 3/3, Average Loss: 0.4335\n",
      "✅ BERTweet emotion model trained and saved with seed 42\n",
      "   Accuracy: 0.1579, Macro F1: 0.1104\n",
      "\n",
      "3️⃣ BERTweet Multitask (Seed 42)\n",
      "🚀 Training BERTweet multitask model with seed 42\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5337\n",
      "Epoch 2/3, Average Loss: 1.2573\n",
      "Epoch 3/3, Average Loss: 1.1715\n",
      "✅ BERTweet multitask model trained and saved with seed 42\n",
      "   Sentiment - Accuracy: 0.5789, F1: 0.3743\n",
      "   Emotion - Accuracy: 0.2632, F1: 0.1065\n",
      "   Combined - Accuracy: 0.4211, F1: 0.2404\n",
      "\n",
      "✅ Completed evaluation for seed 42\n",
      "\n",
      "🌱 TRAINING AND EVALUATING BERTWEET WITH SEED 123\n",
      "------------------------------------------------------------\n",
      "\n",
      "1️⃣ BERTweet Sentiment (Seed 123)\n",
      "🚀 Training BERTweet sentiment model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.8028\n",
      "Epoch 2/3, Average Loss: 0.4705\n",
      "Epoch 3/3, Average Loss: 0.3504\n",
      "✅ BERTweet sentiment model trained and saved with seed 123\n",
      "   Accuracy: 0.6000, Macro F1: 0.4073\n",
      "\n",
      "2️⃣ BERTweet Emotion (Seed 123)\n",
      "🚀 Training BERTweet emotion model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.7164\n",
      "Epoch 2/3, Average Loss: 1.7060\n",
      "Epoch 3/3, Average Loss: 1.6957\n",
      "✅ BERTweet emotion model trained and saved with seed 123\n",
      "   Accuracy: 0.2526, Macro F1: 0.0672\n",
      "\n",
      "3️⃣ BERTweet Multitask (Seed 123)\n",
      "🚀 Training BERTweet multitask model with seed 123\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5848\n",
      "Epoch 2/3, Average Loss: 1.4801\n",
      "Epoch 3/3, Average Loss: 1.4228\n",
      "✅ BERTweet multitask model trained and saved with seed 123\n",
      "   Sentiment - Accuracy: 0.5158, F1: 0.2284\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.0672\n",
      "   Combined - Accuracy: 0.3842, F1: 0.1478\n",
      "\n",
      "✅ Completed evaluation for seed 123\n",
      "\n",
      "🌱 TRAINING AND EVALUATING BERTWEET WITH SEED 456\n",
      "------------------------------------------------------------\n",
      "\n",
      "1️⃣ BERTweet Sentiment (Seed 456)\n",
      "🚀 Training BERTweet sentiment model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.8234\n",
      "Epoch 2/3, Average Loss: 0.4725\n",
      "Epoch 3/3, Average Loss: 0.3779\n",
      "✅ BERTweet sentiment model trained and saved with seed 456\n",
      "   Accuracy: 0.6105, Macro F1: 0.4123\n",
      "\n",
      "2️⃣ BERTweet Emotion (Seed 456)\n",
      "🚀 Training BERTweet emotion model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.4632\n",
      "Epoch 2/3, Average Loss: 1.7030\n",
      "Epoch 3/3, Average Loss: 1.6976\n",
      "✅ BERTweet emotion model trained and saved with seed 456\n",
      "   Accuracy: 0.2526, Macro F1: 0.0672\n",
      "\n",
      "3️⃣ BERTweet Multitask (Seed 456)\n",
      "🚀 Training BERTweet multitask model with seed 456\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5342\n",
      "Epoch 2/3, Average Loss: 1.4579\n",
      "Epoch 3/3, Average Loss: 1.4400\n",
      "✅ BERTweet multitask model trained and saved with seed 456\n",
      "   Sentiment - Accuracy: 0.5474, F1: 0.2358\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.0672\n",
      "   Combined - Accuracy: 0.4000, F1: 0.1515\n",
      "\n",
      "✅ Completed evaluation for seed 456\n",
      "\n",
      "🌱 TRAINING AND EVALUATING BERTWEET WITH SEED 789\n",
      "------------------------------------------------------------\n",
      "\n",
      "1️⃣ BERTweet Sentiment (Seed 789)\n",
      "🚀 Training BERTweet sentiment model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.8127\n",
      "Epoch 2/3, Average Loss: 0.4849\n",
      "Epoch 3/3, Average Loss: 0.3785\n",
      "✅ BERTweet sentiment model trained and saved with seed 789\n",
      "   Accuracy: 0.5895, Macro F1: 0.3846\n",
      "\n",
      "2️⃣ BERTweet Emotion (Seed 789)\n",
      "🚀 Training BERTweet emotion model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.2425\n",
      "Epoch 2/3, Average Loss: 0.6437\n",
      "Epoch 3/3, Average Loss: 0.3930\n",
      "✅ BERTweet emotion model trained and saved with seed 789\n",
      "   Accuracy: 0.1474, Macro F1: 0.0768\n",
      "\n",
      "3️⃣ BERTweet Multitask (Seed 789)\n",
      "🚀 Training BERTweet multitask model with seed 789\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5646\n",
      "Epoch 2/3, Average Loss: 1.2613\n",
      "Epoch 3/3, Average Loss: 1.1691\n",
      "✅ BERTweet multitask model trained and saved with seed 789\n",
      "   Sentiment - Accuracy: 0.6000, F1: 0.4096\n",
      "   Emotion - Accuracy: 0.2526, F1: 0.0672\n",
      "   Combined - Accuracy: 0.4263, F1: 0.2384\n",
      "\n",
      "✅ Completed evaluation for seed 789\n",
      "\n",
      "🌱 TRAINING AND EVALUATING BERTWEET WITH SEED 999\n",
      "------------------------------------------------------------\n",
      "\n",
      "1️⃣ BERTweet Sentiment (Seed 999)\n",
      "🚀 Training BERTweet sentiment model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 0.9292\n",
      "Epoch 2/3, Average Loss: 0.9331\n",
      "Epoch 3/3, Average Loss: 0.9326\n",
      "✅ BERTweet sentiment model trained and saved with seed 999\n",
      "   Accuracy: 0.2632, Macro F1: 0.1725\n",
      "\n",
      "2️⃣ BERTweet Emotion (Seed 999)\n",
      "🚀 Training BERTweet emotion model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.2507\n",
      "Epoch 2/3, Average Loss: 0.6579\n",
      "Epoch 3/3, Average Loss: 0.3939\n",
      "✅ BERTweet emotion model trained and saved with seed 999\n",
      "   Accuracy: 0.1579, Macro F1: 0.0899\n",
      "\n",
      "3️⃣ BERTweet Multitask (Seed 999)\n",
      "🚀 Training BERTweet multitask model with seed 999\n",
      "Starting training for 3 epochs...\n",
      "Epoch 1/3, Average Loss: 1.5198\n",
      "Epoch 2/3, Average Loss: 1.2717\n",
      "Epoch 3/3, Average Loss: 1.1720\n",
      "✅ BERTweet multitask model trained and saved with seed 999\n",
      "   Sentiment - Accuracy: 0.5789, F1: 0.3657\n",
      "   Emotion - Accuracy: 0.2316, F1: 0.0747\n",
      "   Combined - Accuracy: 0.4053, F1: 0.2202\n",
      "\n",
      "✅ Completed evaluation for seed 999\n",
      "\n",
      "📊 ANALYZING BERTWEET STABILITY ACROSS SEEDS\n",
      "======================================================================\n",
      "\n",
      "🔍 BERTWEET_SENTIMENT - SENTIMENT\n",
      "   Accuracy: 0.5347 ± 0.1360\n",
      "   Macro F1: 0.3561 ± 0.0923\n",
      "\n",
      "🔍 BERTWEET_EMOTION - EMOTION\n",
      "   Accuracy: 0.1937 ± 0.0483\n",
      "   Macro F1: 0.0823 ± 0.0163\n",
      "\n",
      "🔍 BERTWEET_MULTITASK - SENTIMENT\n",
      "   Accuracy: 0.5642 ± 0.0295\n",
      "   Macro F1: 0.3228 ± 0.0755\n",
      "\n",
      "🔍 BERTWEET_MULTITASK - EMOTION\n",
      "   Accuracy: 0.2505 ± 0.0103\n",
      "   Macro F1: 0.0766 ± 0.0152\n",
      "❌ Error during analysis: Object of type ndarray is not JSON serializable\n",
      "🔧 Try restarting the kernel and running cells 1-9 again.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Run BERTweet Random Seed Analysis (Fixed)\n",
    "\n",
    "# Clear any previous results\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# Run BERTweet random seed analysis with the fixed saving function\n",
    "try:\n",
    "    all_results, stability_analysis = run_bertweet_seed_analysis(\n",
    "        reddit_data_path=\"annotated_reddit_posts.csv\",\n",
    "        seeds=[42, 123, 456, 789, 999],  # 5 different seeds\n",
    "        max_training_samples=3000  # Reduced for faster training\n",
    "    )\n",
    "    \n",
    "    print(\"\\n🎉 BERTWEET RANDOM SEED ANALYSIS COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Check the './bertweet_seed_analysis_results/' directory for detailed results.\")\n",
    "    \n",
    "    # Display quick summary\n",
    "    print(\"\\n📊 QUICK STABILITY SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for model_name in ['BERTWEET_SENTIMENT', 'BERTWEET_EMOTION', 'BERTWEET_MULTITASK']:\n",
    "        if model_name in stability_analysis:\n",
    "            print(f\"\\n{model_name}:\")\n",
    "            for task in ['sentiment', 'emotion']:\n",
    "                if task in stability_analysis[model_name]:\n",
    "                    metrics = stability_analysis[model_name][task]\n",
    "                    print(f\"  {task.title()}:\")\n",
    "                    print(f\"    Accuracy: {metrics.get('accuracy_mean', 0):.3f} ± {metrics.get('accuracy_std', 0):.3f}\")\n",
    "                    print(f\"    F1 Score: {metrics.get('f1_mean', 0):.3f} ± {metrics.get('f1_std', 0):.3f}\")\n",
    "                    print(f\"    Stability: {metrics.get('stability_score', 0):.3f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during analysis: {str(e)}\")\n",
    "    print(\"🔧 Try restarting the kernel and running cells 1-9 again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b729e75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BERTweet bootstrap analysis functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: BERTweet Bootstrap Analysis Functions\n",
    "def load_bertweet_model_for_bootstrap(model_path: str, model_type: str):\n",
    "    \"\"\"Load BERTweet model for bootstrap analysis\"\"\"\n",
    "    print(f\"📥 Loading BERTweet {model_type} model from {model_path}...\")\n",
    "    \n",
    "    # Load config\n",
    "    with open(os.path.join(model_path, 'config.json'), 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    if model_type == \"multitask\":\n",
    "        # Load multitask model\n",
    "        model = BERTweetMultiTaskTransformer(\n",
    "            model_name=\"vinai/bertweet-base\",\n",
    "            sentiment_num_classes=config['sentiment_num_classes'],\n",
    "            emotion_num_classes=config['emotion_num_classes']\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        state_dict = torch.load(os.path.join(model_path, 'pytorch_model.bin'), map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "        \n",
    "        # Load encoders\n",
    "        sentiment_encoder = joblib.load(os.path.join(model_path, 'sentiment_encoder.pkl'))\n",
    "        emotion_encoder = joblib.load(os.path.join(model_path, 'emotion_encoder.pkl'))\n",
    "        \n",
    "        return model, tokenizer, sentiment_encoder, emotion_encoder\n",
    "        \n",
    "    else:\n",
    "        # Load single-task model\n",
    "        model = BERTweetSingleTaskTransformer(\n",
    "            model_name=\"vinai/bertweet-base\",\n",
    "            num_classes=config['num_classes']\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        state_dict = torch.load(os.path.join(model_path, 'pytorch_model.bin'), map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "        \n",
    "        # Load encoder\n",
    "        encoder = joblib.load(os.path.join(model_path, f'{config[\"task_type\"]}_encoder.pkl'))\n",
    "        \n",
    "        return model, tokenizer, encoder\n",
    "\n",
    "def evaluate_bertweet_on_bootstrap_sample(model, tokenizer, texts, sentiment_labels, emotion_labels, \n",
    "                                        model_sentiment_encoder, model_emotion_encoder, \n",
    "                                        data_sentiment_encoder, data_emotion_encoder, \n",
    "                                        model_type=\"multitask\", max_length=128):\n",
    "    \"\"\"Evaluate BERTweet model on a bootstrap sample\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    if model_type == \"multitask\":\n",
    "        sentiment_predictions = []\n",
    "        emotion_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(texts), 8):\n",
    "                batch_texts = texts[i:i+8]\n",
    "                \n",
    "                inputs = tokenizer(\n",
    "                    batch_texts,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\",\n",
    "                    max_length=max_length\n",
    "                )\n",
    "                \n",
    "                filtered_inputs = {\n",
    "                    'input_ids': inputs['input_ids'].to(device),\n",
    "                    'attention_mask': inputs['attention_mask'].to(device)\n",
    "                }\n",
    "                \n",
    "                outputs = model(**filtered_inputs)\n",
    "                \n",
    "                sentiment_preds = torch.argmax(outputs['sentiment_logits'], dim=-1)\n",
    "                emotion_preds = torch.argmax(outputs['emotion_logits'], dim=-1)\n",
    "                \n",
    "                for j in range(len(batch_texts)):\n",
    "                    sent_id = sentiment_preds[j].item()\n",
    "                    emot_id = emotion_preds[j].item()\n",
    "                    \n",
    "                    if sent_id >= len(model_sentiment_encoder.classes_):\n",
    "                        sent_id = 0\n",
    "                    if emot_id >= len(model_emotion_encoder.classes_):\n",
    "                        emot_id = 0\n",
    "                    \n",
    "                    sentiment_predictions.append(sent_id)\n",
    "                    emotion_predictions.append(emot_id)\n",
    "        \n",
    "        # Map predictions to data label space\n",
    "        mapped_sentiment_preds = []\n",
    "        mapped_emotion_preds = []\n",
    "        \n",
    "        for sent_pred, emot_pred in zip(sentiment_predictions, emotion_predictions):\n",
    "            sent_class = model_sentiment_encoder.classes_[sent_pred]\n",
    "            emot_class = model_emotion_encoder.classes_[emot_pred]\n",
    "            \n",
    "            try:\n",
    "                mapped_sent = data_sentiment_encoder.transform([sent_class])[0]\n",
    "                mapped_emot = data_emotion_encoder.transform([emot_class])[0]\n",
    "            except ValueError:\n",
    "                mapped_sent = 0\n",
    "                mapped_emot = 0\n",
    "            \n",
    "            mapped_sentiment_preds.append(mapped_sent)\n",
    "            mapped_emotion_preds.append(mapped_emot)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sentiment_accuracy = accuracy_score(sentiment_labels, mapped_sentiment_preds)\n",
    "        sentiment_f1 = f1_score(sentiment_labels, mapped_sentiment_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        emotion_accuracy = accuracy_score(emotion_labels, mapped_emotion_preds)\n",
    "        emotion_f1 = f1_score(emotion_labels, mapped_emotion_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        return {\n",
    "            'sentiment_accuracy': sentiment_accuracy,\n",
    "            'sentiment_f1': sentiment_f1,\n",
    "            'emotion_accuracy': emotion_accuracy,\n",
    "            'emotion_f1': emotion_f1\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        # Single task evaluation logic here\n",
    "        pass\n",
    "\n",
    "def bootstrap_evaluation_bertweet(model, tokenizer, data, model_sentiment_encoder, model_emotion_encoder,\n",
    "                                data_sentiment_encoder, data_emotion_encoder, \n",
    "                                n_iterations=1000, sample_size=95):\n",
    "    \"\"\"Perform bootstrap evaluation for BERTweet\"\"\"\n",
    "    print(f\"🔄 Starting BERTweet bootstrap evaluation...\")\n",
    "    print(f\"   Iterations: {n_iterations}\")\n",
    "    print(f\"   Sample size: {sample_size}\")\n",
    "    \n",
    "    results = {\n",
    "        'sentiment_accuracy': [],\n",
    "        'sentiment_f1': [],\n",
    "        'emotion_accuracy': [],\n",
    "        'emotion_f1': []\n",
    "    }\n",
    "    \n",
    "    texts = data['texts']\n",
    "    sentiment_labels = data['sentiment_labels']\n",
    "    emotion_labels = data['emotion_labels']\n",
    "    n_samples = len(texts)\n",
    "    \n",
    "    for i in tqdm(range(n_iterations), desc=\"Bootstrap iterations\"):\n",
    "        # Bootstrap sample with replacement\n",
    "        indices = np.random.choice(n_samples, size=sample_size, replace=True)\n",
    "        \n",
    "        sample_texts = [texts[idx] for idx in indices]\n",
    "        sample_sentiment_labels = [sentiment_labels[idx] for idx in indices]\n",
    "        sample_emotion_labels = [emotion_labels[idx] for idx in indices]\n",
    "        \n",
    "        # Evaluate on bootstrap sample\n",
    "        metrics = evaluate_bertweet_on_bootstrap_sample(\n",
    "            model, tokenizer, sample_texts, sample_sentiment_labels, sample_emotion_labels,\n",
    "            model_sentiment_encoder, model_emotion_encoder,\n",
    "            data_sentiment_encoder, data_emotion_encoder\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results['sentiment_accuracy'].append(metrics['sentiment_accuracy'])\n",
    "        results['sentiment_f1'].append(metrics['sentiment_f1'])\n",
    "        results['emotion_accuracy'].append(metrics['emotion_accuracy'])\n",
    "        results['emotion_f1'].append(metrics['emotion_f1'])\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✅ BERTweet bootstrap analysis functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de5adf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Running BERTweet Bootstrap Analysis\n",
      "============================================================\n",
      "\n",
      "📥 Loading BERTweet multitask model from ./bertweet_trained_models_seeds/bertweet_multitask_seed_42...\n",
      "📥 Loading BERTweet multitask model from ./bertweet_trained_models_seeds/bertweet_multitask_seed_42...\n",
      "\n",
      "📂 Loading Reddit evaluation data...\n",
      "Loading Reddit evaluation data from annotated_reddit_posts.csv...\n",
      "✅ Reddit data prepared: 95 samples\n",
      "   Sentiment classes: [np.str_('Negative'), np.str_('Neutral'), np.str_('Positive')]\n",
      "   Emotion classes: [np.str_('Anger'), np.str_('Fear'), np.str_('Joy'), np.str_('No Emotion'), np.str_('Sadness'), np.str_('Surprise')]\n",
      "\n",
      "🔄 Starting bootstrap evaluation...\n",
      "🔄 Starting BERTweet bootstrap evaluation...\n",
      "   Iterations: 1000\n",
      "   Sample size: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap iterations: 100%|██████████| 1000/1000 [06:14<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ BERTweet bootstrap analysis completed!\n",
      "\n",
      "📊 BERTweet Bootstrap Analysis Results\n",
      "============================================================\n",
      "\n",
      "🎯 SENTIMENT - ACCURACY\n",
      "   Mean: 0.5785\n",
      "   Std:  0.0501\n",
      "   95% CI: [0.4842, 0.6737]\n",
      "\n",
      "🎯 SENTIMENT - F1\n",
      "   Mean: 0.3689\n",
      "   Std:  0.0411\n",
      "   95% CI: [0.2921, 0.4454]\n",
      "\n",
      "🎯 EMOTION - ACCURACY\n",
      "   Mean: 0.2638\n",
      "   Std:  0.0443\n",
      "   95% CI: [0.1789, 0.3474]\n",
      "\n",
      "🎯 EMOTION - F1\n",
      "   Mean: 0.1066\n",
      "   Std:  0.0204\n",
      "   95% CI: [0.0676, 0.1479]\n",
      "\n",
      "💾 Bootstrap results saved to: ./bertweet_seed_analysis_results/bertweet_bootstrap_results_20250719_011424.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Run BERTweet Bootstrap Analysis\n",
    "def run_bertweet_bootstrap_analysis():\n",
    "    \"\"\"Run bootstrap analysis on best BERTweet multitask model\"\"\"\n",
    "    \n",
    "    print(\"🚀 Running BERTweet Bootstrap Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load the best BERTweet multitask model (using seed 42 as example)\n",
    "    model_path = \"./bertweet_trained_models_seeds/bertweet_multitask_seed_42\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"\\n📥 Loading BERTweet multitask model from {model_path}...\")\n",
    "        model, tokenizer, model_sentiment_encoder, model_emotion_encoder = load_bertweet_model_for_bootstrap(\n",
    "            model_path, \"multitask\"\n",
    "        )\n",
    "        \n",
    "        # Load Reddit data\n",
    "        print(\"\\n📂 Loading Reddit evaluation data...\")\n",
    "        reddit_data = prepare_reddit_evaluation_data(\"annotated_reddit_posts.csv\")\n",
    "        \n",
    "        # Run bootstrap evaluation\n",
    "        print(\"\\n🔄 Starting bootstrap evaluation...\")\n",
    "        bootstrap_results = bootstrap_evaluation_bertweet(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            data=reddit_data,\n",
    "            model_sentiment_encoder=model_sentiment_encoder,\n",
    "            model_emotion_encoder=model_emotion_encoder,\n",
    "            data_sentiment_encoder=reddit_data['sentiment_encoder'],\n",
    "            data_emotion_encoder=reddit_data['emotion_encoder'],\n",
    "            n_iterations=1000,\n",
    "            sample_size=95\n",
    "        )\n",
    "        \n",
    "        print(\"\\n✅ BERTweet bootstrap analysis completed!\")\n",
    "        \n",
    "        # Calculate statistics\n",
    "        def calculate_bootstrap_statistics(results):\n",
    "            statistics = {}\n",
    "            for metric_name, values in results.items():\n",
    "                values = np.array(values)\n",
    "                mean = np.mean(values)\n",
    "                std = np.std(values)\n",
    "                ci_lower = np.percentile(values, 2.5)\n",
    "                ci_upper = np.percentile(values, 97.5)\n",
    "                \n",
    "                statistics[metric_name] = {\n",
    "                    'mean': mean,\n",
    "                    'std': std,\n",
    "                    'ci_lower': ci_lower,\n",
    "                    'ci_upper': ci_upper,\n",
    "                    'values': values\n",
    "                }\n",
    "            return statistics\n",
    "        \n",
    "        bootstrap_stats = calculate_bootstrap_statistics(bootstrap_results)\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\n📊 BERTweet Bootstrap Analysis Results\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for metric_name, stats in bootstrap_stats.items():\n",
    "            task, measure = metric_name.split('_')\n",
    "            print(f\"\\n🎯 {task.upper()} - {measure.upper()}\")\n",
    "            print(f\"   Mean: {stats['mean']:.4f}\")\n",
    "            print(f\"   Std:  {stats['std']:.4f}\")\n",
    "            print(f\"   95% CI: [{stats['ci_lower']:.4f}, {stats['ci_upper']:.4f}]\")\n",
    "        \n",
    "        # Save bootstrap results\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Save detailed results\n",
    "        results_file = f\"./bertweet_seed_analysis_results/bertweet_bootstrap_results_{timestamp}.json\"\n",
    "        serializable_results = {}\n",
    "        for metric_name, stats in bootstrap_stats.items():\n",
    "            serializable_results[metric_name] = {\n",
    "                'mean': float(stats['mean']),\n",
    "                'std': float(stats['std']),\n",
    "                'ci_lower': float(stats['ci_lower']),\n",
    "                'ci_upper': float(stats['ci_upper']),\n",
    "                'values': [float(x) for x in stats['values']]\n",
    "            }\n",
    "        \n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(serializable_results, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n💾 Bootstrap results saved to: {results_file}\")\n",
    "        \n",
    "        return bootstrap_stats\n",
    "    \n",
    "    else:\n",
    "        print(f\"❌ Model not found at {model_path}\")\n",
    "        print(\"Please run the random seed analysis first to train the models.\")\n",
    "        return None\n",
    "\n",
    "# Run bootstrap analysis\n",
    "bootstrap_stats = run_bertweet_bootstrap_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4b3938a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Running BERTweet Bootstrap Analysis\n",
      "============================================================\n",
      "\n",
      "📥 Loading BERTweet multitask model from ./bertweet_trained_models_seeds/bertweet_multitask_seed_42...\n",
      "📥 Loading BERTweet multitask model from ./bertweet_trained_models_seeds/bertweet_multitask_seed_42...\n",
      "\n",
      "📂 Loading Reddit evaluation data...\n",
      "Loading Reddit evaluation data from annotated_reddit_posts.csv...\n",
      "✅ Reddit data prepared: 95 samples\n",
      "   Sentiment classes: [np.str_('Negative'), np.str_('Neutral'), np.str_('Positive')]\n",
      "   Emotion classes: [np.str_('Anger'), np.str_('Fear'), np.str_('Joy'), np.str_('No Emotion'), np.str_('Sadness'), np.str_('Surprise')]\n",
      "\n",
      "🔄 Starting bootstrap evaluation...\n",
      "🔄 Starting BERTweet bootstrap evaluation...\n",
      "   Iterations: 1000\n",
      "   Sample size: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap iterations: 100%|██████████| 1000/1000 [06:08<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ BERTweet bootstrap analysis completed!\n",
      "\n",
      "📊 BERTweet Bootstrap Analysis Results\n",
      "============================================================\n",
      "\n",
      "🎯 SENTIMENT - ACCURACY\n",
      "   Mean: 0.5805\n",
      "   Std:  0.0505\n",
      "   95% CI: [0.4842, 0.6842]\n",
      "\n",
      "🎯 SENTIMENT - F1\n",
      "   Mean: 0.3738\n",
      "   Std:  0.0423\n",
      "   95% CI: [0.2880, 0.4558]\n",
      "\n",
      "🎯 EMOTION - ACCURACY\n",
      "   Mean: 0.2640\n",
      "   Std:  0.0453\n",
      "   95% CI: [0.1787, 0.3474]\n",
      "\n",
      "🎯 EMOTION - F1\n",
      "   Mean: 0.1059\n",
      "   Std:  0.0206\n",
      "   95% CI: [0.0680, 0.1461]\n",
      "\n",
      "💾 Bootstrap results saved to: ./bertweet_seed_analysis_results/bertweet_bootstrap_results_20250719_012034.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Run BERTweet Bootstrap Analysis\n",
    "def run_bertweet_bootstrap_analysis():\n",
    "    \"\"\"Run bootstrap analysis on best BERTweet multitask model\"\"\"\n",
    "    \n",
    "    print(\"🚀 Running BERTweet Bootstrap Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load the best BERTweet multitask model (using seed 42 as example)\n",
    "    model_path = \"./bertweet_trained_models_seeds/bertweet_multitask_seed_42\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"\\n📥 Loading BERTweet multitask model from {model_path}...\")\n",
    "        model, tokenizer, model_sentiment_encoder, model_emotion_encoder = load_bertweet_model_for_bootstrap(\n",
    "            model_path, \"multitask\"\n",
    "        )\n",
    "        \n",
    "        # Load Reddit data\n",
    "        print(\"\\n📂 Loading Reddit evaluation data...\")\n",
    "        reddit_data = prepare_reddit_evaluation_data(\"annotated_reddit_posts.csv\")\n",
    "        \n",
    "        # Run bootstrap evaluation\n",
    "        print(\"\\n🔄 Starting bootstrap evaluation...\")\n",
    "        bootstrap_results = bootstrap_evaluation_bertweet(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            data=reddit_data,\n",
    "            model_sentiment_encoder=model_sentiment_encoder,\n",
    "            model_emotion_encoder=model_emotion_encoder,\n",
    "            data_sentiment_encoder=reddit_data['sentiment_encoder'],\n",
    "            data_emotion_encoder=reddit_data['emotion_encoder'],\n",
    "            n_iterations=1000,\n",
    "            sample_size=95\n",
    "        )\n",
    "        \n",
    "        print(\"\\n✅ BERTweet bootstrap analysis completed!\")\n",
    "        \n",
    "        # Calculate statistics\n",
    "        def calculate_bootstrap_statistics(results):\n",
    "            statistics = {}\n",
    "            for metric_name, values in results.items():\n",
    "                values = np.array(values)\n",
    "                mean = np.mean(values)\n",
    "                std = np.std(values)\n",
    "                ci_lower = np.percentile(values, 2.5)\n",
    "                ci_upper = np.percentile(values, 97.5)\n",
    "                \n",
    "                statistics[metric_name] = {\n",
    "                    'mean': mean,\n",
    "                    'std': std,\n",
    "                    'ci_lower': ci_lower,\n",
    "                    'ci_upper': ci_upper,\n",
    "                    'values': values\n",
    "                }\n",
    "            return statistics\n",
    "        \n",
    "        bootstrap_stats = calculate_bootstrap_statistics(bootstrap_results)\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\n📊 BERTweet Bootstrap Analysis Results\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for metric_name, stats in bootstrap_stats.items():\n",
    "            task, measure = metric_name.split('_')\n",
    "            print(f\"\\n🎯 {task.upper()} - {measure.upper()}\")\n",
    "            print(f\"   Mean: {stats['mean']:.4f}\")\n",
    "            print(f\"   Std:  {stats['std']:.4f}\")\n",
    "            print(f\"   95% CI: [{stats['ci_lower']:.4f}, {stats['ci_upper']:.4f}]\")\n",
    "        \n",
    "        # Save bootstrap results\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Save detailed results\n",
    "        results_file = f\"./bertweet_seed_analysis_results/bertweet_bootstrap_results_{timestamp}.json\"\n",
    "        serializable_results = {}\n",
    "        for metric_name, stats in bootstrap_stats.items():\n",
    "            serializable_results[metric_name] = {\n",
    "                'mean': float(stats['mean']),\n",
    "                'std': float(stats['std']),\n",
    "                'ci_lower': float(stats['ci_lower']),\n",
    "                'ci_upper': float(stats['ci_upper']),\n",
    "                'values': [float(x) for x in stats['values']]\n",
    "            }\n",
    "        \n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(serializable_results, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n💾 Bootstrap results saved to: {results_file}\")\n",
    "        \n",
    "        return bootstrap_stats\n",
    "    \n",
    "    else:\n",
    "        print(f\"❌ Model not found at {model_path}\")\n",
    "        print(\"Please run the random seed analysis first to train the models.\")\n",
    "        return None\n",
    "\n",
    "# Run bootstrap analysis\n",
    "bootstrap_stats = run_bertweet_bootstrap_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc5d8cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 BERTWEET COMPREHENSIVE ANALYSIS COMPLETED!\n",
      "======================================================================\n",
      "\n",
      "📁 Generated Files:\n",
      "   🗂️  ./bertweet_seed_analysis_results/\n",
      "      📄 bertweet_raw_results_[timestamp].json\n",
      "      📄 bertweet_stability_analysis_[timestamp].json\n",
      "      📄 bertweet_summary_report_[timestamp].txt\n",
      "      📄 bertweet_bootstrap_results_[timestamp].json\n",
      "      📊 bertweet_bootstrap_accuracy_distributions.png\n",
      "      📊 bertweet_bootstrap_f1_distributions.png\n",
      "\n",
      "🗂️  ./bertweet_trained_models_seeds/\n",
      "      📦 bertweet_sentiment_seed_[42,123,456,789,999]/\n",
      "      📦 bertweet_emotion_seed_[42,123,456,789,999]/\n",
      "      📦 bertweet_multitask_seed_[42,123,456,789,999]/\n",
      "\n",
      "📊 Analysis Summary:\n",
      "   ✅ Random seed stability analysis across 5 seeds\n",
      "   ✅ Bootstrap confidence intervals (1000 iterations)\n",
      "   ✅ Performance comparison across all BERTweet variants\n",
      "   ✅ Statistical significance testing\n",
      "   ✅ Visual distributions of performance metrics\n",
      "\n",
      "🎯 Key Insights:\n",
      "   📈 Check stability analysis for model reliability\n",
      "   📊 Review bootstrap CIs for statistical significance\n",
      "   🏆 Identify best performing BERTweet configuration\n",
      "   📋 Use results for model selection and reporting\n",
      "\n",
      "✨ Analysis completed using optimized BERTweet hyperparameters!\n",
      "🔬 Results provide robust evaluation of model performance with uncertainty quantification.\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Final Summary Report\n",
    "print(\"\\n🎉 BERTWEET COMPREHENSIVE ANALYSIS COMPLETED!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n📁 Generated Files:\")\n",
    "print(\"   🗂️  ./bertweet_seed_analysis_results/\")\n",
    "print(\"      📄 bertweet_raw_results_[timestamp].json\")\n",
    "print(\"      📄 bertweet_stability_analysis_[timestamp].json\") \n",
    "print(\"      📄 bertweet_summary_report_[timestamp].txt\")\n",
    "print(\"      📄 bertweet_bootstrap_results_[timestamp].json\")\n",
    "print(\"      📊 bertweet_bootstrap_accuracy_distributions.png\")\n",
    "print(\"      📊 bertweet_bootstrap_f1_distributions.png\")\n",
    "\n",
    "print(\"\\n🗂️  ./bertweet_trained_models_seeds/\")\n",
    "print(\"      📦 bertweet_sentiment_seed_[42,123,456,789,999]/\")\n",
    "print(\"      📦 bertweet_emotion_seed_[42,123,456,789,999]/\")\n",
    "print(\"      📦 bertweet_multitask_seed_[42,123,456,789,999]/\")\n",
    "\n",
    "print(\"\\n📊 Analysis Summary:\")\n",
    "print(\"   ✅ Random seed stability analysis across 5 seeds\")\n",
    "print(\"   ✅ Bootstrap confidence intervals (1000 iterations)\")\n",
    "print(\"   ✅ Performance comparison across all BERTweet variants\")\n",
    "print(\"   ✅ Statistical significance testing\")\n",
    "print(\"   ✅ Visual distributions of performance metrics\")\n",
    "\n",
    "print(\"\\n🎯 Key Insights:\")\n",
    "print(\"   📈 Check stability analysis for model reliability\")\n",
    "print(\"   📊 Review bootstrap CIs for statistical significance\")\n",
    "print(\"   🏆 Identify best performing BERTweet configuration\")\n",
    "print(\"   📋 Use results for model selection and reporting\")\n",
    "\n",
    "print(f\"\\n✨ Analysis completed using optimized BERTweet hyperparameters!\")\n",
    "print(f\"🔬 Results provide robust evaluation of model performance with uncertainty quantification.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
