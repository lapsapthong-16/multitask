{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a263aba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    RobertaTokenizer, RobertaForSequenceClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset as HFDataset, load_dataset\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, confusion_matrix,\n",
    "    classification_report, cohen_kappa_score, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b90630",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer, max_length: int = 512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4bdf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaTrainer:\n",
    "    \n",
    "    def __init__(self, model_name: str = \"roberta-base\", max_length: int = 512):\n",
    "        self.model_name = model_name\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = None\n",
    "        self.sentiment_model = None\n",
    "        self.emotion_model = None\n",
    "        self.sentiment_label_encoder = LabelEncoder()\n",
    "        self.emotion_label_encoder = LabelEncoder()\n",
    "        \n",
    "        # Set device\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Create output directories\n",
    "        os.makedirs(\"./roberta_sentiment_model\", exist_ok=True)\n",
    "        os.makedirs(\"./roberta_emotion_model\", exist_ok=True)\n",
    "        os.makedirs(\"./plots/roberta\", exist_ok=True)\n",
    "        os.makedirs(\"./results/roberta\", exist_ok=True)\n",
    "    \n",
    "    def setup_tokenizer(self):\n",
    "        logger.info(\"Setting up RoBERTa tokenizer...\")\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "        # Add padding token if it doesn't exist\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        logger.info(\"‚úÖ Tokenizer ready!\")\n",
    "    \n",
    "    def load_reddit_data(self, file_path: str) -> pd.DataFrame:\n",
    "        logger.info(f\"Loading Reddit data from {file_path}...\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            logger.info(f\"‚úÖ Loaded {len(df)} samples from Reddit dataset\")\n",
    "            \n",
    "            # Check for required columns\n",
    "            required_cols = ['text_content', 'sentiment', 'emotion']\n",
    "            missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "            \n",
    "            # Remove rows with missing values\n",
    "            df = df.dropna(subset=required_cols)\n",
    "            logger.info(f\"After removing missing values: {len(df)} samples\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading Reddit data: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def load_external_datasets(self) -> Tuple[Dict, Dict]:\n",
    "        logger.info(\"Loading external datasets...\")\n",
    "        \n",
    "        # Load SST-2 for sentiment\n",
    "        try:\n",
    "            sst2_dataset = load_dataset(\"sst2\")\n",
    "            sentiment_data = {\n",
    "                'train': sst2_dataset['train'],\n",
    "                'validation': sst2_dataset['validation']\n",
    "            }\n",
    "            logger.info(\"‚úÖ SST-2 dataset loaded for sentiment classification\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not load SST-2: {e}. Using dummy data.\")\n",
    "            sentiment_data = self._create_dummy_sentiment_data()\n",
    "        \n",
    "        # Load GoEmotions for emotion\n",
    "        try:\n",
    "            emotions_dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "            emotion_data = {\n",
    "                'train': emotions_dataset['train'],\n",
    "                'validation': emotions_dataset['validation']\n",
    "            }\n",
    "            logger.info(\"‚úÖ GoEmotions dataset loaded for emotion classification\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not load GoEmotions: {e}. Using dummy data.\")\n",
    "            emotion_data = self._create_dummy_emotion_data()\n",
    "        \n",
    "        return sentiment_data, emotion_data\n",
    "    \n",
    "    def _create_dummy_sentiment_data(self) -> Dict:\n",
    "        dummy_texts = [\n",
    "            \"I love this product!\", \"This is terrible\", \"It's okay\",\n",
    "            \"Amazing quality\", \"Worst experience ever\", \"Not bad\"\n",
    "        ] * 100\n",
    "        dummy_labels = [1, 0, 1, 1, 0, 1] * 100\n",
    "        \n",
    "        dummy_data = {\n",
    "            'sentence': dummy_texts,\n",
    "            'label': dummy_labels\n",
    "        }\n",
    "        \n",
    "        dataset = HFDataset.from_dict(dummy_data)\n",
    "        return {'train': dataset, 'validation': dataset.select(range(100))}\n",
    "    \n",
    "    def _create_dummy_emotion_data(self) -> Dict:\n",
    "        \"\"\"Create dummy emotion data for testing\"\"\"\n",
    "        dummy_texts = [\n",
    "            \"I'm so happy!\", \"This is sad\", \"I'm angry\", \"That's scary\",\n",
    "            \"What a surprise!\", \"Okay\", \"I admire you\", \"That's funny\"\n",
    "        ] * 100\n",
    "        dummy_labels = [0, 1, 2, 3, 4, 5, 6, 7] * 100\n",
    "        \n",
    "        dummy_data = {\n",
    "            'text': dummy_texts,\n",
    "            'labels': dummy_labels\n",
    "        }\n",
    "        \n",
    "        dataset = HFDataset.from_dict(dummy_data)\n",
    "        return {'train': dataset, 'validation': dataset.select(range(100))}\n",
    "    \n",
    "    def preprocess_external_data(self, dataset: Dict, task: str) -> Dict:\n",
    "        \"\"\"Preprocess external datasets\"\"\"\n",
    "        logger.info(f\"Preprocessing external data for {task}...\")\n",
    "\n",
    "        # --- ADD THIS BLOCK FOR EMOTION TASK ---\n",
    "        if task == 'emotion':\n",
    "            # Only keep samples with label in [0, 1, 2, 3, 4, 5]\n",
    "            def filter_first_6_classes(example):\n",
    "                # Handle both single-label and multi-label\n",
    "                if isinstance(example['labels'], list):\n",
    "                    return example['labels'] and example['labels'][0] in range(6)\n",
    "                else:\n",
    "                    return example['labels'] in range(6)\n",
    "            dataset['train'] = dataset['train'].filter(filter_first_6_classes)\n",
    "            dataset['validation'] = dataset['validation'].filter(filter_first_6_classes)\n",
    "        # --- END BLOCK ---\n",
    "\n",
    "        def tokenize_function(examples):\n",
    "            if task == 'sentiment':\n",
    "                texts = examples['sentence']\n",
    "                labels = examples['label']\n",
    "            else:  # emotion\n",
    "                texts = examples['text']\n",
    "                # Handle multi-label to single-label conversion\n",
    "                if isinstance(examples['labels'][0], list):\n",
    "                    labels = [label_list[0] if label_list else 0 for label_list in examples['labels']]\n",
    "                else:\n",
    "                    labels = examples['labels']\n",
    "\n",
    "            tokenized = self.tokenizer(\n",
    "                texts,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=None\n",
    "            )\n",
    "\n",
    "            tokenized['labels'] = labels\n",
    "            return tokenized\n",
    "\n",
    "        # Tokenize datasets\n",
    "        tokenized_train = dataset['train'].map(tokenize_function, batched=True)\n",
    "        tokenized_val = dataset['validation'].map(tokenize_function, batched=True)\n",
    "\n",
    "        # Take subsets for faster training\n",
    "        train_subset = tokenized_train.shuffle(seed=42).select(range(min(10000, len(tokenized_train))))\n",
    "        val_subset = tokenized_val.shuffle(seed=42).select(range(min(2000, len(tokenized_val))))\n",
    "\n",
    "        logger.info(f\"‚úÖ Preprocessed {task} data: {len(train_subset)} train, {len(val_subset)} val\")\n",
    "\n",
    "        return {'train': train_subset, 'validation': val_subset}\n",
    "    \n",
    "    def train_model(self, dataset: Dict, task: str, num_labels: int, \n",
    "                   learning_rate: float = 2e-5, num_epochs: int = 3,\n",
    "                   batch_size: int = 16) -> Tuple[any, any]:\n",
    "        \"\"\"Train RoBERTa model for specific task\"\"\"\n",
    "        logger.info(f\"Training RoBERTa model for {task} classification...\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = RobertaForSequenceClassification.from_pretrained(\n",
    "            self.model_name,\n",
    "            num_labels=num_labels,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        # Training arguments\n",
    "        output_dir = f\"./roberta_{task}_model\"\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=num_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            warmup_steps=500,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir=f\"./logs_{task}\",\n",
    "            logging_steps=100,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"eval_accuracy\",\n",
    "            learning_rate=learning_rate,\n",
    "            report_to=None,\n",
    "            save_total_limit=2,\n",
    "            dataloader_num_workers=0,  # Avoid multiprocessing issues\n",
    "        )\n",
    "        \n",
    "        # Data collator\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
    "        \n",
    "        # Compute metrics function\n",
    "        def compute_metrics(eval_pred):\n",
    "            predictions, labels = eval_pred\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "            \n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                labels, predictions, average='macro', zero_division=0\n",
    "            )\n",
    "            accuracy = accuracy_score(labels, predictions)\n",
    "            \n",
    "            return {\n",
    "                'accuracy': accuracy,\n",
    "                'f1': f1,\n",
    "                'precision': precision,\n",
    "                'recall': recall\n",
    "            }\n",
    "        \n",
    "        # Initialize trainer\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset['train'],\n",
    "            eval_dataset=dataset['validation'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            data_collator=data_collator,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        logger.info(f\"üöÄ Starting {task} model training...\")\n",
    "        trainer.train()\n",
    "        \n",
    "        # Save model\n",
    "        final_output_dir = f\"./roberta_{task}_model_final\"\n",
    "        os.makedirs(final_output_dir, exist_ok=True)\n",
    "        trainer.save_model(final_output_dir)\n",
    "        \n",
    "        logger.info(f\"‚úÖ {task.capitalize()} model training completed!\")\n",
    "        \n",
    "        return model, trainer\n",
    "    \n",
    "    def prepare_reddit_data(self, df: pd.DataFrame, task: str) -> Tuple[List[str], List[int]]:\n",
    "        \"\"\"Prepare Reddit data for training/evaluation\"\"\"\n",
    "        texts = df['text_content'].tolist()\n",
    "        \n",
    "        if task == 'sentiment':\n",
    "            labels = df['sentiment'].tolist()\n",
    "            encoded_labels = self.sentiment_label_encoder.fit_transform(labels)\n",
    "        else:  # emotion\n",
    "            labels = df['emotion'].tolist()\n",
    "            encoded_labels = self.emotion_label_encoder.fit_transform(labels)\n",
    "        \n",
    "        return texts, encoded_labels.tolist()\n",
    "    \n",
    "    def evaluate_model(self, model, texts: List[str], true_labels: List[int], \n",
    "                      task: str, label_encoder) -> Dict:\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        logger.info(f\"Evaluating {task} model...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        dataset = RobertaDataset(texts, true_labels, self.tokenizer, self.max_length)\n",
    "        dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "        \n",
    "        # Get predictions\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        prediction_probs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                \n",
    "                # Get predictions and probabilities\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "                \n",
    "                predictions.extend(preds.cpu().numpy())\n",
    "                prediction_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(true_labels, predictions)\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "            true_labels, predictions, average='macro', zero_division=0\n",
    "        )\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "            true_labels, predictions, average='weighted', zero_division=0\n",
    "        )\n",
    "        \n",
    "        # Cohen's Kappa\n",
    "        kappa = cohen_kappa_score(true_labels, predictions)\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(true_labels, predictions)\n",
    "        \n",
    "        # Classification Report\n",
    "        class_report = classification_report(\n",
    "            true_labels, predictions, \n",
    "            target_names=label_encoder.classes_, \n",
    "            output_dict=True, zero_division=0\n",
    "        )\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'f1_macro': f1_macro,\n",
    "            'precision_weighted': precision_weighted,\n",
    "            'recall_weighted': recall_weighted,\n",
    "            'f1_weighted': f1_weighted,\n",
    "            'cohen_kappa': kappa,\n",
    "            'confusion_matrix': cm,\n",
    "            'classification_report': class_report,\n",
    "            'predictions': predictions,\n",
    "            'prediction_probs': prediction_probs,\n",
    "            'true_labels': true_labels,\n",
    "            'label_names': label_encoder.classes_\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        logger.info(f\"\\n{task.upper()} CLASSIFICATION RESULTS:\")\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(f\"Accuracy:           {accuracy:.4f}\")\n",
    "        logger.info(f\"Precision (macro):  {precision_macro:.4f}\")\n",
    "        logger.info(f\"Recall (macro):     {recall_macro:.4f}\")\n",
    "        logger.info(f\"F1-score (macro):   {f1_macro:.4f}\")\n",
    "        logger.info(f\"F1-score (weighted): {f1_weighted:.4f}\")\n",
    "        logger.info(f\"Cohen's Kappa:      {kappa:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def create_confusion_matrix(self, results: Dict, task: str, save_path: str = None):\n",
    "        \"\"\"Create and save confusion matrix\"\"\"\n",
    "        cm = results['confusion_matrix']\n",
    "        labels = results['label_names']\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=labels, yticklabels=labels)\n",
    "        plt.title(f'{task.capitalize()} Classification - Confusion Matrix', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('Predicted', fontsize=12)\n",
    "        plt.ylabel('True', fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=0)\n",
    "        \n",
    "        if save_path:\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"Confusion matrix saved to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def create_roc_curves(self, results: Dict, task: str, save_path: str = None):\n",
    "        \"\"\"Create ROC curves for multi-class classification\"\"\"\n",
    "        y_true = results['true_labels']\n",
    "        y_prob = np.array(results['prediction_probs'])\n",
    "        labels = results['label_names']\n",
    "        n_classes = len(labels)\n",
    "        \n",
    "        # Binarize labels for multi-class ROC\n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Calculate ROC curve for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        # Plot ROC curves\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, n_classes))\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                    label=f'{labels[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate', fontsize=12)\n",
    "        plt.ylabel('True Positive Rate', fontsize=12)\n",
    "        plt.title(f'{task.capitalize()} Classification - ROC Curves', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        \n",
    "        if save_path:\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"ROC curves saved to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def create_precision_recall_curves(self, results: Dict, task: str, save_path: str = None):\n",
    "        \"\"\"Create Precision-Recall curves\"\"\"\n",
    "        y_true = results['true_labels']\n",
    "        y_prob = np.array(results['prediction_probs'])\n",
    "        labels = results['label_names']\n",
    "        n_classes = len(labels)\n",
    "        \n",
    "        # Binarize labels\n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Calculate PR curve for each class\n",
    "        precision = dict()\n",
    "        recall = dict()\n",
    "        ap_score = dict()\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            precision[i], recall[i], _ = precision_recall_curve(y_true_bin[:, i], y_prob[:, i])\n",
    "            ap_score[i] = average_precision_score(y_true_bin[:, i], y_prob[:, i])\n",
    "        \n",
    "        # Plot PR curves\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, n_classes))\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "                    label=f'{labels[i]} (AP = {ap_score[i]:.2f})')\n",
    "        \n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Recall', fontsize=12)\n",
    "        plt.ylabel('Precision', fontsize=12)\n",
    "        plt.title(f'{task.capitalize()} Classification - Precision-Recall Curves', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        \n",
    "        if save_path:\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"PR curves saved to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def hyperparameter_tuning(self, dataset: Dict, task: str, num_labels: int) -> Dict:\n",
    "        \"\"\"Perform hyperparameter tuning\"\"\"\n",
    "        logger.info(f\"Starting hyperparameter tuning for {task}...\")\n",
    "        \n",
    "        # Define parameter grid\n",
    "        param_grid = {\n",
    "            'learning_rate': [1e-5, 2e-5, 3e-5, 5e-5],\n",
    "            'batch_size': [8, 16, 32],\n",
    "            'num_epochs': [2, 3, 4],\n",
    "            'weight_decay': [0.01, 0.1]\n",
    "        }\n",
    "        \n",
    "        best_score = 0\n",
    "        best_params = {}\n",
    "        results = []\n",
    "        \n",
    "        # Random search over parameters\n",
    "        from itertools import product\n",
    "        import random\n",
    "        \n",
    "        # Generate all combinations and sample randomly\n",
    "        all_combinations = list(product(*param_grid.values()))\n",
    "        random.shuffle(all_combinations)\n",
    "        \n",
    "        # Try up to 10 combinations\n",
    "        for i, params in enumerate(all_combinations[:10]):\n",
    "            param_dict = dict(zip(param_grid.keys(), params))\n",
    "            logger.info(f\"Trying parameters {i+1}/10: {param_dict}\")\n",
    "            \n",
    "            try:\n",
    "                # Train model with current parameters\n",
    "                model, trainer = self.train_model(\n",
    "                    dataset, task, num_labels,\n",
    "                    learning_rate=param_dict['learning_rate'],\n",
    "                    num_epochs=param_dict['num_epochs'],\n",
    "                    batch_size=param_dict['batch_size']\n",
    "                )\n",
    "                \n",
    "                # Evaluate on validation set\n",
    "                eval_results = trainer.evaluate()\n",
    "                score = eval_results['eval_accuracy']\n",
    "                \n",
    "                results.append({\n",
    "                    'params': param_dict,\n",
    "                    'score': score,\n",
    "                    'eval_results': eval_results\n",
    "                })\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = param_dict\n",
    "                    \n",
    "                logger.info(f\"Score: {score:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error with parameters {param_dict}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        logger.info(f\"Best parameters for {task}: {best_params}\")\n",
    "        logger.info(f\"Best score: {best_score:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'all_results': results\n",
    "        }\n",
    "    \n",
    "    def save_results(self, results: Dict, task: str, filename: str = None):\n",
    "        \"\"\"Save evaluation results to file\"\"\"\n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"results/roberta_{task}_results_{timestamp}.json\"\n",
    "        \n",
    "        # Convert numpy arrays to lists for JSON serialization\n",
    "        results_copy = results.copy()\n",
    "        for key, value in results_copy.items():\n",
    "            if isinstance(value, np.ndarray):\n",
    "                results_copy[key] = value.tolist()\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(results_copy, f, indent=2, default=str)\n",
    "        \n",
    "        logger.info(f\"Results saved to {filename}\")\n",
    "    \n",
    "    def create_learning_curves(self, trainer, task: str, save_path: str = None):\n",
    "        \"\"\"Create learning curves from training history\"\"\"\n",
    "        # Get training history\n",
    "        history = trainer.state.log_history\n",
    "        \n",
    "        train_losses = []\n",
    "        eval_losses = []\n",
    "        eval_accuracies = []\n",
    "        \n",
    "        for entry in history:\n",
    "            if 'train_loss' in entry:\n",
    "                train_losses.append(entry['train_loss'])\n",
    "            if 'eval_loss' in entry:\n",
    "                eval_losses.append(entry['eval_loss'])\n",
    "            if 'eval_accuracy' in entry:\n",
    "                eval_accuracies.append(entry['eval_accuracy'])\n",
    "        \n",
    "        # Create plots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Loss curves\n",
    "        epochs = range(1, len(eval_losses) + 1)\n",
    "        ax1.plot(epochs, eval_losses, 'b-', label='Validation Loss')\n",
    "        if len(train_losses) > 0:\n",
    "            train_epochs = np.linspace(1, len(eval_losses), len(train_losses))\n",
    "            ax1.plot(train_epochs, train_losses, 'r-', label='Training Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_title(f'{task.capitalize()} - Learning Curves (Loss)')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Accuracy curve\n",
    "        ax2.plot(epochs, eval_accuracies, 'g-', label='Validation Accuracy')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.set_title(f'{task.capitalize()} - Learning Curves (Accuracy)')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        if save_path:\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"Learning curves saved to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def run_complete_pipeline(self, reddit_data_path: str, \n",
    "                             perform_hyperparameter_tuning: bool = True):\n",
    "        \"\"\"Run the complete training and evaluation pipeline\"\"\"\n",
    "        logger.info(\"üöÄ Starting RoBERTa Complete Training Pipeline\")\n",
    "        logger.info(\"=\" * 60)\n",
    "        \n",
    "        # Setup\n",
    "        self.setup_tokenizer()\n",
    "        \n",
    "        # Load data\n",
    "        reddit_df = self.load_reddit_data(reddit_data_path)\n",
    "        sentiment_data, emotion_data = self.load_external_datasets()\n",
    "        \n",
    "        # Preprocess external data\n",
    "        sentiment_processed = self.preprocess_external_data(sentiment_data, 'sentiment')\n",
    "        emotion_processed = self.preprocess_external_data(emotion_data, 'emotion')\n",
    "        \n",
    "        # Prepare Reddit data\n",
    "        sentiment_texts, sentiment_labels = self.prepare_reddit_data(reddit_df, 'sentiment')\n",
    "        emotion_texts, emotion_labels = self.prepare_reddit_data(reddit_df, 'emotion')\n",
    "        \n",
    "        # Get number of classes\n",
    "        n_sentiment_classes = len(self.sentiment_label_encoder.classes_)\n",
    "        n_emotion_classes = len(self.emotion_label_encoder.classes_)\n",
    "        \n",
    "        logger.info(f\"Sentiment classes: {n_sentiment_classes}\")\n",
    "        logger.info(f\"Emotion classes: {n_emotion_classes}\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # SENTIMENT TRAINING\n",
    "        logger.info(\"\\nüéØ SENTIMENT CLASSIFICATION PIPELINE\")\n",
    "        logger.info(\"=\" * 50)\n",
    "        \n",
    "        # Pre-train on external data\n",
    "        logger.info(\"Pre-training on SST-2 dataset...\")\n",
    "        sentiment_model, sentiment_trainer = self.train_model(\n",
    "            sentiment_processed, 'sentiment', n_sentiment_classes\n",
    "        )\n",
    "        \n",
    "        # Evaluate on Reddit data\n",
    "        sentiment_results = self.evaluate_model(\n",
    "            sentiment_model, sentiment_texts, sentiment_labels, \n",
    "            'sentiment', self.sentiment_label_encoder\n",
    "        )\n",
    "        \n",
    "        # Create visualizations\n",
    "        self.create_confusion_matrix(\n",
    "            sentiment_results, 'sentiment', \n",
    "            'plots/sentiment_confusion_matrix.png'\n",
    "        )\n",
    "        self.create_roc_curves(\n",
    "            sentiment_results, 'sentiment', \n",
    "            'plots/sentiment_roc_curves.png'\n",
    "        )\n",
    "        self.create_precision_recall_curves(\n",
    "            sentiment_results, 'sentiment', \n",
    "            'plots/sentiment_pr_curves.png'\n",
    "        )\n",
    "        self.create_learning_curves(\n",
    "            sentiment_trainer, 'sentiment', \n",
    "            'plots/sentiment_learning_curves.png'\n",
    "        )\n",
    "        \n",
    "        # Hyperparameter tuning\n",
    "        if perform_hyperparameter_tuning:\n",
    "            logger.info(\"Performing hyperparameter tuning for sentiment...\")\n",
    "            sentiment_tuning_results = self.hyperparameter_tuning(\n",
    "                sentiment_processed, 'sentiment', n_sentiment_classes\n",
    "            )\n",
    "            \n",
    "            # Re-train with best parameters\n",
    "            best_params = sentiment_tuning_results['best_params']\n",
    "            logger.info(f\"Re-training sentiment model with best parameters: {best_params}\")\n",
    "            \n",
    "            sentiment_model_tuned, sentiment_trainer_tuned = self.train_model(\n",
    "                sentiment_processed, 'sentiment', n_sentiment_classes, **best_params\n",
    "            )\n",
    "            \n",
    "            # Evaluate tuned model\n",
    "            sentiment_results_tuned = self.evaluate_model(\n",
    "                sentiment_model_tuned, sentiment_texts, sentiment_labels,\n",
    "                'sentiment', self.sentiment_label_encoder\n",
    "            )\n",
    "            \n",
    "            results['sentiment_tuned'] = sentiment_results_tuned\n",
    "            results['sentiment_tuning'] = sentiment_tuning_results\n",
    "        \n",
    "        results['sentiment'] = sentiment_results\n",
    "        \n",
    "        # EMOTION TRAINING\n",
    "        logger.info(\"\\nüí≠ EMOTION CLASSIFICATION PIPELINE\")\n",
    "        logger.info(\"=\" * 50)\n",
    "        \n",
    "        # Pre-train on external data\n",
    "        logger.info(\"Pre-training on GoEmotions dataset...\")\n",
    "        emotion_model, emotion_trainer = self.train_model(\n",
    "            emotion_processed, 'emotion', n_emotion_classes\n",
    "        )\n",
    "        \n",
    "        # Evaluate on Reddit data\n",
    "        emotion_results = self.evaluate_model(\n",
    "            emotion_model, emotion_texts, emotion_labels,\n",
    "            'emotion', self.emotion_label_encoder\n",
    "        )\n",
    "        \n",
    "        # Create visualizations\n",
    "        self.create_confusion_matrix(\n",
    "            emotion_results, 'emotion', \n",
    "            'plots/emotion_confusion_matrix.png'\n",
    "        )\n",
    "        self.create_roc_curves(\n",
    "            emotion_results, 'emotion', \n",
    "            'plots/emotion_roc_curves.png'\n",
    "        )\n",
    "        self.create_precision_recall_curves(\n",
    "            emotion_results, 'emotion', \n",
    "            'plots/emotion_pr_curves.png'\n",
    "        )\n",
    "        self.create_learning_curves(\n",
    "            emotion_trainer, 'emotion', \n",
    "            'plots/emotion_learning_curves.png'\n",
    "        )\n",
    "        \n",
    "        # Hyperparameter tuning\n",
    "        if perform_hyperparameter_tuning:\n",
    "            logger.info(\"Performing hyperparameter tuning for emotion...\")\n",
    "            emotion_tuning_results = self.hyperparameter_tuning(\n",
    "                emotion_processed, 'emotion', n_emotion_classes\n",
    "            )\n",
    "            \n",
    "            # Re-train with best parameters\n",
    "            best_params = emotion_tuning_results['best_params']\n",
    "            logger.info(f\"Re-training emotion model with best parameters: {best_params}\")\n",
    "            \n",
    "            emotion_model_tuned, emotion_trainer_tuned = self.train_model(\n",
    "                emotion_processed, 'emotion', n_emotion_classes, **best_params\n",
    "            )\n",
    "            \n",
    "            # Evaluate tuned model\n",
    "            emotion_results_tuned = self.evaluate_model(\n",
    "                emotion_model_tuned, emotion_texts, emotion_labels,\n",
    "                'emotion', self.emotion_label_encoder\n",
    "            )\n",
    "            \n",
    "            results['emotion_tuned'] = emotion_results_tuned\n",
    "            results['emotion_tuning'] = emotion_tuning_results\n",
    "        \n",
    "        results['emotion'] = emotion_results\n",
    "        \n",
    "        # FINAL SUMMARY\n",
    "        logger.info(\"\\nüìã FINAL SUMMARY\")\n",
    "        logger.info(\"=\" * 50)\n",
    "        \n",
    "        self.create_final_summary(results)\n",
    "        \n",
    "        # Save all results\n",
    "        self.save_results(results, 'complete_pipeline')\n",
    "        \n",
    "        logger.info(\"\\nüéâ PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        logger.info(\"üìÅ Output files:\")\n",
    "        logger.info(\"   - ./roberta_sentiment_model_final/ (sentiment model)\")\n",
    "        logger.info(\"   - ./roberta_emotion_model_final/ (emotion model)\")\n",
    "        logger.info(\"   - ./plots/ (all visualization plots)\")\n",
    "        logger.info(\"   - ./results/ (evaluation results)\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def create_final_summary(self, results: Dict):\n",
    "        \"\"\"Create a comprehensive summary of all results\"\"\"\n",
    "        summary_data = []\n",
    "        \n",
    "        for task in ['sentiment', 'emotion']:\n",
    "            if task in results:\n",
    "                res = results[task]\n",
    "                summary_data.append({\n",
    "                    'Task': task.capitalize(),\n",
    "                    'Model': 'RoBERTa (Base)',\n",
    "                    'Accuracy': f\"{res['accuracy']:.4f}\",\n",
    "                    'Precision (Macro)': f\"{res['precision_macro']:.4f}\",\n",
    "                    'Recall (Macro)': f\"{res['recall_macro']:.4f}\",\n",
    "                    'F1-Score (Macro)': f\"{res['f1_macro']:.4f}\",\n",
    "                    'F1-Score (Weighted)': f\"{res['f1_weighted']:.4f}\",\n",
    "                    'Cohen\\'s Kappa': f\"{res['cohen_kappa']:.4f}\"\n",
    "                })\n",
    "            \n",
    "            # Add tuned results if available\n",
    "            if f'{task}_tuned' in results:\n",
    "                res = results[f'{task}_tuned']\n",
    "                summary_data.append({\n",
    "                    'Task': f\"{task.capitalize()} (Tuned)\",\n",
    "                    'Model': 'RoBERTa (Tuned)',\n",
    "                    'Accuracy': f\"{res['accuracy']:.4f}\",\n",
    "                    'Precision (Macro)': f\"{res['precision_macro']:.4f}\",\n",
    "                    'Recall (Macro)': f\"{res['recall_macro']:.4f}\",\n",
    "                    'F1-Score (Macro)': f\"{res['f1_macro']:.4f}\",\n",
    "                    'F1-Score (Weighted)': f\"{res['f1_weighted']:.4f}\",\n",
    "                    'Cohen\\'s Kappa': f\"{res['cohen_kappa']:.4f}\"\n",
    "                })\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ROBERTA EVALUATION SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(summary_df.to_string(index=False))\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Save summary\n",
    "        summary_df.to_csv('results/roberta_evaluation_summary.csv', index=False)\n",
    "        logger.info(\"Summary saved to: results/roberta_evaluation_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4578393e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cuda\n",
      "INFO:__main__:Setting up RoBERTa tokenizer...\n",
      "INFO:__main__:‚úÖ Tokenizer ready!\n"
     ]
    }
   ],
   "source": [
    "trainer = RobertaTrainer()\n",
    "trainer.setup_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d1b69a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading Reddit data from annotated_reddit_posts.csv...\n",
      "INFO:__main__:‚úÖ Loaded 95 samples from Reddit dataset\n",
      "INFO:__main__:After removing missing values: 95 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_content</th>\n",
       "      <th>original_text</th>\n",
       "      <th>type</th>\n",
       "      <th>score</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d8kzu3m</td>\n",
       "      <td>ya screw username really looking forward note ...</td>\n",
       "      <td>Ya this screws me over completely. I was reall...</td>\n",
       "      <td>comment</td>\n",
       "      <td>2</td>\n",
       "      <td>0.464167</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5jd0fx</td>\n",
       "      <td>username samsung galaxy note7 still more user ...</td>\n",
       "      <td>Cancelled Samsung Galaxy Note7 still has more ...</td>\n",
       "      <td>post</td>\n",
       "      <td>95</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbfyq3r</td>\n",
       "      <td>traded note 7 s7 edge really hope samsung user...</td>\n",
       "      <td>I traded my Note 7 in for an S7 Edge.  I reall...</td>\n",
       "      <td>comment</td>\n",
       "      <td>9</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dbgcdgl</td>\n",
       "      <td>reading username report battery design failed ...</td>\n",
       "      <td>From reading the independent report of why its...</td>\n",
       "      <td>comment</td>\n",
       "      <td>2</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dbftpbx</td>\n",
       "      <td>maybe phone unique username feature explode us...</td>\n",
       "      <td>Maybe the phone's unique exploding feature (or...</td>\n",
       "      <td>comment</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       text_content  \\\n",
       "0  d8kzu3m  ya screw username really looking forward note ...   \n",
       "1   5jd0fx  username samsung galaxy note7 still more user ...   \n",
       "2  dbfyq3r  traded note 7 s7 edge really hope samsung user...   \n",
       "3  dbgcdgl  reading username report battery design failed ...   \n",
       "4  dbftpbx  maybe phone unique username feature explode us...   \n",
       "\n",
       "                                       original_text     type  score  \\\n",
       "0  Ya this screws me over completely. I was reall...  comment      2   \n",
       "1  Cancelled Samsung Galaxy Note7 still has more ...     post     95   \n",
       "2  I traded my Note 7 in for an S7 Edge.  I reall...  comment      9   \n",
       "3  From reading the independent report of why its...  comment      2   \n",
       "4  Maybe the phone's unique exploding feature (or...  comment     -4   \n",
       "\n",
       "   subjectivity sentiment   emotion  \n",
       "0      0.464167  Negative   Sadness  \n",
       "1      0.500000   Neutral  Surprise  \n",
       "2      0.414286  Negative   Sadness  \n",
       "3      0.406250  Positive   Sadness  \n",
       "4      0.800000  Negative     Anger  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df = trainer.load_reddit_data('annotated_reddit_posts.csv')\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d3ba7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading external datasets...\n",
      "INFO:__main__:‚úÖ SST-2 dataset loaded for sentiment classification\n",
      "INFO:__main__:‚úÖ GoEmotions dataset loaded for emotion classification\n"
     ]
    }
   ],
   "source": [
    "sentiment_data, emotion_data = trainer.load_external_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ce275f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preprocessing external data for sentiment...\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:09<00:00, 7469.54 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 3974.05 examples/s]\n",
      "INFO:__main__:‚úÖ Preprocessed sentiment data: 10000 train, 872 val\n",
      "INFO:__main__:Preprocessing external data for emotion...\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13621/13621 [00:02<00:00, 5715.87 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1717/1717 [00:00<00:00, 5314.97 examples/s]\n",
      "INFO:__main__:‚úÖ Preprocessed emotion data: 10000 train, 1717 val\n"
     ]
    }
   ],
   "source": [
    "sentiment_processed = trainer.preprocess_external_data(sentiment_data, 'sentiment')\n",
    "emotion_processed = trainer.preprocess_external_data(emotion_data, 'emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9850abf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reddit_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sentiment_texts, sentiment_labels = trainer.prepare_reddit_data(\u001b[43mreddit_df\u001b[49m, \u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m emotion_texts, emotion_labels = trainer.prepare_reddit_data(reddit_df, \u001b[33m'\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m n_sentiment_classes = \u001b[38;5;28mlen\u001b[39m(trainer.sentiment_label_encoder.classes_)\n",
      "\u001b[31mNameError\u001b[39m: name 'reddit_df' is not defined"
     ]
    }
   ],
   "source": [
    "sentiment_texts, sentiment_labels = trainer.prepare_reddit_data(reddit_df, 'sentiment')\n",
    "emotion_texts, emotion_labels = trainer.prepare_reddit_data(reddit_df, 'emotion')\n",
    "n_sentiment_classes = len(trainer.sentiment_label_encoder.classes_)\n",
    "n_emotion_classes = len(trainer.emotion_label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6135f706",
   "metadata": {},
   "source": [
    "#### Train sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c38c4069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Training RoBERTa model for sentiment classification...\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:__main__:üöÄ Starting sentiment model training...\n",
      "  5%|‚ñå         | 100/1875 [26:14<6:55:36, 14.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.045, 'grad_norm': 5.94059419631958, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|‚ñà         | 200/1875 [57:25<6:38:38, 14.28s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4976, 'grad_norm': 11.920705795288086, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 300/1875 [1:25:55<22:36:17, 51.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3364, 'grad_norm': 19.39594078063965, 'learning_rate': 1.2e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà‚ñè       | 400/1875 [2:06:45<5:52:15, 14.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.314, 'grad_norm': 12.545730590820312, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 500/1875 [3:02:46<6:21:36, 16.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2932, 'grad_norm': 25.356975555419922, 'learning_rate': 2e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 600/1875 [3:29:32<5:56:17, 16.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.357, 'grad_norm': 24.92654800415039, 'learning_rate': 1.8545454545454545e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 625/1875 [3:40:33<5:33:34, 16.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2112049013376236, 'eval_accuracy': 0.9208715596330275, 'eval_f1': 0.9208064662610118, 'eval_precision': 0.9211541197110749, 'eval_recall': 0.9206554685526649, 'eval_runtime': 253.6554, 'eval_samples_per_second': 3.438, 'eval_steps_per_second': 0.217, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 700/1875 [4:01:28<5:19:03, 16.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3117, 'grad_norm': 7.736201286315918, 'learning_rate': 1.7090909090909092e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 800/1875 [4:29:41<5:04:21, 16.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2296, 'grad_norm': 7.278459072113037, 'learning_rate': 1.563636363636364e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 900/1875 [5:08:51<5:06:07, 18.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2398, 'grad_norm': 35.191184997558594, 'learning_rate': 1.4181818181818183e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1000/1875 [5:46:55<3:38:18, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2564, 'grad_norm': 0.6027865409851074, 'learning_rate': 1.2727272727272728e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1100/1875 [6:13:40<8:28:12, 39.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2657, 'grad_norm': 7.3694844245910645, 'learning_rate': 1.1272727272727272e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1200/1875 [7:27:55<2:40:34, 14.27s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1982, 'grad_norm': 41.40156173706055, 'learning_rate': 9.81818181818182e-06, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1250/1875 [7:43:57<2:30:10, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2743379771709442, 'eval_accuracy': 0.9243119266055045, 'eval_f1': 0.9241359310326646, 'eval_precision': 0.9261882078966868, 'eval_recall': 0.9237391597204682, 'eval_runtime': 228.1468, 'eval_samples_per_second': 3.822, 'eval_steps_per_second': 0.241, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1300/1875 [7:56:10<2:19:37, 14.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1565, 'grad_norm': 20.35262680053711, 'learning_rate': 8.363636363636365e-06, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1400/1875 [8:42:51<4:54:08, 37.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1184, 'grad_norm': 0.07821206003427505, 'learning_rate': 6.90909090909091e-06, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1500/1875 [9:14:13<1:36:18, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1485, 'grad_norm': 58.94142532348633, 'learning_rate': 5.4545454545454545e-06, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1600/1875 [10:00:28<3:58:44, 52.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1638, 'grad_norm': 65.2631607055664, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1700/1875 [10:36:12<2:03:56, 42.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1566, 'grad_norm': 9.603964805603027, 'learning_rate': 2.5454545454545456e-06, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1800/1875 [11:13:27<19:36, 15.68s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1327, 'grad_norm': 43.211490631103516, 'learning_rate': 1.090909090909091e-06, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [11:36:35<00:00, 15.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31552377343177795, 'eval_accuracy': 0.9288990825688074, 'eval_f1': 0.9288451819407009, 'eval_precision': 0.9291403286978508, 'eval_recall': 0.9287067441273049, 'eval_runtime': 238.9574, 'eval_samples_per_second': 3.649, 'eval_steps_per_second': 0.23, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [11:36:37<00:00, 22.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 41797.1955, 'train_samples_per_second': 0.718, 'train_steps_per_second': 0.045, 'train_loss': 0.28538743743896483, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Sentiment model training completed!\n"
     ]
    }
   ],
   "source": [
    "sentiment_model, sentiment_trainer = trainer.train_model(\n",
    "    sentiment_processed, 'sentiment', n_sentiment_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "879538ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Evaluating sentiment model...\n",
      "INFO:__main__:\n",
      "SENTIMENT CLASSIFICATION RESULTS:\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__:Accuracy:           0.5579\n",
      "INFO:__main__:Precision (macro):  0.3323\n",
      "INFO:__main__:Recall (macro):     0.3681\n",
      "INFO:__main__:F1-score (macro):   0.3095\n",
      "INFO:__main__:F1-score (weighted): 0.4383\n",
      "INFO:__main__:Cohen's Kappa:      0.0725\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plots/roberta-sent/sentiment_confusion_matrix.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m sentiment_results = trainer.evaluate_model(\n\u001b[32m      2\u001b[39m     sentiment_model, sentiment_texts, sentiment_labels, \n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m, trainer.sentiment_label_encoder\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Sentiment\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentiment_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentiment\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mplots/roberta-sent/sentiment_confusion_matrix.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m trainer.create_roc_curves(sentiment_results, \u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mplots/roberta-sent/sentiment_roc_curves.png\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m trainer.create_precision_recall_curves(sentiment_results, \u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mplots/roberta-sent/sentiment_pr_curves.png\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 355\u001b[39m, in \u001b[36mRobertaTrainer.create_confusion_matrix\u001b[39m\u001b[34m(self, results, task, save_path)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m save_path:\n\u001b[32m    354\u001b[39m     plt.tight_layout()\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_inches\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtight\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConfusion matrix saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    358\u001b[39m plt.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\matplotlib\\pyplot.py:1251\u001b[39m, in \u001b[36msavefig\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1248\u001b[39m fig = gcf()\n\u001b[32m   1249\u001b[39m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[32m   1250\u001b[39m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m res = \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[32m   1252\u001b[39m fig.canvas.draw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\matplotlib\\figure.py:3490\u001b[39m, in \u001b[36mFigure.savefig\u001b[39m\u001b[34m(self, fname, transparent, **kwargs)\u001b[39m\n\u001b[32m   3488\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axes:\n\u001b[32m   3489\u001b[39m         _recursively_make_axes_transparent(stack, ax)\n\u001b[32m-> \u001b[39m\u001b[32m3490\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\matplotlib\\backend_bases.py:2184\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2181\u001b[39m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[32m   2182\u001b[39m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[32m   2183\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m cbook._setattr_cm(\u001b[38;5;28mself\u001b[39m.figure, dpi=dpi):\n\u001b[32m-> \u001b[39m\u001b[32m2184\u001b[39m         result = \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2185\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2187\u001b[39m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2188\u001b[39m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[43m=\u001b[49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2189\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2190\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2191\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2192\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\matplotlib\\backend_bases.py:2040\u001b[39m, in \u001b[36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   2036\u001b[39m     optional_kws = {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[32m   2037\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfacecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33medgecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33morientation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2038\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbbox_inches_restore\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m   2039\u001b[39m     skip = optional_kws - {*inspect.signature(meth).parameters}\n\u001b[32m-> \u001b[39m\u001b[32m2040\u001b[39m     print_method = functools.wraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m *args, **kwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2041\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2042\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[32m   2043\u001b[39m     print_method = meth\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:481\u001b[39m, in \u001b[36mFigureCanvasAgg.print_png\u001b[39m\u001b[34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, *, metadata=\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    435\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    436\u001b[39m \u001b[33;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[32m    437\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    479\u001b[39m \u001b[33;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpng\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:430\u001b[39m, in \u001b[36mFigureCanvasAgg._print_pil\u001b[39m\u001b[34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[33;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[33;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    429\u001b[39m FigureCanvasAgg.draw(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[43mmpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupper\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\matplotlib\\image.py:1657\u001b[39m, in \u001b[36mimsave\u001b[39m\u001b[34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[39m\n\u001b[32m   1655\u001b[39m pil_kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[32m   1656\u001b[39m pil_kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, (dpi, dpi))\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m \u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\PIL\\Image.py:2583\u001b[39m, in \u001b[36mImage.save\u001b[39m\u001b[34m(self, fp, format, **params)\u001b[39m\n\u001b[32m   2581\u001b[39m         fp = builtins.open(filename, \u001b[33m\"\u001b[39m\u001b[33mr+b\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2582\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2583\u001b[39m         fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw+b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2585\u001b[39m     fp = cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'plots/roberta-sent/sentiment_confusion_matrix.png'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_results = trainer.evaluate_model(\n",
    "    sentiment_model, sentiment_texts, sentiment_labels, \n",
    "    'sentiment', trainer.sentiment_label_encoder\n",
    ")\n",
    "\n",
    "# Sentiment\n",
    "trainer.create_confusion_matrix(sentiment_results, 'sentiment', 'plots/roberta-sent/sentiment_confusion_matrix.png')\n",
    "trainer.create_roc_curves(sentiment_results, 'sentiment', 'plots/roberta-sent/sentiment_roc_curves.png')\n",
    "trainer.create_precision_recall_curves(sentiment_results, 'sentiment', 'plots/roberta-sent/sentiment_pr_curves.png')\n",
    "trainer.create_learning_curves(sentiment_trainer, 'sentiment', 'plots/roberta-sent/sentiment_learning_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "166b1e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./roberta_sentiment_model\\\\tokenizer_config.json',\n",
       " './roberta_sentiment_model\\\\special_tokens_map.json',\n",
       " './roberta_sentiment_model\\\\vocab.json',\n",
       " './roberta_sentiment_model\\\\merges.txt',\n",
       " './roberta_sentiment_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume you have these from training\n",
    "# model: your trained RobertaForSequenceClassification model\n",
    "# trainer: the HuggingFace Trainer object (optional, but can also be used to save)\n",
    "\n",
    "# Save model and tokenizer to a directory\n",
    "save_directory = \"./roberta_sentiment_model\"\n",
    "sentiment_model.save_pretrained(save_directory)\n",
    "trainer.tokenizer.save_pretrained(save_directory)  # or use your tokenizer object directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3610c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class id: 1\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "# Load the model and tokenizer from the directory you saved\n",
    "model = RobertaForSequenceClassification.from_pretrained(save_directory)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(save_directory)\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "import torch\n",
    "\n",
    "# Example text\n",
    "text = \"I love this phone, it's amazing!\"\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax(dim=-1).item()\n",
    "\n",
    "print(\"Predicted class id:\", predicted_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c02d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n",
      "True\n",
      "NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)  # Should show \"12.1\" or similar\n",
    "print(torch.cuda.is_available())  # Should be True\n",
    "print(torch.cuda.get_device_name(0))  # Should print \"NVIDIA GeForce RTX 4060\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a7c39",
   "metadata": {},
   "source": [
    "#### Train emotion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c73e4190",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emotion_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m n_emotion_classes = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43memotion_labels\u001b[49m))\n\u001b[32m      2\u001b[39m emotion_model, emotion_trainer = trainer.train_model(\n\u001b[32m      3\u001b[39m     emotion_processed, \u001b[33m'\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m'\u001b[39m, n_emotion_classes\n\u001b[32m      4\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'emotion_labels' is not defined"
     ]
    }
   ],
   "source": [
    "n_emotion_classes = len(set(emotion_labels))\n",
    "emotion_model, emotion_trainer = trainer.train_model(\n",
    "    emotion_processed, 'emotion', n_emotion_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd00eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_results = trainer.evaluate_model(\n",
    "    emotion_model, emotion_texts, emotion_labels,\n",
    "    'emotion', trainer.emotion_label_encoder\n",
    ")\n",
    "\n",
    "trainer.create_confusion_matrix(emotion_results, 'emotion', 'plots/emotion_confusion_matrix.png')\n",
    "trainer.create_roc_curves(emotion_results, 'emotion', 'plots/emotion_roc_curves.png')\n",
    "trainer.create_precision_recall_curves(emotion_results, 'emotion', 'plots/emotion_pr_curves.png')\n",
    "trainer.create_learning_curves(emotion_trainer, 'emotion', 'plots/emotion_learning_curves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6821b18d",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9305d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_tuning_results = trainer.hyperparameter_tuning(\n",
    "    sentiment_processed, 'sentiment', n_sentiment_classes\n",
    ")\n",
    "emotion_tuning_results = trainer.hyperparameter_tuning(\n",
    "    emotion_processed, 'emotion', n_emotion_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "050bd5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Results saved to results/roberta_sentiment_results_20250708_234846.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_results(sentiment_results, 'sentiment')\n",
    "#trainer.save_results(emotion_results, 'emotion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262f0490",
   "metadata": {},
   "source": [
    "## Infer models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4435f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "# Path to your saved model directory\n",
    "model_dir = './roberta_sentiment_model_final/'\n",
    "\n",
    "# Load the model\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Load the tokenizer (if you want to preprocess new text)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b764364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
