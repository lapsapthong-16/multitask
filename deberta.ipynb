{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b95d73f5",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33cd7ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4060\n",
      "CUDA Version: 12.1\n",
      "âœ… Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================================\n",
    "# COMPREHENSIVE MULTI-MODEL TRAINING SYSTEM\n",
    "# ================================================================================================\n",
    "# This notebook trains:\n",
    "# 1. Single-task Sentiment Model (on SST-2)\n",
    "# 2. Single-task Emotion Model (on GoEmotion)  \n",
    "# 3. Multi-task Model (on both datasets)\n",
    "# \n",
    "# Each model uses Bayesian optimization (TPE) for hyperparameter tuning\n",
    "# Only macro F1 and accuracy metrics are used for evaluation\n",
    "# ================================================================================================\n",
    "\n",
    "# Cell 1: Setup and Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, AutoConfig,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "# Memory management\n",
    "def aggressive_memory_cleanup():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.reset_accumulated_memory_stats()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print(\"ðŸ§¹ Memory cleaned!\")\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc03661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration classes defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration Classes\n",
    "class TrainingConfig:\n",
    "    \"\"\"Configuration for training parameters\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"microsoft/deberta-base\",\n",
    "        max_length: int = 128,\n",
    "        batch_size: int = 8,\n",
    "        learning_rate: float = 2e-5,\n",
    "        num_epochs: int = 3,\n",
    "        warmup_ratio: float = 0.1,\n",
    "        weight_decay: float = 0.01,\n",
    "        max_grad_norm: float = 1.0,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1,\n",
    "        output_dir: str = \"./model_output\",\n",
    "        save_total_limit: int = 1,\n",
    "        # Multi-task specific\n",
    "        alpha: float = 0.5,  # Only used for multi-task\n",
    "        task_type: str = \"multitask\"  # \"sentiment\", \"emotion\", \"multitask\"\n",
    "    ):\n",
    "        self.model_name = model_name\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.warmup_ratio = warmup_ratio\n",
    "        self.weight_decay = weight_decay\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_dropout_prob = attention_dropout_prob\n",
    "        self.classifier_dropout = classifier_dropout\n",
    "        self.output_dir = output_dir\n",
    "        self.save_total_limit = save_total_limit\n",
    "        self.alpha = alpha\n",
    "        self.task_type = task_type\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration for model architecture\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sentiment_classes = ['Negative', 'Neutral', 'Positive']\n",
    "        self.emotion_classes = ['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise']\n",
    "        self.sentiment_num_classes = len(self.sentiment_classes)\n",
    "        self.emotion_num_classes = len(self.emotion_classes)\n",
    "\n",
    "model_config = ModelConfig()\n",
    "print(\"âœ… Configuration classes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7e0b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset classes defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Dataset Classes\n",
    "class SingleTaskDataset(Dataset):\n",
    "    \"\"\"Dataset for single-task training (sentiment OR emotion)\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: List[int],\n",
    "        tokenizer,\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        assert len(texts) == len(labels), \"Texts and labels must have same length\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "class MultiTaskDataset(Dataset):\n",
    "    \"\"\"Dataset for multi-task training (sentiment AND emotion)\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        sentiment_labels: List[int],\n",
    "        emotion_labels: List[int],\n",
    "        tokenizer,\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        self.texts = texts\n",
    "        self.sentiment_labels = sentiment_labels\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        assert len(texts) == len(sentiment_labels) == len(emotion_labels), \\\n",
    "            \"All inputs must have same length\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        sentiment_label = self.sentiment_labels[idx]\n",
    "        emotion_label = self.emotion_labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'sentiment_labels': torch.tensor(sentiment_label, dtype=torch.long),\n",
    "            'emotion_labels': torch.tensor(emotion_label, dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "print(\"âœ… Dataset classes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "872f7905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model architectures defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Model Architectures\n",
    "class SingleTaskTransformer(nn.Module):\n",
    "    \"\"\"Single-task transformer for sentiment OR emotion classification\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"microsoft/deberta-base\",\n",
    "        num_classes: int = 3,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super(SingleTaskTransformer, self).__init__()\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load configuration\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        # Transformer encoder\n",
    "        self.encoder = AutoModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        hidden_size = self.encoder.config.hidden_size\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize classification head weights\"\"\"\n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Encoder output\n",
    "        encoder_outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token for classification\n",
    "        pooled_output = encoder_outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return {'logits': logits}\n",
    "    \n",
    "    def save_pretrained(self, save_directory: str):\n",
    "        \"\"\"Save model in HuggingFace format\"\"\"\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "        \n",
    "        # Save model state dict\n",
    "        model_path = os.path.join(save_directory, \"pytorch_model.bin\")\n",
    "        torch.save(self.state_dict(), model_path)\n",
    "        \n",
    "        # Save config\n",
    "        config = {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"num_classes\": self.num_classes,\n",
    "            \"model_type\": \"SingleTaskTransformer\"\n",
    "        }\n",
    "        config_path = os.path.join(save_directory, \"config.json\")\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "        \n",
    "        print(f\"Single-task model saved to {save_directory}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_path: str, **kwargs):\n",
    "        \"\"\"Load model from HuggingFace format\"\"\"\n",
    "        # Load config\n",
    "        config_path = os.path.join(model_path, \"config.json\")\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        # Create model instance\n",
    "        model = cls(\n",
    "            model_name=config[\"model_name\"],\n",
    "            num_classes=config[\"num_classes\"],\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        # Load state dict\n",
    "        model_file = os.path.join(model_path, \"pytorch_model.bin\")\n",
    "        state_dict = torch.load(model_file, map_location='cpu')\n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "        return model\n",
    "\n",
    "class MultiTaskTransformer(nn.Module):\n",
    "    \"\"\"Multi-task transformer for sentiment AND emotion classification\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"microsoft/deberta-base\",\n",
    "        sentiment_num_classes: int = 3,\n",
    "        emotion_num_classes: int = 6,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super(MultiTaskTransformer, self).__init__()\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.sentiment_num_classes = sentiment_num_classes\n",
    "        self.emotion_num_classes = emotion_num_classes\n",
    "        \n",
    "        # Load configuration\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        # Shared encoder\n",
    "        self.shared_encoder = AutoModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        hidden_size = self.shared_encoder.config.hidden_size\n",
    "        \n",
    "        # Task-specific attention layers\n",
    "        self.sentiment_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.emotion_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.sentiment_norm = nn.LayerNorm(hidden_size)\n",
    "        self.emotion_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Classification heads\n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, sentiment_num_classes)\n",
    "        )\n",
    "        \n",
    "        self.emotion_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, emotion_num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize classification head weights\"\"\"\n",
    "        for module in [self.sentiment_classifier, self.emotion_classifier]:\n",
    "            for layer in module:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Shared encoder\n",
    "        encoder_outputs = self.shared_encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        sequence_output = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Task-specific attention\n",
    "        sentiment_attended, _ = self.sentiment_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        sentiment_attended = self.sentiment_norm(sentiment_attended + sequence_output)\n",
    "        \n",
    "        emotion_attended, _ = self.emotion_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        emotion_attended = self.emotion_norm(emotion_attended + sequence_output)\n",
    "        \n",
    "        # Use [CLS] token for classification\n",
    "        sentiment_pooled = sentiment_attended[:, 0, :]\n",
    "        emotion_pooled = emotion_attended[:, 0, :]\n",
    "        \n",
    "        # Classification\n",
    "        sentiment_logits = self.sentiment_classifier(sentiment_pooled)\n",
    "        emotion_logits = self.emotion_classifier(emotion_pooled)\n",
    "        \n",
    "        return {\n",
    "            'sentiment_logits': sentiment_logits,\n",
    "            'emotion_logits': emotion_logits\n",
    "        }\n",
    "    \n",
    "    def save_pretrained(self, save_directory: str):\n",
    "        \"\"\"Save model in HuggingFace format\"\"\"\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "        \n",
    "        # Save model state dict\n",
    "        model_path = os.path.join(save_directory, \"pytorch_model.bin\")\n",
    "        torch.save(self.state_dict(), model_path)\n",
    "        \n",
    "        # Save config\n",
    "        config = {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"sentiment_num_classes\": self.sentiment_num_classes,\n",
    "            \"emotion_num_classes\": self.emotion_num_classes,\n",
    "            \"model_type\": \"MultiTaskTransformer\"\n",
    "        }\n",
    "        config_path = os.path.join(save_directory, \"config.json\")\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "        \n",
    "        print(f\"Multi-task model saved to {save_directory}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_path: str, **kwargs):\n",
    "        \"\"\"Load model from HuggingFace format\"\"\"\n",
    "        # Load config\n",
    "        config_path = os.path.join(model_path, \"config.json\")\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        # Create model instance\n",
    "        model = cls(\n",
    "            model_name=config[\"model_name\"],\n",
    "            sentiment_num_classes=config[\"sentiment_num_classes\"],\n",
    "            emotion_num_classes=config[\"emotion_num_classes\"],\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        # Load state dict\n",
    "        model_file = os.path.join(model_path, \"pytorch_model.bin\")\n",
    "        state_dict = torch.load(model_file, map_location='cpu')\n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "        return model\n",
    "\n",
    "print(\"âœ… Model architectures defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aaf4b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fixed data processing functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Fixed Data Loading and Processing\n",
    "def load_and_process_datasets():\n",
    "    \"\"\"Load and process SST-2 and GoEmotion datasets\"\"\"\n",
    "    \n",
    "    print(\"ðŸ“¥ Loading datasets...\")\n",
    "    \n",
    "    # Load SST-2 for sentiment\n",
    "    try:\n",
    "        sst2_dataset = load_dataset(\"sst2\")\n",
    "        print(f\"âœ… SST-2 loaded: {len(sst2_dataset['train'])} train, {len(sst2_dataset['validation'])} val\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load SST-2: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Load GoEmotion for emotion\n",
    "    try:\n",
    "        emotion_dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "        print(f\"âœ… GoEmotion loaded: {len(emotion_dataset['train'])} train, {len(emotion_dataset['validation'])} val\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load GoEmotion: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Try to load existing encoders first\n",
    "    sentiment_encoder, emotion_encoder = load_existing_encoders()\n",
    "    \n",
    "    # Process sentiment data (SST-2)\n",
    "    sentiment_data = process_sentiment_data(sst2_dataset, sentiment_encoder)\n",
    "    \n",
    "    # Process emotion data (GoEmotion)\n",
    "    emotion_data = process_emotion_data(emotion_dataset, emotion_encoder)\n",
    "    \n",
    "    return sentiment_data, emotion_data\n",
    "\n",
    "def load_existing_encoders():\n",
    "    \"\"\"Load existing encoders from enc/ directory or create new ones\"\"\"\n",
    "    \n",
    "    import joblib\n",
    "    \n",
    "    # Try to load existing encoders\n",
    "    try:\n",
    "        sentiment_encoder = joblib.load('enc/sentiment_label_encoder.pkl')\n",
    "        emotion_encoder = joblib.load('enc/emotion_label_encoder.pkl')\n",
    "        print(\"âœ… Loaded existing encoders from enc/ directory\")\n",
    "        return sentiment_encoder, emotion_encoder\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not load existing encoders: {e}\")\n",
    "        print(\"Creating new encoders...\")\n",
    "        \n",
    "        # Create new encoders\n",
    "        sentiment_encoder = LabelEncoder()\n",
    "        emotion_encoder = LabelEncoder()\n",
    "        sentiment_encoder.classes_ = np.array(model_config.sentiment_classes)\n",
    "        emotion_encoder.classes_ = np.array(model_config.emotion_classes)\n",
    "        \n",
    "        # Save new encoders\n",
    "        os.makedirs('enc', exist_ok=True)\n",
    "        joblib.dump(sentiment_encoder, 'enc/sentiment_label_encoder.pkl')\n",
    "        joblib.dump(emotion_encoder, 'enc/emotion_label_encoder.pkl')\n",
    "        print(\"âœ… Created and saved new encoders\")\n",
    "        \n",
    "        return sentiment_encoder, emotion_encoder\n",
    "\n",
    "def process_sentiment_data(sst2_dataset, sentiment_encoder, max_samples=10000):\n",
    "    \"\"\"Process SST-2 dataset for sentiment classification\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”„ Processing sentiment data...\")\n",
    "    \n",
    "    # Extract texts and labels\n",
    "    train_texts = sst2_dataset['train']['sentence'][:max_samples]\n",
    "    train_labels = sst2_dataset['train']['label'][:max_samples]\n",
    "    \n",
    "    val_texts = sst2_dataset['validation']['sentence']\n",
    "    val_labels = sst2_dataset['validation']['label']\n",
    "    \n",
    "    # Map SST-2 labels to 3 classes: 0->Negative, 1->Positive\n",
    "    # Add some neutral examples by random assignment\n",
    "    expanded_labels = []\n",
    "    expanded_texts = []\n",
    "    \n",
    "    for text, label in zip(train_texts, train_labels):\n",
    "        if label == 0:  # Negative\n",
    "            expanded_labels.append(0)\n",
    "            expanded_texts.append(text)\n",
    "        elif label == 1:  # Positive\n",
    "            # Sometimes assign as positive, sometimes as neutral\n",
    "            if np.random.random() < 0.15:  # 15% chance to be neutral\n",
    "                expanded_labels.append(1)  # Neutral\n",
    "            else:\n",
    "                expanded_labels.append(2)  # Positive\n",
    "            expanded_texts.append(text)\n",
    "    \n",
    "    # Ensure we have all 3 classes\n",
    "    if 1 not in expanded_labels:\n",
    "        # Force some examples to be neutral\n",
    "        neutral_indices = np.random.choice(len(expanded_labels), size=100, replace=False)\n",
    "        for idx in neutral_indices:\n",
    "            expanded_labels[idx] = 1\n",
    "    \n",
    "    # Create train/val/test splits\n",
    "    train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "        expanded_texts, expanded_labels, test_size=0.3, random_state=42, stratify=expanded_labels\n",
    "    )\n",
    "    \n",
    "    val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "        temp_texts, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
    "    )\n",
    "    \n",
    "    sentiment_data = {\n",
    "        'train': {'texts': train_texts, 'labels': train_labels},\n",
    "        'val': {'texts': val_texts, 'labels': val_labels},\n",
    "        'test': {'texts': test_texts, 'labels': test_labels},\n",
    "        'encoder': sentiment_encoder\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Sentiment data processed:\")\n",
    "    print(f\"  Train: {len(train_texts)} samples\")\n",
    "    print(f\"  Val: {len(val_texts)} samples\")\n",
    "    print(f\"  Test: {len(test_texts)} samples\")\n",
    "    \n",
    "    return sentiment_data\n",
    "\n",
    "def process_emotion_data(emotion_dataset, emotion_encoder, max_samples=10000):\n",
    "    \"\"\"Process GoEmotion dataset for emotion classification\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”„ Processing emotion data...\")\n",
    "    \n",
    "    # Filter to first 6 emotions only\n",
    "    def filter_emotions(example):\n",
    "        if isinstance(example['labels'], list):\n",
    "            return example['labels'] and example['labels'][0] in range(6)\n",
    "        else:\n",
    "            return example['labels'] in range(6)\n",
    "    \n",
    "    filtered_train = emotion_dataset['train'].filter(filter_emotions)\n",
    "    filtered_val = emotion_dataset['validation'].filter(filter_emotions)\n",
    "    \n",
    "    # Extract texts and labels\n",
    "    train_texts = filtered_train['text'][:max_samples]\n",
    "    train_labels_raw = filtered_train['labels'][:max_samples]\n",
    "    \n",
    "    val_texts = filtered_val['text']\n",
    "    val_labels_raw = filtered_val['labels']\n",
    "    \n",
    "    # Handle multi-label to single-label conversion\n",
    "    train_labels = []\n",
    "    for label in train_labels_raw:\n",
    "        if isinstance(label, list):\n",
    "            train_labels.append(label[0] if label else 0)\n",
    "        else:\n",
    "            train_labels.append(label)\n",
    "    \n",
    "    val_labels = []\n",
    "    for label in val_labels_raw:\n",
    "        if isinstance(label, list):\n",
    "            val_labels.append(label[0] if label else 0)\n",
    "        else:\n",
    "            val_labels.append(label)\n",
    "    \n",
    "    # Create train/val/test splits\n",
    "    train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "        train_texts, train_labels, test_size=0.3, random_state=42, stratify=train_labels\n",
    "    )\n",
    "    \n",
    "    val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "        temp_texts, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
    "    )\n",
    "    \n",
    "    emotion_data = {\n",
    "        'train': {'texts': train_texts, 'labels': train_labels},\n",
    "        'val': {'texts': val_texts, 'labels': val_labels},\n",
    "        'test': {'texts': test_texts, 'labels': test_labels},\n",
    "        'encoder': emotion_encoder\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Emotion data processed:\")\n",
    "    print(f\"  Train: {len(train_texts)} samples\")\n",
    "    print(f\"  Val: {len(val_texts)} samples\")\n",
    "    print(f\"  Test: {len(test_texts)} samples\")\n",
    "    \n",
    "    return emotion_data\n",
    "\n",
    "def create_multitask_data(sentiment_data, emotion_data):\n",
    "    \"\"\"Create combined dataset for multi-task learning\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”„ Creating multi-task dataset...\")\n",
    "    \n",
    "    # Take minimum length to balance datasets\n",
    "    min_train_len = min(len(sentiment_data['train']['texts']), len(emotion_data['train']['texts']))\n",
    "    min_val_len = min(len(sentiment_data['val']['texts']), len(emotion_data['val']['texts']))\n",
    "    min_test_len = min(len(sentiment_data['test']['texts']), len(emotion_data['test']['texts']))\n",
    "    \n",
    "    multitask_data = {\n",
    "        'train': {\n",
    "            'texts': sentiment_data['train']['texts'][:min_train_len],\n",
    "            'sentiment_labels': sentiment_data['train']['labels'][:min_train_len],\n",
    "            'emotion_labels': emotion_data['train']['labels'][:min_train_len]\n",
    "        },\n",
    "        'val': {\n",
    "            'texts': sentiment_data['val']['texts'][:min_val_len],\n",
    "            'sentiment_labels': sentiment_data['val']['labels'][:min_val_len],\n",
    "            'emotion_labels': emotion_data['val']['labels'][:min_val_len]\n",
    "        },\n",
    "        'test': {\n",
    "            'texts': sentiment_data['test']['texts'][:min_test_len],\n",
    "            'sentiment_labels': sentiment_data['test']['labels'][:min_test_len],\n",
    "            'emotion_labels': emotion_data['test']['labels'][:min_test_len]\n",
    "        },\n",
    "        'sentiment_encoder': sentiment_data['encoder'],\n",
    "        'emotion_encoder': emotion_data['encoder']\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Multi-task data created:\")\n",
    "    print(f\"  Train: {len(multitask_data['train']['texts'])} samples\")\n",
    "    print(f\"  Val: {len(multitask_data['val']['texts'])} samples\")\n",
    "    print(f\"  Test: {len(multitask_data['test']['texts'])} samples\")\n",
    "    \n",
    "    return multitask_data\n",
    "\n",
    "print(\"âœ… Fixed data processing functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2561e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training classes defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Training Classes\n",
    "class SingleTaskTrainer:\n",
    "    \"\"\"Trainer for single-task models\"\"\"\n",
    "    \n",
    "    def __init__(self, config: TrainingConfig, num_classes: int):\n",
    "        self.config = config\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = SingleTaskTransformer(\n",
    "            model_name=config.model_name,\n",
    "            num_classes=num_classes,\n",
    "            hidden_dropout_prob=config.hidden_dropout_prob,\n",
    "            attention_dropout_prob=config.attention_dropout_prob,\n",
    "            classifier_dropout=config.classifier_dropout\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Initialize tracking\n",
    "        self.training_history = {\n",
    "            'train_loss': [],\n",
    "            'train_accuracy': [],\n",
    "            'val_loss': [],\n",
    "            'val_accuracy': [],\n",
    "            'val_f1_macro': []\n",
    "        }\n",
    "    \n",
    "    def create_data_loaders(self, data_splits: Dict):\n",
    "        \"\"\"Create data loaders for training\"\"\"\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = SingleTaskDataset(\n",
    "            texts=data_splits['train']['texts'],\n",
    "            labels=data_splits['train']['labels'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        \n",
    "        val_dataset = SingleTaskDataset(\n",
    "            texts=data_splits['val']['texts'],\n",
    "            labels=data_splits['val']['labels'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Setup optimizer and scheduler\n",
    "        num_training_steps = len(self.train_loader) * self.config.num_epochs\n",
    "        self.optimizer = AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config.learning_rate,\n",
    "            weight_decay=self.config.weight_decay\n",
    "        )\n",
    "        \n",
    "        num_warmup_steps = int(num_training_steps * self.config.warmup_ratio)\n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        for batch in self.train_loader:\n",
    "            # Move to device\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            labels = batch['labels'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = self.loss_fn(outputs['logits'], labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            total_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        \n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate on validation set\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "                \n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = self.loss_fn(outputs['logits'], labels)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "                \n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        f1_macro = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "        \n",
    "        return avg_loss, accuracy, f1_macro\n",
    "    \n",
    "    def train(self, data_splits: Dict):\n",
    "        \"\"\"Main training loop\"\"\"\n",
    "        print(f\"ðŸš€ Starting single-task training ({self.config.task_type})...\")\n",
    "        \n",
    "        # Setup data loaders\n",
    "        self.create_data_loaders(data_splits)\n",
    "        \n",
    "        best_f1 = 0.0\n",
    "        \n",
    "        for epoch in range(self.config.num_epochs):\n",
    "            print(f\"\\nðŸ“ Epoch {epoch + 1}/{self.config.num_epochs}\")\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_accuracy = self.train_epoch()\n",
    "            \n",
    "            # Evaluate\n",
    "            val_loss, val_accuracy, val_f1_macro = self.evaluate()\n",
    "            \n",
    "            # Track metrics\n",
    "            self.training_history['train_loss'].append(train_loss)\n",
    "            self.training_history['train_accuracy'].append(train_accuracy)\n",
    "            self.training_history['val_loss'].append(val_loss)\n",
    "            self.training_history['val_accuracy'].append(val_accuracy)\n",
    "            self.training_history['val_f1_macro'].append(val_f1_macro)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, Val F1: {val_f1_macro:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_f1_macro > best_f1:\n",
    "                best_f1 = val_f1_macro\n",
    "                self.save_model(is_best=True)\n",
    "        \n",
    "        print(f\"\\nâœ… Training completed! Best F1: {best_f1:.4f}\")\n",
    "        return self.training_history\n",
    "    \n",
    "    def save_model(self, is_best=False):\n",
    "        \"\"\"Save model and tokenizer\"\"\"\n",
    "        suffix = \"_best\" if is_best else \"\"\n",
    "        model_dir = os.path.join(self.config.output_dir, f\"model{suffix}\")\n",
    "        \n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        self.model.save_pretrained(model_dir)\n",
    "        self.tokenizer.save_pretrained(model_dir)\n",
    "        \n",
    "        if is_best:\n",
    "            print(f\"ðŸ’¾ Best model saved to {model_dir}\")\n",
    "\n",
    "class MultiTaskTrainer:\n",
    "    \"\"\"Trainer for multi-task models\"\"\"\n",
    "    \n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = MultiTaskTransformer(\n",
    "            model_name=config.model_name,\n",
    "            sentiment_num_classes=model_config.sentiment_num_classes,\n",
    "            emotion_num_classes=model_config.emotion_num_classes,\n",
    "            hidden_dropout_prob=config.hidden_dropout_prob,\n",
    "            attention_dropout_prob=config.attention_dropout_prob,\n",
    "            classifier_dropout=config.classifier_dropout\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Initialize tracking\n",
    "        self.training_history = {\n",
    "            'train_loss': [],\n",
    "            'train_sentiment_accuracy': [],\n",
    "            'train_emotion_accuracy': [],\n",
    "            'val_loss': [],\n",
    "            'val_sentiment_accuracy': [],\n",
    "            'val_emotion_accuracy': [],\n",
    "            'val_sentiment_f1_macro': [],\n",
    "            'val_emotion_f1_macro': []\n",
    "        }\n",
    "    \n",
    "    def create_data_loaders(self, data_splits: Dict):\n",
    "        \"\"\"Create data loaders for training\"\"\"\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = MultiTaskDataset(\n",
    "            texts=data_splits['train']['texts'],\n",
    "            sentiment_labels=data_splits['train']['sentiment_labels'],\n",
    "            emotion_labels=data_splits['train']['emotion_labels'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        \n",
    "        val_dataset = MultiTaskDataset(\n",
    "            texts=data_splits['val']['texts'],\n",
    "            sentiment_labels=data_splits['val']['sentiment_labels'],\n",
    "            emotion_labels=data_splits['val']['emotion_labels'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Setup optimizer and scheduler\n",
    "        num_training_steps = len(self.train_loader) * self.config.num_epochs\n",
    "        self.optimizer = AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config.learning_rate,\n",
    "            weight_decay=self.config.weight_decay\n",
    "        )\n",
    "        \n",
    "        num_warmup_steps = int(num_training_steps * self.config.warmup_ratio)\n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        sentiment_correct = 0\n",
    "        emotion_correct = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        for batch in self.train_loader:\n",
    "            # Move to device\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            sentiment_labels = batch['sentiment_labels'].to(self.device)\n",
    "            emotion_labels = batch['emotion_labels'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Calculate losses\n",
    "            sentiment_loss = self.loss_fn(outputs['sentiment_logits'], sentiment_labels)\n",
    "            emotion_loss = self.loss_fn(outputs['emotion_logits'], emotion_labels)\n",
    "            \n",
    "            # Combined loss with alpha weighting\n",
    "            loss = self.config.alpha * sentiment_loss + (1 - self.config.alpha) * emotion_loss\n",
    "            \n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            sentiment_preds = torch.argmax(outputs['sentiment_logits'], dim=-1)\n",
    "            emotion_preds = torch.argmax(outputs['emotion_logits'], dim=-1)\n",
    "            \n",
    "            sentiment_correct += (sentiment_preds == sentiment_labels).sum().item()\n",
    "            emotion_correct += (emotion_preds == emotion_labels).sum().item()\n",
    "            total_predictions += sentiment_labels.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        sentiment_accuracy = sentiment_correct / total_predictions\n",
    "        emotion_accuracy = emotion_correct / total_predictions\n",
    "        \n",
    "        return avg_loss, sentiment_accuracy, emotion_accuracy\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate on validation set\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        sentiment_predictions = []\n",
    "        emotion_predictions = []\n",
    "        sentiment_labels = []\n",
    "        emotion_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                sentiment_true = batch['sentiment_labels'].to(self.device)\n",
    "                emotion_true = batch['emotion_labels'].to(self.device)\n",
    "                \n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                \n",
    "                sentiment_loss = self.loss_fn(outputs['sentiment_logits'], sentiment_true)\n",
    "                emotion_loss = self.loss_fn(outputs['emotion_logits'], emotion_true)\n",
    "                loss = self.config.alpha * sentiment_loss + (1 - self.config.alpha) * emotion_loss\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                sentiment_preds = torch.argmax(outputs['sentiment_logits'], dim=-1)\n",
    "                emotion_preds = torch.argmax(outputs['emotion_logits'], dim=-1)\n",
    "                \n",
    "                sentiment_predictions.extend(sentiment_preds.cpu().numpy())\n",
    "                emotion_predictions.extend(emotion_preds.cpu().numpy())\n",
    "                sentiment_labels.extend(sentiment_true.cpu().numpy())\n",
    "                emotion_labels.extend(emotion_true.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sentiment_accuracy = accuracy_score(sentiment_labels, sentiment_predictions)\n",
    "        emotion_accuracy = accuracy_score(emotion_labels, emotion_predictions)\n",
    "        sentiment_f1_macro = f1_score(sentiment_labels, sentiment_predictions, average='macro', zero_division=0)\n",
    "        emotion_f1_macro = f1_score(emotion_labels, emotion_predictions, average='macro', zero_division=0)\n",
    "        \n",
    "        return avg_loss, sentiment_accuracy, emotion_accuracy, sentiment_f1_macro, emotion_f1_macro\n",
    "    \n",
    "    def train(self, data_splits: Dict):\n",
    "        \"\"\"Main training loop\"\"\"\n",
    "        print(f\"ðŸš€ Starting multi-task training...\")\n",
    "        \n",
    "        # Setup data loaders\n",
    "        self.create_data_loaders(data_splits)\n",
    "        \n",
    "        best_combined_f1 = 0.0\n",
    "        \n",
    "        for epoch in range(self.config.num_epochs):\n",
    "            print(f\"\\nðŸ“ Epoch {epoch + 1}/{self.config.num_epochs}\")\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_sent_acc, train_emo_acc = self.train_epoch()\n",
    "            \n",
    "            # Evaluate\n",
    "            val_loss, val_sent_acc, val_emo_acc, val_sent_f1, val_emo_f1 = self.evaluate()\n",
    "            \n",
    "            # Track metrics\n",
    "            self.training_history['train_loss'].append(train_loss)\n",
    "            self.training_history['train_sentiment_accuracy'].append(train_sent_acc)\n",
    "            self.training_history['train_emotion_accuracy'].append(train_emo_acc)\n",
    "            self.training_history['val_loss'].append(val_loss)\n",
    "            self.training_history['val_sentiment_accuracy'].append(val_sent_acc)\n",
    "            self.training_history['val_emotion_accuracy'].append(val_emo_acc)\n",
    "            self.training_history['val_sentiment_f1_macro'].append(val_sent_f1)\n",
    "            self.training_history['val_emotion_f1_macro'].append(val_emo_f1)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"  Train Sentiment Acc: {train_sent_acc:.4f}, Train Emotion Acc: {train_emo_acc:.4f}\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"  Val Sentiment Acc: {val_sent_acc:.4f}, F1: {val_sent_f1:.4f}\")\n",
    "            print(f\"  Val Emotion Acc: {val_emo_acc:.4f}, F1: {val_emo_f1:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            combined_f1 = (val_sent_f1 + val_emo_f1) / 2\n",
    "            if combined_f1 > best_combined_f1:\n",
    "                best_combined_f1 = combined_f1\n",
    "                self.save_model(is_best=True)\n",
    "        \n",
    "        print(f\"\\nâœ… Training completed! Best Combined F1: {best_combined_f1:.4f}\")\n",
    "        return self.training_history\n",
    "    \n",
    "    def save_model(self, is_best=False):\n",
    "        \"\"\"Save model and tokenizer\"\"\"\n",
    "        suffix = \"_best\" if is_best else \"\"\n",
    "        model_dir = os.path.join(self.config.output_dir, f\"model{suffix}\")\n",
    "        \n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        self.model.save_pretrained(model_dir)\n",
    "        self.tokenizer.save_pretrained(model_dir)\n",
    "        \n",
    "        if is_best:\n",
    "            print(f\"ðŸ’¾ Best model saved to {model_dir}\")\n",
    "\n",
    "print(\"âœ… Training classes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be26f0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated main training pipeline with initial training phase defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Updated Main Training Pipeline with Initial Training\n",
    "def main_training_pipeline():\n",
    "    \"\"\"Main pipeline: Initial training â†’ Hyperparameter tuning â†’ Final training\"\"\"\n",
    "    \n",
    "    print(\"ðŸš€ STARTING COMPREHENSIVE TRAINING PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load and process datasets\n",
    "    print(\"\\n1ï¸âƒ£ Loading and processing datasets...\")\n",
    "    sentiment_data, emotion_data = load_and_process_datasets()\n",
    "    multitask_data = create_multitask_data(sentiment_data, emotion_data)\n",
    "    \n",
    "    # Model configurations\n",
    "    model_name = \"microsoft/deberta-base\"  # You can change this to \"vinai/bertweet-base\"\n",
    "    n_trials = 15  # Number of hyperparameter tuning trials\n",
    "    \n",
    "    # Store results\n",
    "    all_results = {}\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # PHASE 1: INITIAL TRAINING WITH DEFAULT PARAMETERS\n",
    "    # ==============================================================================\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(f\"ðŸ“ PHASE 1: INITIAL TRAINING WITH DEFAULT PARAMETERS\")\n",
    "    print(f\"=\"*80)\n",
    "    \n",
    "    # Default configuration\n",
    "    default_config_sentiment = TrainingConfig(\n",
    "        model_name=model_name,\n",
    "        batch_size=8,\n",
    "        learning_rate=2e-5,\n",
    "        num_epochs=3,\n",
    "        max_length=128,\n",
    "        task_type=\"sentiment\",\n",
    "        output_dir=\"./initial_sentiment_model\"\n",
    "    )\n",
    "    \n",
    "    default_config_emotion = TrainingConfig(\n",
    "        model_name=model_name,\n",
    "        batch_size=8,\n",
    "        learning_rate=2e-5,\n",
    "        num_epochs=3,\n",
    "        max_length=128,\n",
    "        task_type=\"emotion\",\n",
    "        output_dir=\"./initial_emotion_model\"\n",
    "    )\n",
    "    \n",
    "    default_config_multitask = TrainingConfig(\n",
    "        model_name=model_name,\n",
    "        batch_size=8,\n",
    "        learning_rate=2e-5,\n",
    "        num_epochs=3,\n",
    "        max_length=128,\n",
    "        alpha=0.5,\n",
    "        task_type=\"multitask\",\n",
    "        output_dir=\"./initial_multitask_model\"\n",
    "    )\n",
    "    \n",
    "    # 1.1 Train Initial Sentiment Model\n",
    "    print(f\"\\n2ï¸âƒ£ Training Initial Sentiment Model...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    initial_sentiment_trainer = SingleTaskTrainer(\n",
    "        config=default_config_sentiment,\n",
    "        num_classes=model_config.sentiment_num_classes\n",
    "    )\n",
    "    initial_sentiment_history = initial_sentiment_trainer.train(sentiment_data)\n",
    "    \n",
    "    # Evaluate initial sentiment model\n",
    "    initial_sentiment_results = evaluate_model(\n",
    "        model_path=\"./initial_sentiment_model/model_best\",\n",
    "        model_type=\"sentiment\",\n",
    "        test_data=sentiment_data['test'],\n",
    "        model_name=model_name\n",
    "    )\n",
    "    all_results['initial_sentiment'] = initial_sentiment_results\n",
    "    \n",
    "    # 1.2 Train Initial Emotion Model\n",
    "    print(f\"\\n3ï¸âƒ£ Training Initial Emotion Model...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    initial_emotion_trainer = SingleTaskTrainer(\n",
    "        config=default_config_emotion,\n",
    "        num_classes=model_config.emotion_num_classes\n",
    "    )\n",
    "    initial_emotion_history = initial_emotion_trainer.train(emotion_data)\n",
    "    \n",
    "    # Evaluate initial emotion model\n",
    "    initial_emotion_results = evaluate_model(\n",
    "        model_path=\"./initial_emotion_model/model_best\",\n",
    "        model_type=\"emotion\",\n",
    "        test_data=emotion_data['test'],\n",
    "        model_name=model_name\n",
    "    )\n",
    "    all_results['initial_emotion'] = initial_emotion_results\n",
    "    \n",
    "    # 1.3 Train Initial Multi-task Model\n",
    "    print(f\"\\n4ï¸âƒ£ Training Initial Multi-task Model...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    initial_multitask_trainer = MultiTaskTrainer(config=default_config_multitask)\n",
    "    initial_multitask_history = initial_multitask_trainer.train(multitask_data)\n",
    "    \n",
    "    # Evaluate initial multi-task model\n",
    "    initial_multitask_results = evaluate_model(\n",
    "        model_path=\"./initial_multitask_model/model_best\",\n",
    "        model_type=\"multitask\",\n",
    "        test_data=multitask_data['test'],\n",
    "        model_name=model_name\n",
    "    )\n",
    "    all_results['initial_multitask'] = initial_multitask_results\n",
    "    \n",
    "    # Display initial results summary\n",
    "    print(f\"\\n5ï¸âƒ£ Initial Results Summary...\")\n",
    "    print(\"=\"*60)\n",
    "    create_initial_results_summary(\n",
    "        sentiment_results=all_results['initial_sentiment'],\n",
    "        emotion_results=all_results['initial_emotion'],\n",
    "        multitask_results=all_results['initial_multitask']\n",
    "    )\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # PHASE 2: HYPERPARAMETER TUNING\n",
    "    # ==============================================================================\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(f\"ðŸ“ PHASE 2: HYPERPARAMETER TUNING\")\n",
    "    print(f\"=\"*80)\n",
    "    \n",
    "    # 2.1 Hyperparameter tuning for sentiment\n",
    "    print(f\"\\n6ï¸âƒ£ Hyperparameter Tuning for Sentiment Model...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    sentiment_tuner = HyperparameterTuner(\n",
    "        model_type=\"sentiment\",\n",
    "        data_splits=sentiment_data,\n",
    "        n_trials=n_trials,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    sentiment_study = sentiment_tuner.tune()\n",
    "    \n",
    "    # 2.2 Hyperparameter tuning for emotion\n",
    "    print(f\"\\n7ï¸âƒ£ Hyperparameter Tuning for Emotion Model...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    emotion_tuner = HyperparameterTuner(\n",
    "        model_type=\"emotion\",\n",
    "        data_splits=emotion_data,\n",
    "        n_trials=n_trials,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    emotion_study = emotion_tuner.tune()\n",
    "    \n",
    "    # 2.3 Hyperparameter tuning for multi-task\n",
    "    print(f\"\\n8ï¸âƒ£ Hyperparameter Tuning for Multi-task Model...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    multitask_tuner = HyperparameterTuner(\n",
    "        model_type=\"multitask\",\n",
    "        data_splits=multitask_data,\n",
    "        n_trials=n_trials,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    multitask_study = multitask_tuner.tune()\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # PHASE 3: FINAL TRAINING WITH OPTIMIZED PARAMETERS\n",
    "    # ==============================================================================\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(f\"ðŸ“ PHASE 3: FINAL TRAINING WITH OPTIMIZED PARAMETERS\")\n",
    "    print(f\"=\"*80)\n",
    "    \n",
    "    # 3.1 Train optimized sentiment model\n",
    "    print(f\"\\n9ï¸âƒ£ Training Optimized Sentiment Model...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    optimized_sentiment_trainer, optimized_sentiment_history = train_with_best_params(\n",
    "        model_type=\"sentiment\",\n",
    "        data_splits=sentiment_data,\n",
    "        best_params=sentiment_study.best_params,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    \n",
    "    # Evaluate optimized sentiment model\n",
    "    optimized_sentiment_results = evaluate_model(\n",
    "        model_path=\"./final_sentiment_model/model_best\",\n",
    "        model_type=\"sentiment\",\n",
    "        test_data=sentiment_data['test'],\n",
    "        model_name=model_name\n",
    "    )\n",
    "    all_results['optimized_sentiment'] = optimized_sentiment_results\n",
    "    \n",
    "    # 3.2 Train optimized emotion model\n",
    "    print(f\"\\nðŸ”Ÿ Training Optimized Emotion Model...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    optimized_emotion_trainer, optimized_emotion_history = train_with_best_params(\n",
    "        model_type=\"emotion\",\n",
    "        data_splits=emotion_data,\n",
    "        best_params=emotion_study.best_params,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    \n",
    "    # Evaluate optimized emotion model\n",
    "    optimized_emotion_results = evaluate_model(\n",
    "        model_path=\"./final_emotion_model/model_best\",\n",
    "        model_type=\"emotion\",\n",
    "        test_data=emotion_data['test'],\n",
    "        model_name=model_name\n",
    "    )\n",
    "    all_results['optimized_emotion'] = optimized_emotion_results\n",
    "    \n",
    "    # 3.3 Train optimized multi-task model\n",
    "    print(f\"\\n1ï¸âƒ£1ï¸âƒ£ Training Optimized Multi-task Model...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    optimized_multitask_trainer, optimized_multitask_history = train_with_best_params(\n",
    "        model_type=\"multitask\",\n",
    "        data_splits=multitask_data,\n",
    "        best_params=multitask_study.best_params,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    \n",
    "    # Evaluate optimized multi-task model\n",
    "    optimized_multitask_results = evaluate_model(\n",
    "        model_path=\"./final_multitask_model/model_best\",\n",
    "        model_type=\"multitask\",\n",
    "        test_data=multitask_data['test'],\n",
    "        model_name=model_name\n",
    "    )\n",
    "    all_results['optimized_multitask'] = optimized_multitask_results\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # PHASE 4: COMPREHENSIVE RESULTS COMPARISON\n",
    "    # ==============================================================================\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(f\"ðŸ“ PHASE 4: COMPREHENSIVE RESULTS COMPARISON\")\n",
    "    print(f\"=\"*80)\n",
    "    \n",
    "    # Create comprehensive comparison\n",
    "    create_comprehensive_results_comparison(all_results)\n",
    "    \n",
    "    # Save all results\n",
    "    results_summary = {\n",
    "        'initial_models': {\n",
    "            'sentiment': all_results['initial_sentiment'],\n",
    "            'emotion': all_results['initial_emotion'],\n",
    "            'multitask': all_results['initial_multitask']\n",
    "        },\n",
    "        'optimized_models': {\n",
    "            'sentiment': all_results['optimized_sentiment'],\n",
    "            'emotion': all_results['optimized_emotion'],\n",
    "            'multitask': all_results['optimized_multitask']\n",
    "        },\n",
    "        'hyperparameter_studies': {\n",
    "            'sentiment': sentiment_study.best_params,\n",
    "            'emotion': emotion_study.best_params,\n",
    "            'multitask': multitask_study.best_params\n",
    "        },\n",
    "        'improvements': {\n",
    "            'sentiment': {\n",
    "                'accuracy_improvement': all_results['optimized_sentiment']['accuracy'] - all_results['initial_sentiment']['accuracy'],\n",
    "                'f1_improvement': all_results['optimized_sentiment']['f1_macro'] - all_results['initial_sentiment']['f1_macro']\n",
    "            },\n",
    "            'emotion': {\n",
    "                'accuracy_improvement': all_results['optimized_emotion']['accuracy'] - all_results['initial_emotion']['accuracy'],\n",
    "                'f1_improvement': all_results['optimized_emotion']['f1_macro'] - all_results['initial_emotion']['f1_macro']\n",
    "            },\n",
    "            'multitask': {\n",
    "                'sentiment_accuracy_improvement': all_results['optimized_multitask']['sentiment_accuracy'] - all_results['initial_multitask']['sentiment_accuracy'],\n",
    "                'emotion_accuracy_improvement': all_results['optimized_multitask']['emotion_accuracy'] - all_results['initial_multitask']['emotion_accuracy'],\n",
    "                'combined_f1_improvement': all_results['optimized_multitask']['combined_f1_macro'] - all_results['initial_multitask']['combined_f1_macro']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open('comprehensive_results_summary.json', 'w') as f:\n",
    "        json.dump(results_summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nâœ… COMPLETE PIPELINE FINISHED!\")\n",
    "    print(f\"ðŸ“ Results saved to: comprehensive_results_summary.json\")\n",
    "    print(f\"ðŸ“ Initial models saved to: ./initial_*_model/\")\n",
    "    print(f\"ðŸ“ Optimized models saved to: ./final_*_model/\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def create_initial_results_summary(sentiment_results: Dict, emotion_results: Dict, multitask_results: Dict):\n",
    "    \"\"\"Create a summary of initial model results\"\"\"\n",
    "    \n",
    "    print(f\"\\nðŸ“Š INITIAL MODELS RESULTS SUMMARY\")\n",
    "    print(f\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ INITIAL SENTIMENT MODEL:\")\n",
    "    print(f\"  Accuracy: {sentiment_results['accuracy']:.4f}\")\n",
    "    print(f\"  F1 Macro: {sentiment_results['f1_macro']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ˜Š INITIAL EMOTION MODEL:\")\n",
    "    print(f\"  Accuracy: {emotion_results['accuracy']:.4f}\")\n",
    "    print(f\"  F1 Macro: {emotion_results['f1_macro']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”— INITIAL MULTI-TASK MODEL:\")\n",
    "    print(f\"  Sentiment - Accuracy: {multitask_results['sentiment_accuracy']:.4f}, F1: {multitask_results['sentiment_f1_macro']:.4f}\")\n",
    "    print(f\"  Emotion - Accuracy: {multitask_results['emotion_accuracy']:.4f}, F1: {multitask_results['emotion_f1_macro']:.4f}\")\n",
    "    print(f\"  Combined - Accuracy: {multitask_results['combined_accuracy']:.4f}, F1: {multitask_results['combined_f1_macro']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ These are baseline results. Hyperparameter tuning will aim to improve them!\")\n",
    "\n",
    "def create_comprehensive_results_comparison(all_results: Dict):\n",
    "    \"\"\"Create comprehensive comparison between initial and optimized models\"\"\"\n",
    "    \n",
    "    print(f\"\\nðŸ“Š COMPREHENSIVE RESULTS COMPARISON\")\n",
    "    print(f\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ SENTIMENT MODEL COMPARISON:\")\n",
    "    print(f\"  Initial    - Accuracy: {all_results['initial_sentiment']['accuracy']:.4f}, F1: {all_results['initial_sentiment']['f1_macro']:.4f}\")\n",
    "    print(f\"  Optimized  - Accuracy: {all_results['optimized_sentiment']['accuracy']:.4f}, F1: {all_results['optimized_sentiment']['f1_macro']:.4f}\")\n",
    "    \n",
    "    sent_acc_improve = all_results['optimized_sentiment']['accuracy'] - all_results['initial_sentiment']['accuracy']\n",
    "    sent_f1_improve = all_results['optimized_sentiment']['f1_macro'] - all_results['initial_sentiment']['f1_macro']\n",
    "    print(f\"  Improvement - Accuracy: {sent_acc_improve:+.4f}, F1: {sent_f1_improve:+.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ˜Š EMOTION MODEL COMPARISON:\")\n",
    "    print(f\"  Initial    - Accuracy: {all_results['initial_emotion']['accuracy']:.4f}, F1: {all_results['initial_emotion']['f1_macro']:.4f}\")\n",
    "    print(f\"  Optimized  - Accuracy: {all_results['optimized_emotion']['accuracy']:.4f}, F1: {all_results['optimized_emotion']['f1_macro']:.4f}\")\n",
    "    \n",
    "    emo_acc_improve = all_results['optimized_emotion']['accuracy'] - all_results['initial_emotion']['accuracy']\n",
    "    emo_f1_improve = all_results['optimized_emotion']['f1_macro'] - all_results['initial_emotion']['f1_macro']\n",
    "    print(f\"  Improvement - Accuracy: {emo_acc_improve:+.4f}, F1: {emo_f1_improve:+.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”— MULTI-TASK MODEL COMPARISON:\")\n",
    "    print(f\"  SENTIMENT TASK:\")\n",
    "    print(f\"    Initial    - Accuracy: {all_results['initial_multitask']['sentiment_accuracy']:.4f}, F1: {all_results['initial_multitask']['sentiment_f1_macro']:.4f}\")\n",
    "    print(f\"    Optimized  - Accuracy: {all_results['optimized_multitask']['sentiment_accuracy']:.4f}, F1: {all_results['optimized_multitask']['sentiment_f1_macro']:.4f}\")\n",
    "    \n",
    "    mt_sent_acc_improve = all_results['optimized_multitask']['sentiment_accuracy'] - all_results['initial_multitask']['sentiment_accuracy']\n",
    "    mt_sent_f1_improve = all_results['optimized_multitask']['sentiment_f1_macro'] - all_results['initial_multitask']['sentiment_f1_macro']\n",
    "    print(f\"    Improvement - Accuracy: {mt_sent_acc_improve:+.4f}, F1: {mt_sent_f1_improve:+.4f}\")\n",
    "    \n",
    "    print(f\"  EMOTION TASK:\")\n",
    "    print(f\"    Initial    - Accuracy: {all_results['initial_multitask']['emotion_accuracy']:.4f}, F1: {all_results['initial_multitask']['emotion_f1_macro']:.4f}\")\n",
    "    print(f\"    Optimized  - Accuracy: {all_results['optimized_multitask']['emotion_accuracy']:.4f}, F1: {all_results['optimized_multitask']['emotion_f1_macro']:.4f}\")\n",
    "    \n",
    "    mt_emo_acc_improve = all_results['optimized_multitask']['emotion_accuracy'] - all_results['initial_multitask']['emotion_accuracy']\n",
    "    mt_emo_f1_improve = all_results['optimized_multitask']['emotion_f1_macro'] - all_results['initial_multitask']['emotion_f1_macro']\n",
    "    print(f\"    Improvement - Accuracy: {mt_emo_acc_improve:+.4f}, F1: {mt_emo_f1_improve:+.4f}\")\n",
    "    \n",
    "    print(f\"  COMBINED:\")\n",
    "    print(f\"    Initial    - Accuracy: {all_results['initial_multitask']['combined_accuracy']:.4f}, F1: {all_results['initial_multitask']['combined_f1_macro']:.4f}\")\n",
    "    print(f\"    Optimized  - Accuracy: {all_results['optimized_multitask']['combined_accuracy']:.4f}, F1: {all_results['optimized_multitask']['combined_f1_macro']:.4f}\")\n",
    "    \n",
    "    mt_combined_acc_improve = all_results['optimized_multitask']['combined_accuracy'] - all_results['initial_multitask']['combined_accuracy']\n",
    "    mt_combined_f1_improve = all_results['optimized_multitask']['combined_f1_macro'] - all_results['initial_multitask']['combined_f1_macro']\n",
    "    print(f\"    Improvement - Accuracy: {mt_combined_acc_improve:+.4f}, F1: {mt_combined_f1_improve:+.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ SINGLE-TASK vs MULTI-TASK COMPARISON (OPTIMIZED):\")\n",
    "    print(f\"  SENTIMENT:\")\n",
    "    print(f\"    Single-task: Accuracy: {all_results['optimized_sentiment']['accuracy']:.4f}, F1: {all_results['optimized_sentiment']['f1_macro']:.4f}\")\n",
    "    print(f\"    Multi-task:  Accuracy: {all_results['optimized_multitask']['sentiment_accuracy']:.4f}, F1: {all_results['optimized_multitask']['sentiment_f1_macro']:.4f}\")\n",
    "    \n",
    "    print(f\"  EMOTION:\")\n",
    "    print(f\"    Single-task: Accuracy: {all_results['optimized_emotion']['accuracy']:.4f}, F1: {all_results['optimized_emotion']['f1_macro']:.4f}\")\n",
    "    print(f\"    Multi-task:  Accuracy: {all_results['optimized_multitask']['emotion_accuracy']:.4f}, F1: {all_results['optimized_multitask']['emotion_f1_macro']:.4f}\")\n",
    "    \n",
    "    print(f\"=\"*80)\n",
    "\n",
    "print(\"âœ… Updated main training pipeline with initial training phase defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644ea1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fixed evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Fixed Evaluation Functions\n",
    "def evaluate_model(model_path: str, model_type: str, test_data: Dict, model_name: str = \"microsoft/deberta-base\"):\n",
    "    \"\"\"Fixed evaluation function that handles data structure correctly\"\"\"\n",
    "    \n",
    "    print(f\"ðŸ“Š Evaluating {model_type} model...\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    # Load model\n",
    "    if model_type == \"multitask\":\n",
    "        model = MultiTaskTransformer.from_pretrained(model_path)\n",
    "    else:\n",
    "        model = SingleTaskTransformer.from_pretrained(model_path)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare test data - FIXED: Handle single-task vs multi-task correctly\n",
    "    if model_type == \"multitask\":\n",
    "        test_dataset = MultiTaskDataset(\n",
    "            texts=test_data['texts'],\n",
    "            sentiment_labels=test_data['sentiment_labels'],\n",
    "            emotion_labels=test_data['emotion_labels'],\n",
    "            tokenizer=tokenizer,\n",
    "            max_length=128\n",
    "        )\n",
    "    else:\n",
    "        # For single-task, use 'labels' directly (not 'sentiment_labels' or 'emotion_labels')\n",
    "        test_dataset = SingleTaskDataset(\n",
    "            texts=test_data['texts'],\n",
    "            labels=test_data['labels'],  # FIXED: Use 'labels' directly\n",
    "            tokenizer=tokenizer,\n",
    "            max_length=128\n",
    "        )\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    # Evaluate\n",
    "    if model_type == \"multitask\":\n",
    "        all_sentiment_predictions = []\n",
    "        all_emotion_predictions = []\n",
    "        all_sentiment_labels = []\n",
    "        all_emotion_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                \n",
    "                sentiment_preds = torch.argmax(outputs['sentiment_logits'], dim=-1)\n",
    "                emotion_preds = torch.argmax(outputs['emotion_logits'], dim=-1)\n",
    "                \n",
    "                all_sentiment_predictions.extend(sentiment_preds.cpu().numpy())\n",
    "                all_emotion_predictions.extend(emotion_preds.cpu().numpy())\n",
    "                all_sentiment_labels.extend(batch['sentiment_labels'].numpy())\n",
    "                all_emotion_labels.extend(batch['emotion_labels'].numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sentiment_accuracy = accuracy_score(all_sentiment_labels, all_sentiment_predictions)\n",
    "        emotion_accuracy = accuracy_score(all_emotion_labels, all_emotion_predictions)\n",
    "        sentiment_f1_macro = f1_score(all_sentiment_labels, all_sentiment_predictions, average='macro', zero_division=0)\n",
    "        emotion_f1_macro = f1_score(all_emotion_labels, all_emotion_predictions, average='macro', zero_division=0)\n",
    "        \n",
    "        results = {\n",
    "            'sentiment_accuracy': sentiment_accuracy,\n",
    "            'emotion_accuracy': emotion_accuracy,\n",
    "            'sentiment_f1_macro': sentiment_f1_macro,\n",
    "            'emotion_f1_macro': emotion_f1_macro,\n",
    "            'combined_accuracy': (sentiment_accuracy + emotion_accuracy) / 2,\n",
    "            'combined_f1_macro': (sentiment_f1_macro + emotion_f1_macro) / 2\n",
    "        }\n",
    "        \n",
    "        print(f\"ðŸ“Š Multi-task Results:\")\n",
    "        print(f\"  Sentiment - Accuracy: {sentiment_accuracy:.4f}, F1: {sentiment_f1_macro:.4f}\")\n",
    "        print(f\"  Emotion - Accuracy: {emotion_accuracy:.4f}, F1: {emotion_f1_macro:.4f}\")\n",
    "        print(f\"  Combined - Accuracy: {results['combined_accuracy']:.4f}, F1: {results['combined_f1_macro']:.4f}\")\n",
    "        \n",
    "    else:\n",
    "        # Single-task evaluation\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "                \n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(batch['labels'].numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        f1_macro = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'f1_macro': f1_macro\n",
    "        }\n",
    "        \n",
    "        print(f\"ðŸ“Š {model_type.capitalize()} Results:\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  F1 Macro: {f1_macro:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_results_summary(sentiment_results: Dict, emotion_results: Dict, multitask_results: Dict):\n",
    "    \"\"\"Create a summary of all model results\"\"\"\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(f\"ðŸ“Š FINAL RESULTS SUMMARY\")\n",
    "    print(f\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ SINGLE-TASK SENTIMENT MODEL:\")\n",
    "    print(f\"  Accuracy: {sentiment_results['accuracy']:.4f}\")\n",
    "    print(f\"  F1 Macro: {sentiment_results['f1_macro']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ˜Š SINGLE-TASK EMOTION MODEL:\")\n",
    "    print(f\"  Accuracy: {emotion_results['accuracy']:.4f}\")\n",
    "    print(f\"  F1 Macro: {emotion_results['f1_macro']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”— MULTI-TASK MODEL:\")\n",
    "    print(f\"  Sentiment - Accuracy: {multitask_results['sentiment_accuracy']:.4f}, F1: {multitask_results['sentiment_f1_macro']:.4f}\")\n",
    "    print(f\"  Emotion - Accuracy: {multitask_results['emotion_accuracy']:.4f}, F1: {multitask_results['emotion_f1_macro']:.4f}\")\n",
    "    print(f\"  Combined - Accuracy: {multitask_results['combined_accuracy']:.4f}, F1: {multitask_results['combined_f1_macro']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ COMPARISON:\")\n",
    "    print(f\"  Single-task Sentiment vs Multi-task Sentiment:\")\n",
    "    print(f\"    Accuracy: {sentiment_results['accuracy']:.4f} vs {multitask_results['sentiment_accuracy']:.4f}\")\n",
    "    print(f\"    F1 Macro: {sentiment_results['f1_macro']:.4f} vs {multitask_results['sentiment_f1_macro']:.4f}\")\n",
    "    \n",
    "    print(f\"  Single-task Emotion vs Multi-task Emotion:\")\n",
    "    print(f\"    Accuracy: {emotion_results['accuracy']:.4f} vs {multitask_results['emotion_accuracy']:.4f}\")\n",
    "    print(f\"    F1 Macro: {emotion_results['f1_macro']:.4f} vs {multitask_results['emotion_f1_macro']:.4f}\")\n",
    "    \n",
    "    print(f\"=\"*80)\n",
    "\n",
    "print(\"âœ… Fixed evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c9e3075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fixed hyperparameter tuning classes defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Fixed Hyperparameter Tuning\n",
    "class HyperparameterTuner:\n",
    "    \"\"\"Fixed hyperparameter tuning using TPE\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_type: str,  # \"sentiment\", \"emotion\", \"multitask\"\n",
    "        data_splits: Dict,\n",
    "        n_trials: int = 20,\n",
    "        model_name: str = \"microsoft/deberta-base\"\n",
    "    ):\n",
    "        self.model_type = model_type\n",
    "        self.data_splits = data_splits\n",
    "        self.n_trials = n_trials\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        print(f\"ðŸ” Hyperparameter tuner initialized for {model_type}\")\n",
    "    \n",
    "    def objective(self, trial):\n",
    "        \"\"\"Optuna objective function\"\"\"\n",
    "        \n",
    "        # Sample hyperparameters\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-4, log=True)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [4, 8, 16])\n",
    "        num_epochs = trial.suggest_int('num_epochs', 3, 8)\n",
    "        warmup_ratio = trial.suggest_float('warmup_ratio', 0.05, 0.2)\n",
    "        weight_decay = trial.suggest_float('weight_decay', 0.001, 0.1)\n",
    "        hidden_dropout = trial.suggest_float('hidden_dropout_prob', 0.1, 0.3)\n",
    "        classifier_dropout = trial.suggest_float('classifier_dropout', 0.1, 0.3)\n",
    "        max_length = trial.suggest_categorical('max_length', [128, 256])\n",
    "        \n",
    "        # Multi-task specific parameter\n",
    "        alpha = trial.suggest_float('alpha', 0.3, 0.7) if self.model_type == \"multitask\" else 0.5\n",
    "        \n",
    "        # Create config\n",
    "        config = TrainingConfig(\n",
    "            model_name=self.model_name,\n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=num_epochs,\n",
    "            warmup_ratio=warmup_ratio,\n",
    "            weight_decay=weight_decay,\n",
    "            hidden_dropout_prob=hidden_dropout,\n",
    "            classifier_dropout=classifier_dropout,\n",
    "            max_length=max_length,\n",
    "            alpha=alpha,\n",
    "            task_type=self.model_type,\n",
    "            output_dir=f\"./temp_trial_{trial.number}\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # Clear memory\n",
    "            aggressive_memory_cleanup()\n",
    "            \n",
    "            # Train model\n",
    "            if self.model_type == \"multitask\":\n",
    "                trainer = MultiTaskTrainer(config)\n",
    "                history = trainer.train(self.data_splits)\n",
    "                \n",
    "                # Return combined F1 score\n",
    "                best_sentiment_f1 = max(history['val_sentiment_f1_macro'])\n",
    "                best_emotion_f1 = max(history['val_emotion_f1_macro'])\n",
    "                combined_f1 = (best_sentiment_f1 + best_emotion_f1) / 2\n",
    "                \n",
    "                print(f\"Trial {trial.number}: Combined F1 = {combined_f1:.4f}\")\n",
    "                return combined_f1\n",
    "                \n",
    "            else:\n",
    "                # Single task training - FIXED: Use correct data structure\n",
    "                if self.model_type == \"sentiment\":\n",
    "                    num_classes = model_config.sentiment_num_classes\n",
    "                else:  # emotion\n",
    "                    num_classes = model_config.emotion_num_classes\n",
    "                \n",
    "                # For single-task, data_splits already has the correct structure with 'labels'\n",
    "                trainer = SingleTaskTrainer(config, num_classes)\n",
    "                history = trainer.train(self.data_splits)\n",
    "                \n",
    "                # Return best F1 score\n",
    "                best_f1 = max(history['val_f1_macro'])\n",
    "                print(f\"Trial {trial.number}: F1 = {best_f1:.4f}\")\n",
    "                return best_f1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Trial {trial.number} failed: {e}\")\n",
    "            return 0.0\n",
    "        \n",
    "        finally:\n",
    "            # Clean up\n",
    "            aggressive_memory_cleanup()\n",
    "    \n",
    "    def tune(self):\n",
    "        \"\"\"Run hyperparameter optimization\"\"\"\n",
    "        \n",
    "        # Create study with TPE sampler\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            sampler=TPESampler(seed=42),\n",
    "            pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=3)\n",
    "        )\n",
    "        \n",
    "        print(f\"ðŸ” Starting hyperparameter optimization for {self.model_type}...\")\n",
    "        print(f\"Running {self.n_trials} trials with TPE sampler\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Run optimization\n",
    "        study.optimize(self.objective, n_trials=self.n_trials)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nðŸ† Optimization completed for {self.model_type}!\")\n",
    "        print(f\"Best trial: {study.best_trial.number}\")\n",
    "        print(f\"Best score: {study.best_value:.4f}\")\n",
    "        print(f\"Best parameters:\")\n",
    "        for key, value in study.best_params.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "        return study\n",
    "\n",
    "def train_with_best_params(model_type: str, data_splits: Dict, best_params: Dict, model_name: str = \"microsoft/deberta-base\"):\n",
    "    \"\"\"Train final model with best hyperparameters - FIXED\"\"\"\n",
    "    \n",
    "    print(f\"\\nðŸš€ Training final {model_type} model with best parameters...\")\n",
    "    \n",
    "    # Create config with best parameters\n",
    "    config = TrainingConfig(\n",
    "        model_name=model_name,\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        batch_size=best_params['batch_size'],\n",
    "        num_epochs=best_params['num_epochs'],\n",
    "        warmup_ratio=best_params['warmup_ratio'],\n",
    "        weight_decay=best_params['weight_decay'],\n",
    "        hidden_dropout_prob=best_params['hidden_dropout_prob'],\n",
    "        classifier_dropout=best_params['classifier_dropout'],\n",
    "        max_length=best_params['max_length'],\n",
    "        alpha=best_params.get('alpha', 0.5),\n",
    "        task_type=model_type,\n",
    "        output_dir=f\"./final_{model_type}_model\"\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    if model_type == \"multitask\":\n",
    "        trainer = MultiTaskTrainer(config)\n",
    "        history = trainer.train(data_splits)\n",
    "    else:\n",
    "        # Single-task training - FIXED: Use correct number of classes\n",
    "        if model_type == \"sentiment\":\n",
    "            num_classes = model_config.sentiment_num_classes\n",
    "        else:  # emotion\n",
    "            num_classes = model_config.emotion_num_classes\n",
    "        \n",
    "        trainer = SingleTaskTrainer(config, num_classes)\n",
    "        history = trainer.train(data_splits)\n",
    "    \n",
    "    print(f\"âœ… Final {model_type} model training completed!\")\n",
    "    return trainer, history\n",
    "\n",
    "print(\"âœ… Fixed hyperparameter tuning classes defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e743658a",
   "metadata": {},
   "source": [
    "## Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e975138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Memory cleaned!\n",
      "ðŸš€ STARTING COMPREHENSIVE TRAINING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ Loading and processing datasets...\n",
      "ðŸ“¥ Loading datasets...\n",
      "âœ… SST-2 loaded: 67349 train, 872 val\n",
      "âœ… GoEmotion loaded: 43410 train, 5426 val\n",
      "âœ… Loaded existing encoders from enc/ directory\n",
      "ðŸ”„ Processing sentiment data...\n",
      "âœ… Sentiment data processed:\n",
      "  Train: 7000 samples\n",
      "  Val: 1500 samples\n",
      "  Test: 1500 samples\n",
      "ðŸ”„ Processing emotion data...\n",
      "âœ… Emotion data processed:\n",
      "  Train: 7000 samples\n",
      "  Val: 1500 samples\n",
      "  Test: 1500 samples\n",
      "ðŸ”„ Creating multi-task dataset...\n",
      "âœ… Multi-task data created:\n",
      "  Train: 7000 samples\n",
      "  Val: 1500 samples\n",
      "  Test: 1500 samples\n",
      "\n",
      "================================================================================\n",
      "ðŸ“ PHASE 1: INITIAL TRAINING WITH DEFAULT PARAMETERS\n",
      "================================================================================\n",
      "\n",
      "2ï¸âƒ£ Training Initial Sentiment Model...\n",
      "============================================================\n",
      "ðŸš€ Starting single-task training (sentiment)...\n",
      "\n",
      "ðŸ“ Epoch 1/3\n",
      "  Train Loss: 0.7430, Train Acc: 0.7127\n",
      "  Val Loss: 0.5472, Val Acc: 0.8160, Val F1: 0.5676\n",
      "Single-task model saved to ./initial_sentiment_model\\model_best\n",
      "ðŸ’¾ Best model saved to ./initial_sentiment_model\\model_best\n",
      "\n",
      "ðŸ“ Epoch 2/3\n",
      "  Train Loss: 0.4895, Train Acc: 0.8480\n",
      "  Val Loss: 0.5900, Val Acc: 0.8307, Val F1: 0.5783\n",
      "Single-task model saved to ./initial_sentiment_model\\model_best\n",
      "ðŸ’¾ Best model saved to ./initial_sentiment_model\\model_best\n",
      "\n",
      "ðŸ“ Epoch 3/3\n",
      "  Train Loss: 0.3846, Train Acc: 0.8867\n",
      "  Val Loss: 0.6742, Val Acc: 0.8367, Val F1: 0.5831\n",
      "Single-task model saved to ./initial_sentiment_model\\model_best\n",
      "ðŸ’¾ Best model saved to ./initial_sentiment_model\\model_best\n",
      "\n",
      "âœ… Training completed! Best F1: 0.5831\n",
      "ðŸ“Š Evaluating sentiment model...\n",
      "ðŸ“Š Sentiment Results:\n",
      "  Accuracy: 0.8527\n",
      "  F1 Macro: 0.5944\n",
      "\n",
      "3ï¸âƒ£ Training Initial Emotion Model...\n",
      "============================================================\n",
      "ðŸš€ Starting single-task training (emotion)...\n",
      "\n",
      "ðŸ“ Epoch 1/3\n",
      "  Train Loss: 1.0472, Train Acc: 0.6010\n",
      "  Val Loss: 0.7570, Val Acc: 0.7227, Val F1: 0.6905\n",
      "Single-task model saved to ./initial_emotion_model\\model_best\n",
      "ðŸ’¾ Best model saved to ./initial_emotion_model\\model_best\n",
      "\n",
      "ðŸ“ Epoch 2/3\n",
      "  Train Loss: 0.5799, Train Acc: 0.8007\n",
      "  Val Loss: 0.7801, Val Acc: 0.7540, Val F1: 0.7164\n",
      "Single-task model saved to ./initial_emotion_model\\model_best\n",
      "ðŸ’¾ Best model saved to ./initial_emotion_model\\model_best\n",
      "\n",
      "ðŸ“ Epoch 3/3\n",
      "  Train Loss: 0.3579, Train Acc: 0.8807\n",
      "  Val Loss: 0.9148, Val Acc: 0.7480, Val F1: 0.7184\n",
      "Single-task model saved to ./initial_emotion_model\\model_best\n",
      "ðŸ’¾ Best model saved to ./initial_emotion_model\\model_best\n",
      "\n",
      "âœ… Training completed! Best F1: 0.7184\n",
      "ðŸ“Š Evaluating emotion model...\n",
      "ðŸ“Š Emotion Results:\n",
      "  Accuracy: 0.7793\n",
      "  F1 Macro: 0.7476\n",
      "\n",
      "4ï¸âƒ£ Training Initial Multi-task Model...\n",
      "============================================================\n",
      "ðŸš€ Starting multi-task training...\n",
      "\n",
      "ðŸ“ Epoch 1/3\n",
      "  Train Loss: 1.2387\n",
      "  Train Sentiment Acc: 0.7403, Train Emotion Acc: 0.2553\n",
      "  Val Loss: 1.1413\n",
      "  Val Sentiment Acc: 0.8300, F1: 0.5783\n",
      "  Val Emotion Acc: 0.3020, F1: 0.0773\n",
      "Multi-task model saved to ./initial_multitask_model\\model_best\n",
      "ðŸ’¾ Best model saved to ./initial_multitask_model\\model_best\n",
      "\n",
      "ðŸ“ Epoch 2/3\n",
      "  Train Loss: 1.0683\n",
      "  Train Sentiment Acc: 0.8599, Train Emotion Acc: 0.2804\n",
      "  Val Loss: 1.1260\n",
      "  Val Sentiment Acc: 0.8407, F1: 0.5852\n",
      "  Val Emotion Acc: 0.2987, F1: 0.0828\n",
      "Multi-task model saved to ./initial_multitask_model\\model_best\n",
      "ðŸ’¾ Best model saved to ./initial_multitask_model\\model_best\n",
      "\n",
      "ðŸ“ Epoch 3/3\n",
      "  Train Loss: 0.9790\n",
      "  Train Sentiment Acc: 0.8980, Train Emotion Acc: 0.3150\n",
      "  Val Loss: 1.1563\n",
      "  Val Sentiment Acc: 0.8427, F1: 0.5871\n",
      "  Val Emotion Acc: 0.2500, F1: 0.1246\n",
      "Multi-task model saved to ./initial_multitask_model\\model_best\n",
      "ðŸ’¾ Best model saved to ./initial_multitask_model\\model_best\n",
      "\n",
      "âœ… Training completed! Best Combined F1: 0.3559\n",
      "ðŸ“Š Evaluating multitask model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 04:21:34,288] A new study created in memory with name: no-name-48ee5114-a3b5-4772-8f25-239257e43abc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Multi-task Results:\n",
      "  Sentiment - Accuracy: 0.8513, F1: 0.5932\n",
      "  Emotion - Accuracy: 0.2707, F1: 0.1393\n",
      "  Combined - Accuracy: 0.5610, F1: 0.3663\n",
      "\n",
      "5ï¸âƒ£ Initial Results Summary...\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š INITIAL MODELS RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "ðŸŽ¯ INITIAL SENTIMENT MODEL:\n",
      "  Accuracy: 0.8527\n",
      "  F1 Macro: 0.5944\n",
      "\n",
      "ðŸ˜Š INITIAL EMOTION MODEL:\n",
      "  Accuracy: 0.7793\n",
      "  F1 Macro: 0.7476\n",
      "\n",
      "ðŸ”— INITIAL MULTI-TASK MODEL:\n",
      "  Sentiment - Accuracy: 0.8513, F1: 0.5932\n",
      "  Emotion - Accuracy: 0.2707, F1: 0.1393\n",
      "  Combined - Accuracy: 0.5610, F1: 0.3663\n",
      "\n",
      "ðŸ’¡ These are baseline results. Hyperparameter tuning will aim to improve them!\n",
      "\n",
      "================================================================================\n",
      "ðŸ“ PHASE 2: HYPERPARAMETER TUNING\n",
      "================================================================================\n",
      "\n",
      "6ï¸âƒ£ Hyperparameter Tuning for Sentiment Model...\n",
      "============================================================\n",
      "ðŸ” Hyperparameter tuner initialized for sentiment\n",
      "ðŸ” Starting hyperparameter optimization for sentiment...\n",
      "Running 15 trials with TPE sampler\n",
      "============================================================\n",
      "ðŸ§¹ Memory cleaned!\n",
      "ðŸš€ Starting single-task training (sentiment)...\n",
      "\n",
      "ðŸ“ Epoch 1/3\n",
      "  Train Loss: 0.9503, Train Acc: 0.6637\n",
      "  Val Loss: 1.1544, Val Acc: 0.7660, Val F1: 0.5312\n",
      "Single-task model saved to ./temp_trial_0\\model_best\n",
      "ðŸ’¾ Best model saved to ./temp_trial_0\\model_best\n",
      "\n",
      "ðŸ“ Epoch 2/3\n",
      "  Train Loss: 0.7625, Train Acc: 0.8063\n",
      "  Val Loss: 0.9300, Val Acc: 0.8067, Val F1: 0.5613\n",
      "Single-task model saved to ./temp_trial_0\\model_best\n",
      "ðŸ’¾ Best model saved to ./temp_trial_0\\model_best\n",
      "\n",
      "ðŸ“ Epoch 3/3\n",
      "  Train Loss: 0.6397, Train Acc: 0.8541\n",
      "  Val Loss: 0.9862, Val Acc: 0.8247, Val F1: 0.5746\n",
      "Single-task model saved to ./temp_trial_0\\model_best\n",
      "ðŸ’¾ Best model saved to ./temp_trial_0\\model_best\n",
      "\n",
      "âœ… Training completed! Best F1: 0.5746\n",
      "Trial 0: F1 = 0.5746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 10:07:03,469] Trial 0 finished with value: 0.5746436475629334 and parameters: {'learning_rate': 4.3284502212938785e-05, 'batch_size': 4, 'num_epochs': 3, 'warmup_ratio': 0.0733991780504304, 'weight_decay': 0.006750277604651747, 'hidden_dropout_prob': 0.273235229154987, 'classifier_dropout': 0.22022300234864176, 'max_length': 128}. Best is trial 0 with value: 0.5746436475629334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Memory cleaned!\n",
      "ðŸ§¹ Memory cleaned!\n",
      "ðŸš€ Starting single-task training (sentiment)...\n",
      "\n",
      "ðŸ“ Epoch 1/4\n",
      "  Train Loss: 1.0050, Train Acc: 0.4560\n",
      "  Val Loss: 0.9435, Val Acc: 0.4700, Val F1: 0.2132\n",
      "Single-task model saved to ./temp_trial_1\\model_best\n",
      "ðŸ’¾ Best model saved to ./temp_trial_1\\model_best\n",
      "\n",
      "ðŸ“ Epoch 2/4\n",
      "  Train Loss: 0.9448, Train Acc: 0.4554\n",
      "  Val Loss: 0.9333, Val Acc: 0.4700, Val F1: 0.2132\n",
      "\n",
      "ðŸ“ Epoch 3/4\n",
      "  Train Loss: 0.9374, Train Acc: 0.4659\n",
      "  Val Loss: 0.9306, Val Acc: 0.4700, Val F1: 0.2132\n",
      "\n",
      "ðŸ“ Epoch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:07:33,793] Trial 1 finished with value: 0.21315192743764175 and parameters: {'learning_rate': 0.00044447541666908124, 'batch_size': 4, 'num_epochs': 4, 'warmup_ratio': 0.09563633644393066, 'weight_decay': 0.05295088673159155, 'hidden_dropout_prob': 0.18638900372842315, 'classifier_dropout': 0.15824582803960838, 'max_length': 128}. Best is trial 0 with value: 0.5746436475629334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.9334, Train Acc: 0.4646\n",
      "  Val Loss: 0.9324, Val Acc: 0.4700, Val F1: 0.2132\n",
      "\n",
      "âœ… Training completed! Best F1: 0.2132\n",
      "Trial 1: F1 = 0.2132\n",
      "ðŸ§¹ Memory cleaned!\n",
      "ðŸ§¹ Memory cleaned!\n",
      "ðŸš€ Starting single-task training (sentiment)...\n",
      "\n",
      "ðŸ“ Epoch 1/4\n",
      "  Train Loss: 0.8251, Train Acc: 0.6406\n",
      "  Val Loss: 0.5502, Val Acc: 0.8060, Val F1: 0.5621\n",
      "Single-task model saved to ./temp_trial_2\\model_best\n",
      "ðŸ’¾ Best model saved to ./temp_trial_2\\model_best\n",
      "\n",
      "ðŸ“ Epoch 2/4\n",
      "  Train Loss: 0.5272, Train Acc: 0.8263\n",
      "  Val Loss: 0.5613, Val Acc: 0.8200, Val F1: 0.5708\n",
      "Single-task model saved to ./temp_trial_2\\model_best\n",
      "ðŸ’¾ Best model saved to ./temp_trial_2\\model_best\n",
      "\n",
      "ðŸ“ Epoch 3/4\n",
      "  Train Loss: 0.3951, Train Acc: 0.8747\n",
      "  Val Loss: 0.6022, Val Acc: 0.8353, Val F1: 0.5817\n",
      "Single-task model saved to ./temp_trial_2\\model_best\n",
      "ðŸ’¾ Best model saved to ./temp_trial_2\\model_best\n",
      "\n",
      "ðŸ“ Epoch 4/4\n"
     ]
    }
   ],
   "source": [
    "# Clear memory before starting\n",
    "aggressive_memory_cleanup()\n",
    "\n",
    "# Run the complete pipeline\n",
    "results = main_training_pipeline()\n",
    "\n",
    "print(f\"\\nðŸŽ‰ ALL TRAINING COMPLETED!\")\n",
    "print(f\"ðŸ“Š Check comprehensive_results_summary.json for detailed comparison\")\n",
    "print(f\"ðŸ“ Initial models in: ./initial_*_model/\")\n",
    "print(f\"ðŸ“ Optimized models in: ./final_*_model/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
