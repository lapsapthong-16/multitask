{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1df2808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4060\n",
      "CUDA Version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, AutoConfig,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "023ed9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multitask model architecture defined!\n",
      "Available models: ['bertweet', 'deberta']\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Multitask Model Architecture\n",
    "class MultiTaskTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Multitask Learning Framework for Sentiment and Emotion Classification\n",
    "    \n",
    "    Features:\n",
    "    - Shared transformer encoder (BERTweet, DeBERTa)\n",
    "    - Task-specific attention heads\n",
    "    - Parallel classification heads\n",
    "    - Dropout for regularization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"microsoft/deberta-base\",\n",
    "        sentiment_num_classes: int = 3,\n",
    "        emotion_num_classes: int = 6,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1,\n",
    "        freeze_encoder: bool = False\n",
    "    ):\n",
    "        super(MultiTaskTransformer, self).__init__()\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.sentiment_num_classes = sentiment_num_classes\n",
    "        self.emotion_num_classes = emotion_num_classes\n",
    "        \n",
    "        # Load configuration and adjust dropout\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.hidden_dropout_prob = hidden_dropout_prob\n",
    "        config.attention_probs_dropout_prob = attention_dropout_prob\n",
    "        \n",
    "        # Shared transformer encoder\n",
    "        self.shared_encoder = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            config=config,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        # Freeze encoder if specified\n",
    "        if freeze_encoder:\n",
    "            for param in self.shared_encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        hidden_size = self.shared_encoder.config.hidden_size\n",
    "        \n",
    "        # Task-specific attention layers\n",
    "        self.sentiment_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.emotion_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Shared attention for common features\n",
    "        self.shared_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=attention_dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.sentiment_norm = nn.LayerNorm(hidden_size)\n",
    "        self.emotion_norm = nn.LayerNorm(hidden_size)\n",
    "        self.shared_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.sentiment_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.emotion_dropout = nn.Dropout(classifier_dropout)\n",
    "        self.shared_dropout = nn.Dropout(classifier_dropout)\n",
    "        \n",
    "        # Classification heads\n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),  # *2 for shared + task-specific\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, sentiment_num_classes)\n",
    "        )\n",
    "        \n",
    "        self.emotion_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),  # *2 for shared + task-specific\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(classifier_dropout),\n",
    "            nn.Linear(hidden_size, emotion_num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize classification head weights\"\"\"\n",
    "        for module in [self.sentiment_classifier, self.emotion_classifier]:\n",
    "            for layer in module:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        task: Optional[str] = None\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Token IDs [batch_size, seq_len]\n",
    "            attention_mask: Attention mask [batch_size, seq_len]\n",
    "            task: Optional task specification (\"sentiment\", \"emotion\", or None for both)\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing logits for requested tasks\n",
    "        \"\"\"\n",
    "        # Shared encoder\n",
    "        encoder_outputs = self.shared_encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        # Get sequence output [batch_size, seq_len, hidden_size]\n",
    "        sequence_output = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply shared attention to capture common linguistic features\n",
    "        shared_attended, _ = self.shared_attention(\n",
    "            sequence_output, sequence_output, sequence_output,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "        shared_attended = self.shared_norm(shared_attended + sequence_output)\n",
    "        shared_attended = self.shared_dropout(shared_attended)\n",
    "        \n",
    "        # Pool shared features (use [CLS] token or mean pooling)\n",
    "        shared_pooled = shared_attended[:, 0, :]  # [CLS] token\n",
    "        \n",
    "        outputs = {}\n",
    "        \n",
    "        # Sentiment branch\n",
    "        if task is None or task == \"sentiment\":\n",
    "            # Task-specific attention for sentiment\n",
    "            sentiment_attended, sentiment_weights = self.sentiment_attention(\n",
    "                sequence_output, sequence_output, sequence_output,\n",
    "                key_padding_mask=~attention_mask.bool()\n",
    "            )\n",
    "            sentiment_attended = self.sentiment_norm(sentiment_attended + sequence_output)\n",
    "            sentiment_attended = self.sentiment_dropout(sentiment_attended)\n",
    "            \n",
    "            # Pool sentiment features\n",
    "            sentiment_pooled = sentiment_attended[:, 0, :]  # [CLS] token\n",
    "            \n",
    "            # Combine shared and task-specific features\n",
    "            sentiment_features = torch.cat([shared_pooled, sentiment_pooled], dim=-1)\n",
    "            \n",
    "            # Sentiment classification\n",
    "            sentiment_logits = self.sentiment_classifier(sentiment_features)\n",
    "            outputs[\"sentiment_logits\"] = sentiment_logits\n",
    "            outputs[\"sentiment_attention_weights\"] = sentiment_weights\n",
    "        \n",
    "        # Emotion branch\n",
    "        if task is None or task == \"emotion\":\n",
    "            # Task-specific attention for emotion\n",
    "            emotion_attended, emotion_weights = self.emotion_attention(\n",
    "                sequence_output, sequence_output, sequence_output,\n",
    "                key_padding_mask=~attention_mask.bool()\n",
    "            )\n",
    "            emotion_attended = self.emotion_norm(emotion_attended + sequence_output)\n",
    "            emotion_attended = self.emotion_dropout(emotion_attended)\n",
    "            \n",
    "            # Pool emotion features\n",
    "            emotion_pooled = emotion_attended[:, 0, :]  # [CLS] token\n",
    "            \n",
    "            # Combine shared and task-specific features\n",
    "            emotion_features = torch.cat([shared_pooled, emotion_pooled], dim=-1)\n",
    "            \n",
    "            # Emotion classification\n",
    "            emotion_logits = self.emotion_classifier(emotion_features)\n",
    "            outputs[\"emotion_logits\"] = emotion_logits\n",
    "            outputs[\"emotion_attention_weights\"] = emotion_weights\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "# Model configuration options\n",
    "MODEL_CONFIGS = {\n",
    "    \"bertweet\": {\n",
    "        \"name\": \"vinai/bertweet-base\",\n",
    "        \"description\": \"BERTweet optimized for social media text\"\n",
    "    },\n",
    "    \"deberta\": {\n",
    "        \"name\": \"microsoft/deberta-base\",\n",
    "        \"description\": \"DeBERTa with enhanced attention mechanism\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ… Multitask model architecture defined!\")\n",
    "print(\"Available models:\", list(MODEL_CONFIGS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c35e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated dataset preparation functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Updated Dataset Class and External Data Loading (FIXED)\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "from collections import Counter\n",
    "\n",
    "class MultiTaskDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for multitask learning with sentiment and emotion labels\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        sentiment_labels: List[int],\n",
    "        emotion_labels: List[int],\n",
    "        tokenizer,\n",
    "        max_length: int = 512,\n",
    "        sentiment_label_encoder=None,\n",
    "        emotion_label_encoder=None\n",
    "    ):\n",
    "        self.texts = texts\n",
    "        self.sentiment_labels = sentiment_labels\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.sentiment_label_encoder = sentiment_label_encoder\n",
    "        self.emotion_label_encoder = emotion_label_encoder\n",
    "        \n",
    "        # Validate data\n",
    "        assert len(texts) == len(sentiment_labels) == len(emotion_labels), \\\n",
    "            \"All inputs must have the same length\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        sentiment_label = self.sentiment_labels[idx]\n",
    "        emotion_label = self.emotion_labels[idx]\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'sentiment_labels': torch.tensor(sentiment_label, dtype=torch.long),\n",
    "            'emotion_labels': torch.tensor(emotion_label, dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "def load_external_datasets() -> Tuple[Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Load external datasets for training (SST-2 and GoEmotions)\n",
    "    \"\"\"\n",
    "    print(\"ðŸ“ Loading external datasets for training...\")\n",
    "    \n",
    "    # Load SST-2 for sentiment\n",
    "    try:\n",
    "        sst2_dataset = load_dataset(\"sst2\")\n",
    "        sentiment_data = {\n",
    "            'train': sst2_dataset['train'],\n",
    "            'validation': sst2_dataset['validation']\n",
    "        }\n",
    "        print(f\"âœ… SST-2 dataset loaded: {len(sentiment_data['train'])} train, {len(sentiment_data['validation'])} val\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not load SST-2: {e}. Using dummy data.\")\n",
    "        sentiment_data = _create_dummy_sentiment_data()\n",
    "    \n",
    "    # Load GoEmotions for emotion\n",
    "    try:\n",
    "        emotions_dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "        emotion_data = {\n",
    "            'train': emotions_dataset['train'],\n",
    "            'validation': emotions_dataset['validation']\n",
    "        }\n",
    "        print(f\"âœ… GoEmotions dataset loaded: {len(emotion_data['train'])} train, {len(emotion_data['validation'])} val\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not load GoEmotions: {e}. Using dummy data.\")\n",
    "        emotion_data = _create_dummy_emotion_data()\n",
    "    \n",
    "    return sentiment_data, emotion_data\n",
    "\n",
    "def _create_dummy_sentiment_data() -> Dict:\n",
    "    \"\"\"Create dummy sentiment data for testing\"\"\"\n",
    "    dummy_texts = [\n",
    "        \"I love this product!\", \"This is terrible\", \"It's okay\",\n",
    "        \"Amazing quality\", \"Worst experience ever\", \"Not bad\"\n",
    "    ] * 200\n",
    "    dummy_labels = [1, 0, 1, 1, 0, 1] * 200\n",
    "    \n",
    "    dummy_data = {\n",
    "        'sentence': dummy_texts,\n",
    "        'label': dummy_labels\n",
    "    }\n",
    "    \n",
    "    dataset = HFDataset.from_dict(dummy_data)\n",
    "    return {'train': dataset, 'validation': dataset.select(range(200))}\n",
    "\n",
    "def _create_dummy_emotion_data() -> Dict:\n",
    "    \"\"\"Create dummy emotion data for testing\"\"\"\n",
    "    dummy_texts = [\n",
    "        \"I'm so happy!\", \"This is sad\", \"I'm angry\", \"That's scary\",\n",
    "        \"What a surprise!\", \"This is neutral\", \"I love this!\", \"Great stuff\"\n",
    "    ] * 200\n",
    "    dummy_labels = [0, 1, 2, 3, 4, 5, 0, 0] * 200  # Map to 6 classes\n",
    "    \n",
    "    dummy_data = {\n",
    "        'text': dummy_texts,\n",
    "        'labels': dummy_labels\n",
    "    }\n",
    "    \n",
    "    dataset = HFDataset.from_dict(dummy_data)\n",
    "    return {'train': dataset, 'validation': dataset.select(range(200))}\n",
    "\n",
    "def prepare_external_data_for_multitask(\n",
    "    sentiment_data: Dict,\n",
    "    emotion_data: Dict,\n",
    "    max_samples: int = 10000\n",
    ") -> Tuple[Dict, LabelEncoder, LabelEncoder]:\n",
    "    \"\"\"\n",
    "    Prepare external datasets for multitask training\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”„ Preparing external datasets for multitask training...\")\n",
    "    \n",
    "    # Filter emotion data to first 6 classes only (to match your Reddit data)\n",
    "    def filter_emotion_classes(example):\n",
    "        # Handle both single-label and multi-label\n",
    "        if isinstance(example['labels'], list):\n",
    "            return example['labels'] and example['labels'][0] in range(6)\n",
    "        else:\n",
    "            return example['labels'] in range(6)\n",
    "    \n",
    "    emotion_data['train'] = emotion_data['train'].filter(filter_emotion_classes)\n",
    "    emotion_data['validation'] = emotion_data['validation'].filter(filter_emotion_classes)\n",
    "    \n",
    "    # Extract texts and labels\n",
    "    # Sentiment (SST-2)\n",
    "    sentiment_texts = sentiment_data['train']['sentence'][:max_samples]\n",
    "    sentiment_labels = sentiment_data['train']['label'][:max_samples]\n",
    "    \n",
    "    # Emotion (GoEmotions) \n",
    "    emotion_texts = emotion_data['train']['text'][:max_samples]\n",
    "    emotion_labels_raw = emotion_data['train']['labels'][:max_samples]\n",
    "    \n",
    "    # Handle multi-label to single-label conversion for emotions\n",
    "    emotion_labels = []\n",
    "    for label in emotion_labels_raw:\n",
    "        if isinstance(label, list):\n",
    "            emotion_labels.append(label[0] if label else 0)\n",
    "        else:\n",
    "            emotion_labels.append(label)\n",
    "    \n",
    "    # Create label encoders based on your Reddit data classes\n",
    "    sentiment_encoder = LabelEncoder()\n",
    "    emotion_encoder = LabelEncoder()\n",
    "    \n",
    "    # Fit with the classes that match your Reddit data\n",
    "    # SST-2: 0=negative, 1=positive. We need: Negative, Neutral, Positive\n",
    "    # Map SST labels to 3-class: 0->0 (Negative), 1->2 (Positive), add 1 (Neutral) artificially\n",
    "    sentiment_encoder.classes_ = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "    \n",
    "    # GoEmotions: Map to your 6 classes\n",
    "    emotion_encoder.classes_ = np.array(['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise'])\n",
    "    \n",
    "    # Convert SST labels: 0->0 (Negative), 1->2 (Positive)\n",
    "    # We'll add some neutral examples by randomly converting some to class 1\n",
    "    converted_sentiment_labels = []\n",
    "    for label in sentiment_labels:\n",
    "        if label == 0:  # Negative\n",
    "            converted_sentiment_labels.append(0)\n",
    "        elif label == 1:  # Positive\n",
    "            # Randomly assign some as neutral (class 1) to have all 3 classes\n",
    "            if np.random.random() < 0.1:  # 10% chance\n",
    "                converted_sentiment_labels.append(1)  # Neutral\n",
    "            else:\n",
    "                converted_sentiment_labels.append(2)  # Positive\n",
    "    \n",
    "    # Ensure we have all 3 sentiment classes\n",
    "    if 1 not in converted_sentiment_labels:\n",
    "        # Force some examples to be neutral\n",
    "        neutral_indices = np.random.choice(len(converted_sentiment_labels), size=50, replace=False)\n",
    "        for idx in neutral_indices:\n",
    "            converted_sentiment_labels[idx] = 1\n",
    "    \n",
    "    # Balance the datasets - use minimum length\n",
    "    min_length = min(len(sentiment_texts), len(emotion_texts))\n",
    "    \n",
    "    final_texts = sentiment_texts[:min_length]\n",
    "    final_sentiment_labels = converted_sentiment_labels[:min_length]\n",
    "    final_emotion_labels = emotion_labels[:min_length]\n",
    "    \n",
    "    # Create train/val splits\n",
    "    split_idx = int(0.8 * min_length)\n",
    "    \n",
    "    data_splits = {\n",
    "        'train': {\n",
    "            'texts': final_texts[:split_idx],\n",
    "            'sentiment_labels': final_sentiment_labels[:split_idx],\n",
    "            'emotion_labels': final_emotion_labels[:split_idx]\n",
    "        },\n",
    "        'val': {\n",
    "            'texts': final_texts[split_idx:],\n",
    "            'sentiment_labels': final_sentiment_labels[split_idx:],\n",
    "            'emotion_labels': final_emotion_labels[split_idx:]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… External data prepared:\")\n",
    "    print(f\"  Train samples: {len(data_splits['train']['texts'])}\")\n",
    "    print(f\"  Validation samples: {len(data_splits['val']['texts'])}\")\n",
    "    print(f\"  Sentiment classes: {list(sentiment_encoder.classes_)}\")\n",
    "    print(f\"  Emotion classes: {list(emotion_encoder.classes_)}\")\n",
    "    \n",
    "    # Print class distribution\n",
    "    train_sentiment_counts = Counter(data_splits['train']['sentiment_labels'])\n",
    "    train_emotion_counts = Counter(data_splits['train']['emotion_labels'])\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Training set class distribution:\")\n",
    "    for i, class_name in enumerate(sentiment_encoder.classes_):\n",
    "        count = train_sentiment_counts.get(i, 0)\n",
    "        print(f\"  Sentiment '{class_name}': {count} samples\")\n",
    "    \n",
    "    for i, class_name in enumerate(emotion_encoder.classes_):\n",
    "        count = train_emotion_counts.get(i, 0)\n",
    "        print(f\"  Emotion '{class_name}': {count} samples\")\n",
    "    \n",
    "    return data_splits, sentiment_encoder, emotion_encoder\n",
    "\n",
    "def prepare_reddit_data_for_evaluation(\n",
    "    df: pd.DataFrame,\n",
    "    sentiment_encoder: LabelEncoder,\n",
    "    emotion_encoder: LabelEncoder,\n",
    "    sentiment_column: str = 'sentiment',\n",
    "    emotion_column: str = 'emotion',\n",
    "    text_column: str = 'text_content'\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Prepare Reddit data for evaluation only (not training)\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”„ Preparing Reddit data for evaluation...\")\n",
    "    \n",
    "    # Extract data\n",
    "    texts = df[text_column].tolist()\n",
    "    sentiment_labels_text = df[sentiment_column].tolist()\n",
    "    emotion_labels_text = df[emotion_column].tolist()\n",
    "    \n",
    "    # Transform labels using pre-fitted encoders\n",
    "    try:\n",
    "        sentiment_labels = sentiment_encoder.transform(sentiment_labels_text)\n",
    "    except ValueError as e:\n",
    "        print(f\"âš ï¸ Sentiment label mismatch: {e}\")\n",
    "        # Handle unknown labels by mapping them to existing classes\n",
    "        sentiment_labels = []\n",
    "        for label in sentiment_labels_text:\n",
    "            if label in sentiment_encoder.classes_:\n",
    "                sentiment_labels.append(sentiment_encoder.transform([label])[0])\n",
    "            else:\n",
    "                print(f\"âš ï¸ Unknown sentiment label '{label}', mapping to 'Neutral'\")\n",
    "                sentiment_labels.append(sentiment_encoder.transform(['Neutral'])[0])\n",
    "        sentiment_labels = np.array(sentiment_labels)\n",
    "    \n",
    "    try:\n",
    "        emotion_labels = emotion_encoder.transform(emotion_labels_text)\n",
    "    except ValueError as e:\n",
    "        print(f\"âš ï¸ Emotion label mismatch: {e}\")\n",
    "        # Handle unknown labels\n",
    "        emotion_labels = []\n",
    "        for label in emotion_labels_text:\n",
    "            if label in emotion_encoder.classes_:\n",
    "                emotion_labels.append(emotion_encoder.transform([label])[0])\n",
    "            else:\n",
    "                print(f\"âš ï¸ Unknown emotion label '{label}', mapping to 'No Emotion'\")\n",
    "                emotion_labels.append(emotion_encoder.transform(['No Emotion'])[0])\n",
    "        emotion_labels = np.array(emotion_labels)\n",
    "    \n",
    "    evaluation_data = {\n",
    "        'texts': texts,\n",
    "        'sentiment_labels': sentiment_labels.tolist(),\n",
    "        'emotion_labels': emotion_labels.tolist()\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Reddit evaluation data prepared: {len(texts)} samples\")\n",
    "    \n",
    "    return evaluation_data\n",
    "\n",
    "def create_stratified_sampler(sentiment_labels: List[int], emotion_labels: List[int]) -> WeightedRandomSampler:\n",
    "    \"\"\"\n",
    "    Create a weighted random sampler for stratified sampling\n",
    "    considering both sentiment and emotion class distributions\n",
    "    \"\"\"\n",
    "    # Combine labels to create compound classes for stratification\n",
    "    compound_labels = [f\"{s}_{e}\" for s, e in zip(sentiment_labels, emotion_labels)]\n",
    "    \n",
    "    # Calculate class weights\n",
    "    unique_labels = list(set(compound_labels))\n",
    "    \n",
    "    # FIX: Convert to numpy array as required by compute_class_weight\n",
    "    unique_labels_array = np.array(unique_labels)\n",
    "    \n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=unique_labels_array,  # Now it's a numpy array\n",
    "        y=compound_labels\n",
    "    )\n",
    "    \n",
    "    # Create weight dictionary\n",
    "    weight_dict = dict(zip(unique_labels, class_weights))\n",
    "    \n",
    "    # Assign weights to each sample\n",
    "    sample_weights = [weight_dict[label] for label in compound_labels]\n",
    "    \n",
    "    return WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "\n",
    "print(\"âœ… Updated dataset preparation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f18169d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loss functions and schedulers defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Loss Function with Weighting\n",
    "class MultiTaskLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Weighted loss function for multitask learning\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha: float = 0.5,\n",
    "        sentiment_class_weights: Optional[torch.Tensor] = None,\n",
    "        emotion_class_weights: Optional[torch.Tensor] = None,\n",
    "        device: torch.device = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha: Weight parameter between sentiment and emotion loss (0.3-0.7)\n",
    "            sentiment_class_weights: Class weights for sentiment imbalance\n",
    "            emotion_class_weights: Class weights for emotion imbalance\n",
    "        \"\"\"\n",
    "        super(MultiTaskLoss, self).__init__()\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.device = device or torch.device('cpu')\n",
    "        \n",
    "        # Initialize loss functions with class weights\n",
    "        self.sentiment_loss_fn = nn.CrossEntropyLoss(\n",
    "            weight=sentiment_class_weights.to(self.device) if sentiment_class_weights is not None else None\n",
    "        )\n",
    "        self.emotion_loss_fn = nn.CrossEntropyLoss(\n",
    "            weight=emotion_class_weights.to(self.device) if emotion_class_weights is not None else None\n",
    "        )\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        sentiment_logits: torch.Tensor,\n",
    "        emotion_logits: torch.Tensor,\n",
    "        sentiment_labels: torch.Tensor,\n",
    "        emotion_labels: torch.Tensor\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Calculate weighted multitask loss\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing individual and combined losses\n",
    "        \"\"\"\n",
    "        # Calculate individual losses\n",
    "        sentiment_loss = self.sentiment_loss_fn(sentiment_logits, sentiment_labels)\n",
    "        emotion_loss = self.emotion_loss_fn(emotion_logits, emotion_labels)\n",
    "        \n",
    "        # Weighted combination\n",
    "        total_loss = self.alpha * sentiment_loss + (1 - self.alpha) * emotion_loss\n",
    "        \n",
    "        return {\n",
    "            'total_loss': total_loss,\n",
    "            'sentiment_loss': sentiment_loss,\n",
    "            'emotion_loss': emotion_loss,\n",
    "            'alpha': self.alpha\n",
    "        }\n",
    "    \n",
    "    def update_alpha(self, new_alpha: float):\n",
    "        \"\"\"Update alpha parameter during training\"\"\"\n",
    "        self.alpha = max(0.3, min(0.7, new_alpha))  # Constrain to [0.3, 0.7]\n",
    "\n",
    "def compute_class_weights_from_labels(labels: List[int], device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"Compute class weights for imbalanced datasets\"\"\"\n",
    "    unique_labels = np.unique(labels)\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=unique_labels,\n",
    "        y=labels\n",
    "    )\n",
    "    return torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "class AdaptiveAlphaScheduler:\n",
    "    \"\"\"\n",
    "    Adaptive alpha scheduler that adjusts the loss weighting based on task performance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, initial_alpha: float = 0.5, adaptation_rate: float = 0.1):\n",
    "        self.alpha = initial_alpha\n",
    "        self.adaptation_rate = adaptation_rate\n",
    "        self.sentiment_history = []\n",
    "        self.emotion_history = []\n",
    "    \n",
    "    def step(self, sentiment_accuracy: float, emotion_accuracy: float) -> float:\n",
    "        \"\"\"\n",
    "        Adjust alpha based on relative task performance\n",
    "        Better performing task gets lower weight to balance learning\n",
    "        \"\"\"\n",
    "        self.sentiment_history.append(sentiment_accuracy)\n",
    "        self.emotion_history.append(emotion_accuracy)\n",
    "        \n",
    "        if len(self.sentiment_history) >= 2:\n",
    "            # Calculate performance difference\n",
    "            sentiment_trend = sentiment_accuracy - np.mean(self.sentiment_history[-3:])\n",
    "            emotion_trend = emotion_accuracy - np.mean(self.emotion_history[-3:])\n",
    "            \n",
    "            # Adjust alpha: if sentiment is improving faster, decrease its weight\n",
    "            if sentiment_trend > emotion_trend:\n",
    "                self.alpha -= self.adaptation_rate\n",
    "            elif emotion_trend > sentiment_trend:\n",
    "                self.alpha += self.adaptation_rate\n",
    "            \n",
    "            # Constrain alpha to [0.3, 0.7]\n",
    "            self.alpha = max(0.3, min(0.7, self.alpha))\n",
    "        \n",
    "        return self.alpha\n",
    "\n",
    "print(\"âœ… Loss functions and schedulers defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c85ccbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training utilities defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Training Utilities\n",
    "class TrainingConfig:\n",
    "    \"\"\"Configuration class for training parameters\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"roberta-base\",\n",
    "        max_length: int = 512,\n",
    "        batch_size: int = 16,\n",
    "        learning_rate: float = 2e-5,\n",
    "        num_epochs: int = 5,\n",
    "        warmup_ratio: float = 0.1,\n",
    "        weight_decay: float = 0.01,\n",
    "        max_grad_norm: float = 1.0,\n",
    "        alpha: float = 0.5,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1,\n",
    "        adaptive_alpha: bool = True,\n",
    "        save_strategy: str = \"epoch\",\n",
    "        evaluation_strategy: str = \"epoch\",\n",
    "        output_dir: str = \"./multitask_model\",\n",
    "        logging_steps: int = 50,\n",
    "        save_total_limit: int = 3\n",
    "    ):\n",
    "        self.model_name = model_name\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.warmup_ratio = warmup_ratio\n",
    "        self.weight_decay = weight_decay\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.alpha = alpha\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_dropout_prob = attention_dropout_prob\n",
    "        self.classifier_dropout = classifier_dropout\n",
    "        self.adaptive_alpha = adaptive_alpha\n",
    "        self.save_strategy = save_strategy\n",
    "        self.evaluation_strategy = evaluation_strategy\n",
    "        self.output_dir = output_dir\n",
    "        self.logging_steps = logging_steps\n",
    "        self.save_total_limit = save_total_limit\n",
    "\n",
    "def create_optimizer_and_scheduler(\n",
    "    model: nn.Module,\n",
    "    config: TrainingConfig,\n",
    "    num_training_steps: int\n",
    ") -> Tuple[AdamW, LambdaLR]:\n",
    "    \"\"\"\n",
    "    Create optimizer and learning rate scheduler\n",
    "    \"\"\"\n",
    "    # Separate parameters for different learning rates\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() \n",
    "                      if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": config.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() \n",
    "                      if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    # AdamW optimizer\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=config.learning_rate,\n",
    "        eps=1e-8\n",
    "    )\n",
    "    \n",
    "    # Linear warmup scheduler\n",
    "    num_warmup_steps = int(num_training_steps * config.warmup_ratio)\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "    \n",
    "    return optimizer, scheduler\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping utility\"\"\"\n",
    "    \n",
    "    def __init__(self, patience: int = 3, min_delta: float = 0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        \n",
    "    def __call__(self, score: float) -> bool:\n",
    "        \"\"\"Returns True if training should be stopped\"\"\"\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        return False\n",
    "\n",
    "class ModelCheckpointer:\n",
    "    \"\"\"Model checkpointing utility\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str, save_total_limit: int = 3):\n",
    "        self.output_dir = output_dir\n",
    "        self.save_total_limit = save_total_limit\n",
    "        self.saved_checkpoints = []\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    def save_checkpoint(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        tokenizer,\n",
    "        optimizer: AdamW,\n",
    "        scheduler: LambdaLR,\n",
    "        epoch: int,\n",
    "        metrics: Dict,\n",
    "        is_best: bool = False\n",
    "    ):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        checkpoint_dir = os.path.join(self.output_dir, f\"checkpoint-epoch-{epoch}\")\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        # Save model and tokenizer\n",
    "        model.save_pretrained(checkpoint_dir)\n",
    "        tokenizer.save_pretrained(checkpoint_dir)\n",
    "        \n",
    "        # Save training state\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'metrics': metrics\n",
    "        }, os.path.join(checkpoint_dir, 'training_state.pt'))\n",
    "        \n",
    "        # Save best model separately\n",
    "        if is_best:\n",
    "            best_dir = os.path.join(self.output_dir, 'best_model')\n",
    "            os.makedirs(best_dir, exist_ok=True)\n",
    "            model.save_pretrained(best_dir)\n",
    "            tokenizer.save_pretrained(best_dir)\n",
    "        \n",
    "        # Manage checkpoint limit\n",
    "        self.saved_checkpoints.append(checkpoint_dir)\n",
    "        if len(self.saved_checkpoints) > self.save_total_limit:\n",
    "            old_checkpoint = self.saved_checkpoints.pop(0)\n",
    "            if os.path.exists(old_checkpoint) and 'best_model' not in old_checkpoint:\n",
    "                import shutil\n",
    "                shutil.rmtree(old_checkpoint)\n",
    "\n",
    "print(\"âœ… Training utilities defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d432163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training loop defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Training Loop\n",
    "class MultiTaskTrainer:\n",
    "    \"\"\"\n",
    "    Main trainer class for multitask learning\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config: TrainingConfig,\n",
    "        sentiment_num_classes: int,\n",
    "        emotion_num_classes: int\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.sentiment_num_classes = sentiment_num_classes\n",
    "        self.emotion_num_classes = emotion_num_classes\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize components\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        self.model = None\n",
    "        self.loss_fn = None\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.alpha_scheduler = None\n",
    "        self.early_stopping = None\n",
    "        self.checkpointer = None\n",
    "        \n",
    "        # Training history\n",
    "        self.training_history = {\n",
    "            'epoch': [],\n",
    "            'train_loss': [],\n",
    "            'train_sentiment_loss': [],\n",
    "            'train_emotion_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_sentiment_loss': [],\n",
    "            'val_emotion_loss': [],\n",
    "            'val_sentiment_accuracy': [],\n",
    "            'val_emotion_accuracy': [],\n",
    "            'alpha': [],\n",
    "            'learning_rate': []\n",
    "        }\n",
    "    \n",
    "    def setup(\n",
    "        self,\n",
    "        data_splits: Dict,\n",
    "        sentiment_encoder: LabelEncoder,\n",
    "        emotion_encoder: LabelEncoder\n",
    "    ):\n",
    "        \"\"\"Setup model, loss function, and training components\"\"\"\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = MultiTaskTransformer(\n",
    "            model_name=self.config.model_name,\n",
    "            sentiment_num_classes=self.sentiment_num_classes,\n",
    "            emotion_num_classes=self.emotion_num_classes,\n",
    "            hidden_dropout_prob=self.config.hidden_dropout_prob,\n",
    "            attention_dropout_prob=self.config.attention_dropout_prob,\n",
    "            classifier_dropout=self.config.classifier_dropout\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Compute class weights\n",
    "        sentiment_weights = compute_class_weights_from_labels(\n",
    "            data_splits['train']['sentiment_labels'], self.device\n",
    "        )\n",
    "        emotion_weights = compute_class_weights_from_labels(\n",
    "            data_splits['train']['emotion_labels'], self.device\n",
    "        )\n",
    "        \n",
    "        # Initialize loss function\n",
    "        self.loss_fn = MultiTaskLoss(\n",
    "            alpha=self.config.alpha,\n",
    "            sentiment_class_weights=sentiment_weights,\n",
    "            emotion_class_weights=emotion_weights,\n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        # Create datasets\n",
    "        self.train_dataset = MultiTaskDataset(\n",
    "            texts=data_splits['train']['texts'],\n",
    "            sentiment_labels=data_splits['train']['sentiment_labels'],\n",
    "            emotion_labels=data_splits['train']['emotion_labels'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length,\n",
    "            sentiment_label_encoder=sentiment_encoder,\n",
    "            emotion_label_encoder=emotion_encoder\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = MultiTaskDataset(\n",
    "            texts=data_splits['val']['texts'],\n",
    "            sentiment_labels=data_splits['val']['sentiment_labels'],\n",
    "            emotion_labels=data_splits['val']['emotion_labels'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length,\n",
    "            sentiment_label_encoder=sentiment_encoder,\n",
    "            emotion_label_encoder=emotion_encoder\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_sampler = create_stratified_sampler(\n",
    "            data_splits['train']['sentiment_labels'],\n",
    "            data_splits['train']['emotion_labels']\n",
    "        ) if len(data_splits['train']['texts']) > 50 else None\n",
    "        \n",
    "        self.train_loader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            sampler=train_sampler,\n",
    "            shuffle=(train_sampler is None),\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        self.val_loader = DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Setup optimizer and scheduler\n",
    "        num_training_steps = len(self.train_loader) * self.config.num_epochs\n",
    "        self.optimizer, self.scheduler = create_optimizer_and_scheduler(\n",
    "            self.model, self.config, num_training_steps\n",
    "        )\n",
    "        \n",
    "        # Initialize utilities\n",
    "        if self.config.adaptive_alpha:\n",
    "            self.alpha_scheduler = AdaptiveAlphaScheduler(\n",
    "                initial_alpha=self.config.alpha\n",
    "            )\n",
    "        \n",
    "        self.early_stopping = EarlyStopping(patience=3, min_delta=0.001)\n",
    "        self.checkpointer = ModelCheckpointer(\n",
    "            self.config.output_dir,\n",
    "            self.config.save_total_limit\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Setup complete!\")\n",
    "        print(f\"  Model: {self.config.model_name}\")\n",
    "        print(f\"  Training samples: {len(self.train_dataset)}\")\n",
    "        print(f\"  Validation samples: {len(self.val_dataset)}\")\n",
    "        print(f\"  Training steps per epoch: {len(self.train_loader)}\")\n",
    "        print(f\"  Total training steps: {num_training_steps}\")\n",
    "    \n",
    "    def train_epoch(self) -> Dict[str, float]:\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        total_sentiment_loss = 0.0\n",
    "        total_emotion_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(self.train_loader):\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            sentiment_labels = batch['sentiment_labels'].to(self.device)\n",
    "            emotion_labels = batch['emotion_labels'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss_dict = self.loss_fn(\n",
    "                sentiment_logits=outputs['sentiment_logits'],\n",
    "                emotion_logits=outputs['emotion_logits'],\n",
    "                sentiment_labels=sentiment_labels,\n",
    "                emotion_labels=emotion_labels\n",
    "            )\n",
    "            \n",
    "            loss = loss_dict['total_loss']\n",
    "            \n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.model.parameters(),\n",
    "                self.config.max_grad_norm\n",
    "            )\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            # Accumulate losses\n",
    "            total_loss += loss.item()\n",
    "            total_sentiment_loss += loss_dict['sentiment_loss'].item()\n",
    "            total_emotion_loss += loss_dict['emotion_loss'].item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Logging\n",
    "            if (batch_idx + 1) % self.config.logging_steps == 0:\n",
    "                avg_loss = total_loss / num_batches\n",
    "                current_lr = self.scheduler.get_last_lr()[0]\n",
    "                print(f\"  Batch {batch_idx + 1}/{len(self.train_loader)} | \"\n",
    "                      f\"Loss: {avg_loss:.4f} | \"\n",
    "                      f\"LR: {current_lr:.2e} | \"\n",
    "                      f\"Alpha: {self.loss_fn.alpha:.3f}\")\n",
    "        \n",
    "        return {\n",
    "            'train_loss': total_loss / num_batches,\n",
    "            'train_sentiment_loss': total_sentiment_loss / num_batches,\n",
    "            'train_emotion_loss': total_emotion_loss / num_batches\n",
    "        }\n",
    "    \n",
    "    def evaluate(self) -> Dict[str, float]:\n",
    "        \"\"\"Evaluate on validation set\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        total_sentiment_loss = 0.0\n",
    "        total_emotion_loss = 0.0\n",
    "        \n",
    "        sentiment_predictions = []\n",
    "        sentiment_true_labels = []\n",
    "        emotion_predictions = []\n",
    "        emotion_true_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                # Move batch to device\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                sentiment_labels = batch['sentiment_labels'].to(self.device)\n",
    "                emotion_labels = batch['emotion_labels'].to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask\n",
    "                )\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss_dict = self.loss_fn(\n",
    "                    sentiment_logits=outputs['sentiment_logits'],\n",
    "                    emotion_logits=outputs['emotion_logits'],\n",
    "                    sentiment_labels=sentiment_labels,\n",
    "                    emotion_labels=emotion_labels\n",
    "                )\n",
    "                \n",
    "                # Accumulate losses\n",
    "                total_loss += loss_dict['total_loss'].item()\n",
    "                total_sentiment_loss += loss_dict['sentiment_loss'].item()\n",
    "                total_emotion_loss += loss_dict['emotion_loss'].item()\n",
    "                \n",
    "                # Predictions\n",
    "                sentiment_preds = torch.argmax(outputs['sentiment_logits'], dim=-1)\n",
    "                emotion_preds = torch.argmax(outputs['emotion_logits'], dim=-1)\n",
    "                \n",
    "                sentiment_predictions.extend(sentiment_preds.cpu().numpy())\n",
    "                sentiment_true_labels.extend(sentiment_labels.cpu().numpy())\n",
    "                emotion_predictions.extend(emotion_preds.cpu().numpy())\n",
    "                emotion_true_labels.extend(emotion_labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        num_batches = len(self.val_loader)\n",
    "        sentiment_accuracy = accuracy_score(sentiment_true_labels, sentiment_predictions)\n",
    "        emotion_accuracy = accuracy_score(emotion_true_labels, emotion_predictions)\n",
    "        \n",
    "        return {\n",
    "            'val_loss': total_loss / num_batches,\n",
    "            'val_sentiment_loss': total_sentiment_loss / num_batches,\n",
    "            'val_emotion_loss': total_emotion_loss / num_batches,\n",
    "            'val_sentiment_accuracy': sentiment_accuracy,\n",
    "            'val_emotion_accuracy': emotion_accuracy,\n",
    "            'sentiment_predictions': sentiment_predictions,\n",
    "            'sentiment_true_labels': sentiment_true_labels,\n",
    "            'emotion_predictions': emotion_predictions,\n",
    "            'emotion_true_labels': emotion_true_labels\n",
    "        }\n",
    "    \n",
    "    def train(self) -> Dict[str, List]:\n",
    "        \"\"\"Main training loop\"\"\"\n",
    "        print(f\"ðŸš€ Starting training for {self.config.num_epochs} epochs...\")\n",
    "        \n",
    "        best_combined_score = 0.0\n",
    "        \n",
    "        for epoch in range(self.config.num_epochs):\n",
    "            print(f\"\\nðŸ“ Epoch {epoch + 1}/{self.config.num_epochs}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Train for one epoch\n",
    "            train_metrics = self.train_epoch()\n",
    "            \n",
    "            # Evaluate\n",
    "            val_metrics = self.evaluate()\n",
    "            \n",
    "            # Update alpha if adaptive\n",
    "            if self.alpha_scheduler:\n",
    "                new_alpha = self.alpha_scheduler.step(\n",
    "                    val_metrics['val_sentiment_accuracy'],\n",
    "                    val_metrics['val_emotion_accuracy']\n",
    "                )\n",
    "                self.loss_fn.update_alpha(new_alpha)\n",
    "            \n",
    "            # Calculate combined score for checkpointing\n",
    "            combined_score = (\n",
    "                val_metrics['val_sentiment_accuracy'] + \n",
    "                val_metrics['val_emotion_accuracy']\n",
    "            ) / 2\n",
    "            \n",
    "            is_best = combined_score > best_combined_score\n",
    "            if is_best:\n",
    "                best_combined_score = combined_score\n",
    "            \n",
    "            # Log metrics\n",
    "            current_lr = self.scheduler.get_last_lr()[0]\n",
    "            \n",
    "            print(f\"ðŸ“Š Epoch {epoch + 1} Results:\")\n",
    "            print(f\"  Train Loss: {train_metrics['train_loss']:.4f}\")\n",
    "            print(f\"  Val Loss: {val_metrics['val_loss']:.4f}\")\n",
    "            print(f\"  Sentiment Accuracy: {val_metrics['val_sentiment_accuracy']:.4f}\")\n",
    "            print(f\"  Emotion Accuracy: {val_metrics['val_emotion_accuracy']:.4f}\")\n",
    "            print(f\"  Combined Score: {combined_score:.4f}\")\n",
    "            print(f\"  Alpha: {self.loss_fn.alpha:.3f}\")\n",
    "            print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "            \n",
    "            # Save history\n",
    "            self.training_history['epoch'].append(epoch + 1)\n",
    "            self.training_history['train_loss'].append(train_metrics['train_loss'])\n",
    "            self.training_history['train_sentiment_loss'].append(train_metrics['train_sentiment_loss'])\n",
    "            self.training_history['train_emotion_loss'].append(train_metrics['train_emotion_loss'])\n",
    "            self.training_history['val_loss'].append(val_metrics['val_loss'])\n",
    "            self.training_history['val_sentiment_loss'].append(val_metrics['val_sentiment_loss'])\n",
    "            self.training_history['val_emotion_loss'].append(val_metrics['val_emotion_loss'])\n",
    "            self.training_history['val_sentiment_accuracy'].append(val_metrics['val_sentiment_accuracy'])\n",
    "            self.training_history['val_emotion_accuracy'].append(val_metrics['val_emotion_accuracy'])\n",
    "            self.training_history['alpha'].append(self.loss_fn.alpha)\n",
    "            self.training_history['learning_rate'].append(current_lr)\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if self.config.save_strategy == \"epoch\":\n",
    "                self.checkpointer.save_checkpoint(\n",
    "                    model=self.model,\n",
    "                    tokenizer=self.tokenizer,\n",
    "                    optimizer=self.optimizer,\n",
    "                    scheduler=self.scheduler,\n",
    "                    epoch=epoch + 1,\n",
    "                    metrics=val_metrics,\n",
    "                    is_best=is_best\n",
    "                )\n",
    "            \n",
    "            # Early stopping\n",
    "            if self.early_stopping(combined_score):\n",
    "                print(f\"â¹ï¸ Early stopping triggered at epoch {epoch + 1}\")\n",
    "                break\n",
    "        \n",
    "        print(f\"\\nðŸŽ‰ Training completed!\")\n",
    "        print(f\"Best combined score: {best_combined_score:.4f}\")\n",
    "        \n",
    "        return self.training_history\n",
    "\n",
    "print(\"âœ… Training loop defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6908f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Simplified evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Evaluation Functions\n",
    "class MultiTaskEvaluator:\n",
    "    \"\"\"\n",
    "    Simplified evaluation for multitask models\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: MultiTaskTransformer,\n",
    "        tokenizer,\n",
    "        sentiment_encoder: LabelEncoder,\n",
    "        emotion_encoder: LabelEncoder,\n",
    "        device: torch.device\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sentiment_encoder = sentiment_encoder\n",
    "        self.emotion_encoder = emotion_encoder\n",
    "        self.device = device\n",
    "        \n",
    "        self.model.eval()\n",
    "    \n",
    "    def evaluate_dataset(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        sentiment_labels: List[int],\n",
    "        emotion_labels: List[int],\n",
    "        batch_size: int = 32\n",
    "    ) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Evaluate model on a dataset\n",
    "        \"\"\"\n",
    "        dataset = MultiTaskDataset(\n",
    "            texts=texts,\n",
    "            sentiment_labels=sentiment_labels,\n",
    "            emotion_labels=emotion_labels,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=512,\n",
    "            sentiment_label_encoder=self.sentiment_encoder,\n",
    "            emotion_label_encoder=self.emotion_encoder\n",
    "        )\n",
    "        \n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        sentiment_predictions = []\n",
    "        emotion_predictions = []\n",
    "        sentiment_true_labels = []\n",
    "        emotion_true_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                \n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask\n",
    "                )\n",
    "                \n",
    "                # Get predictions\n",
    "                sentiment_preds = torch.argmax(outputs['sentiment_logits'], dim=-1)\n",
    "                emotion_preds = torch.argmax(outputs['emotion_logits'], dim=-1)\n",
    "                \n",
    "                # Store results\n",
    "                sentiment_predictions.extend(sentiment_preds.cpu().numpy())\n",
    "                emotion_predictions.extend(emotion_preds.cpu().numpy())\n",
    "                sentiment_true_labels.extend(batch['sentiment_labels'].numpy())\n",
    "                emotion_true_labels.extend(batch['emotion_labels'].numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        results = self._calculate_metrics(\n",
    "            sentiment_predictions=sentiment_predictions,\n",
    "            emotion_predictions=emotion_predictions,\n",
    "            sentiment_true_labels=sentiment_true_labels,\n",
    "            emotion_true_labels=emotion_true_labels\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _calculate_metrics(\n",
    "        self,\n",
    "        sentiment_predictions: List[int],\n",
    "        emotion_predictions: List[int],\n",
    "        sentiment_true_labels: List[int],\n",
    "        emotion_true_labels: List[int]\n",
    "    ) -> Dict[str, any]:\n",
    "        \"\"\"Calculate simplified metrics: only accuracy and macro F1\"\"\"\n",
    "        \n",
    "        # Sentiment metrics\n",
    "        sentiment_accuracy = accuracy_score(sentiment_true_labels, sentiment_predictions)\n",
    "        sentiment_f1_macro = f1_score(sentiment_true_labels, sentiment_predictions, average='macro', zero_division=0)\n",
    "        \n",
    "        # Emotion metrics\n",
    "        emotion_accuracy = accuracy_score(emotion_true_labels, emotion_predictions)\n",
    "        emotion_f1_macro = f1_score(emotion_true_labels, emotion_predictions, average='macro', zero_division=0)\n",
    "        \n",
    "        return {\n",
    "            'sentiment': {\n",
    "                'accuracy': sentiment_accuracy,\n",
    "                'f1_macro': sentiment_f1_macro,\n",
    "                'predictions': sentiment_predictions,\n",
    "                'true_labels': sentiment_true_labels\n",
    "            },\n",
    "            'emotion': {\n",
    "                'accuracy': emotion_accuracy,\n",
    "                'f1_macro': emotion_f1_macro,\n",
    "                'predictions': emotion_predictions,\n",
    "                'true_labels': emotion_true_labels\n",
    "            },\n",
    "            'combined': {\n",
    "                'average_accuracy': (sentiment_accuracy + emotion_accuracy) / 2,\n",
    "                'average_f1': (sentiment_f1_macro + emotion_f1_macro) / 2\n",
    "            }\n",
    "        }\n",
    "\n",
    "print(\"âœ… Simplified evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f592b14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Inference functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Inference Functions\n",
    "class MultiTaskPredictor:\n",
    "    \"\"\"\n",
    "    Inference class for multitask model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: str,\n",
    "        sentiment_encoder_path: str,\n",
    "        emotion_encoder_path: str,\n",
    "        device: torch.device = None\n",
    "    ):\n",
    "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        \n",
    "        # Load model\n",
    "        self.model = MultiTaskTransformer.from_pretrained(model_path)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Load label encoders\n",
    "        import joblib\n",
    "        self.sentiment_encoder = joblib.load(sentiment_encoder_path)\n",
    "        self.emotion_encoder = joblib.load(emotion_encoder_path)\n",
    "        \n",
    "        print(f\"âœ… Model loaded successfully!\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"Sentiment classes: {list(self.sentiment_encoder.classes_)}\")\n",
    "        print(f\"Emotion classes: {list(self.emotion_encoder.classes_)}\")\n",
    "    \n",
    "    def predict_single(\n",
    "        self,\n",
    "        text: str,\n",
    "        return_probabilities: bool = True,\n",
    "        return_attention: bool = False\n",
    "    ) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Predict sentiment and emotion for a single text\n",
    "        \"\"\"\n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        # Move to device\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            \n",
    "            # Get predictions\n",
    "            sentiment_logits = outputs['sentiment_logits']\n",
    "            emotion_logits = outputs['emotion_logits']\n",
    "            \n",
    "            sentiment_probs = F.softmax(sentiment_logits, dim=-1)\n",
    "            emotion_probs = F.softmax(emotion_logits, dim=-1)\n",
    "            \n",
    "            sentiment_pred_id = torch.argmax(sentiment_logits, dim=-1).item()\n",
    "            emotion_pred_id = torch.argmax(emotion_logits, dim=-1).item()\n",
    "            \n",
    "            # Decode predictions\n",
    "            sentiment_label = self.sentiment_encoder.inverse_transform([sentiment_pred_id])[0]\n",
    "            emotion_label = self.emotion_encoder.inverse_transform([emotion_pred_id])[0]\n",
    "            \n",
    "            result = {\n",
    "                'text': text,\n",
    "                'sentiment': {\n",
    "                    'label': sentiment_label,\n",
    "                    'confidence': sentiment_probs[0][sentiment_pred_id].item(),\n",
    "                    'class_id': sentiment_pred_id\n",
    "                },\n",
    "                'emotion': {\n",
    "                    'label': emotion_label,\n",
    "                    'confidence': emotion_probs[0][emotion_pred_id].item(),\n",
    "                    'class_id': emotion_pred_id\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            if return_probabilities:\n",
    "                result['sentiment']['probabilities'] = {\n",
    "                    class_name: prob.item() for class_name, prob in \n",
    "                    zip(self.sentiment_encoder.classes_, sentiment_probs[0])\n",
    "                }\n",
    "                result['emotion']['probabilities'] = {\n",
    "                    class_name: prob.item() for class_name, prob in \n",
    "                    zip(self.emotion_encoder.classes_, emotion_probs[0])\n",
    "                }\n",
    "            \n",
    "            if return_attention:\n",
    "                result['sentiment']['attention_weights'] = outputs['sentiment_attention_weights']\n",
    "                result['emotion']['attention_weights'] = outputs['emotion_attention_weights']\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def predict_batch(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        batch_size: int = 32,\n",
    "        return_probabilities: bool = False\n",
    "    ) -> List[Dict[str, any]]:\n",
    "        \"\"\"\n",
    "        Predict sentiment and emotion for a batch of texts\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            \n",
    "            # Tokenize batch\n",
    "            inputs = self.tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=512\n",
    "            )\n",
    "            \n",
    "            # Move to device\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                \n",
    "                sentiment_logits = outputs['sentiment_logits']\n",
    "                emotion_logits = outputs['emotion_logits']\n",
    "                \n",
    "                sentiment_probs = F.softmax(sentiment_logits, dim=-1)\n",
    "                emotion_probs = F.softmax(emotion_logits, dim=-1)\n",
    "                \n",
    "                sentiment_preds = torch.argmax(sentiment_logits, dim=-1)\n",
    "                emotion_preds = torch.argmax(emotion_logits, dim=-1)\n",
    "                \n",
    "                # Process each item in batch\n",
    "                for j in range(len(batch_texts)):\n",
    "                    sentiment_pred_id = sentiment_preds[j].item()\n",
    "                    emotion_pred_id = emotion_preds[j].item()\n",
    "                    \n",
    "                    sentiment_label = self.sentiment_encoder.inverse_transform([sentiment_pred_id])[0]\n",
    "                    emotion_label = self.emotion_encoder.inverse_transform([emotion_pred_id])[0]\n",
    "                    \n",
    "                    result = {\n",
    "                        'text': batch_texts[j],\n",
    "                        'sentiment': {\n",
    "                            'label': sentiment_label,\n",
    "                            'confidence': sentiment_probs[j][sentiment_pred_id].item(),\n",
    "                            'class_id': sentiment_pred_id\n",
    "                        },\n",
    "                        'emotion': {\n",
    "                            'label': emotion_label,\n",
    "                            'confidence': emotion_probs[j][emotion_pred_id].item(),\n",
    "                            'class_id': emotion_pred_id\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    if return_probabilities:\n",
    "                        result['sentiment']['probabilities'] = {\n",
    "                            class_name: prob.item() for class_name, prob in \n",
    "                            zip(self.sentiment_encoder.classes_, sentiment_probs[j])\n",
    "                        }\n",
    "                        result['emotion']['probabilities'] = {\n",
    "                            class_name: prob.item() for class_name, prob in \n",
    "                            zip(self.emotion_encoder.classes_, emotion_probs[j])\n",
    "                        }\n",
    "                    \n",
    "                    results.append(result)\n",
    "        \n",
    "        return results\n",
    "\n",
    "def save_model_and_encoders(\n",
    "    model: MultiTaskTransformer,\n",
    "    tokenizer,\n",
    "    sentiment_encoder: LabelEncoder,\n",
    "    emotion_encoder: LabelEncoder,\n",
    "    output_dir: str\n",
    "):\n",
    "    \"\"\"Save complete model with encoders\"\"\"\n",
    "    import joblib\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model and tokenizer\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    \n",
    "    # Save encoders\n",
    "    joblib.dump(sentiment_encoder, os.path.join(output_dir, 'sentiment_encoder.pkl'))\n",
    "    joblib.dump(emotion_encoder, os.path.join(output_dir, 'emotion_encoder.pkl'))\n",
    "    \n",
    "    # Save model configuration\n",
    "    config = {\n",
    "        'sentiment_classes': list(sentiment_encoder.classes_),\n",
    "        'emotion_classes': list(emotion_encoder.classes_),\n",
    "        'sentiment_num_classes': len(sentiment_encoder.classes_),\n",
    "        'emotion_num_classes': len(emotion_encoder.classes_)\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(output_dir, 'model_config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ… Model and encoders saved to: {output_dir}\")\n",
    "\n",
    "print(\"âœ… Inference functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a52e6c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated main execution functions defined!\n",
      "\n",
      "ðŸŽ¯ Ready to start multitask learning!\n",
      "\n",
      "To begin training with DeBERTa on external datasets:\n",
      "model, results = run_multitask_training(model_name='microsoft/deberta-base')\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Updated Main Execution Function\n",
    "\n",
    "def run_multitask_training(\n",
    "    reddit_data_path: str = \"annotated_reddit_posts.csv\",\n",
    "    model_name: str = \"microsoft/deberta-base\",\n",
    "    output_dir: str = \"./multitask_model\",\n",
    "    config_overrides: Dict = None,\n",
    "    max_external_samples: int = 10000\n",
    ") -> Tuple[MultiTaskTransformer, Dict]:\n",
    "    \"\"\"\n",
    "    Main function to run complete multitask training pipeline\n",
    "    - Trains on external datasets (SST-2 + GoEmotions)\n",
    "    - Evaluates on Reddit data\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ Starting Multitask Learning Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ðŸ“‹ Training Strategy:\")\n",
    "    print(\"  â€¢ Train on: SST-2 (sentiment) + GoEmotions (emotion)\")\n",
    "    print(\"  â€¢ Evaluate on: Reddit Note 7 data\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Validate model choice\n",
    "    if model_name not in [config[\"name\"] for config in MODEL_CONFIGS.values()]:\n",
    "        available_models = [config[\"name\"] for config in MODEL_CONFIGS.values()]\n",
    "        raise ValueError(f\"Model must be one of: {available_models}\")\n",
    "    \n",
    "    # Load external datasets for training\n",
    "    print(\"\\n1ï¸âƒ£ Loading external datasets for training...\")\n",
    "    sentiment_data, emotion_data = load_external_datasets()\n",
    "    \n",
    "    # Prepare external data for multitask training\n",
    "    print(\"\\n2ï¸âƒ£ Preparing external data for multitask training...\")\n",
    "    external_data_splits, sentiment_encoder, emotion_encoder = prepare_external_data_for_multitask(\n",
    "        sentiment_data, emotion_data, max_samples=max_external_samples\n",
    "    )\n",
    "    \n",
    "    # Load Reddit data for evaluation\n",
    "    print(\"\\n3ï¸âƒ£ Loading Reddit data for evaluation...\")\n",
    "    reddit_df = pd.read_csv(reddit_data_path)\n",
    "    print(f\"Loaded {len(reddit_df)} Reddit samples for evaluation\")\n",
    "    \n",
    "    # Prepare Reddit data for evaluation using the same encoders\n",
    "    reddit_evaluation_data = prepare_reddit_data_for_evaluation(\n",
    "        reddit_df, sentiment_encoder, emotion_encoder\n",
    "    )\n",
    "    \n",
    "    # Create training configuration\n",
    "    config = TrainingConfig(\n",
    "        model_name=model_name,\n",
    "        output_dir=output_dir,\n",
    "        num_epochs=5,  # Reduced since we have more data\n",
    "        batch_size=16,\n",
    "        learning_rate=2e-5,\n",
    "        warmup_ratio=0.1,\n",
    "        weight_decay=0.01,\n",
    "        max_grad_norm=1.0,\n",
    "        alpha=0.5,\n",
    "        adaptive_alpha=True,\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_dropout_prob=0.1,\n",
    "        classifier_dropout=0.1\n",
    "    )\n",
    "    \n",
    "    # Apply any configuration overrides\n",
    "    if config_overrides:\n",
    "        for key, value in config_overrides.items():\n",
    "            if hasattr(config, key):\n",
    "                setattr(config, key, value)\n",
    "                print(f\"Updated config.{key} = {value}\")\n",
    "    \n",
    "    print(f\"\\n4ï¸âƒ£ Initializing multitask trainer...\")\n",
    "    # Initialize trainer\n",
    "    trainer = MultiTaskTrainer(\n",
    "        config=config,\n",
    "        sentiment_num_classes=len(sentiment_encoder.classes_),\n",
    "        emotion_num_classes=len(emotion_encoder.classes_)\n",
    "    )\n",
    "    \n",
    "    # Setup training with external data\n",
    "    print(f\"\\n5ï¸âƒ£ Setting up training...\")\n",
    "    trainer.setup(external_data_splits, sentiment_encoder, emotion_encoder)\n",
    "    \n",
    "    # Train model on external data\n",
    "    print(f\"\\n6ï¸âƒ£ Training model on external datasets...\")\n",
    "    history = trainer.train()\n",
    "    \n",
    "    # Save final model\n",
    "    save_model_and_encoders(\n",
    "        model=trainer.model,\n",
    "        tokenizer=trainer.tokenizer,\n",
    "        sentiment_encoder=sentiment_encoder,\n",
    "        emotion_encoder=emotion_encoder,\n",
    "        output_dir=os.path.join(output_dir, 'final_model')\n",
    "    )\n",
    "    \n",
    "    # Evaluate on Reddit data\n",
    "    print(f\"\\n7ï¸âƒ£ Evaluating on Reddit data...\")\n",
    "    evaluator = MultiTaskEvaluator(\n",
    "        model=trainer.model,\n",
    "        tokenizer=trainer.tokenizer,\n",
    "        sentiment_encoder=sentiment_encoder,\n",
    "        emotion_encoder=emotion_encoder,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    reddit_results = evaluator.evaluate_dataset(\n",
    "        texts=reddit_evaluation_data['texts'],\n",
    "        sentiment_labels=reddit_evaluation_data['sentiment_labels'],\n",
    "        emotion_labels=reddit_evaluation_data['emotion_labels']\n",
    "    )\n",
    "    \n",
    "    # Print results summary\n",
    "    print(f\"\\nðŸ“ˆ Final Results Summary:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ðŸ“Š Training Data: SST-2 + GoEmotions ({len(external_data_splits['train']['texts'])} samples)\")\n",
    "    print(f\"ðŸ“Š Evaluation Data: Reddit Note 7 ({len(reddit_evaluation_data['texts'])} samples)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Sentiment Classification (on Reddit data):\")\n",
    "    print(f\"  Accuracy: {reddit_results['sentiment']['accuracy']:.4f}\")\n",
    "    print(f\"  F1-Score (Macro): {reddit_results['sentiment']['f1_macro']:.4f}\")\n",
    "    print(f\"\")\n",
    "    print(f\"Emotion Classification (on Reddit data):\")\n",
    "    print(f\"  Accuracy: {reddit_results['emotion']['accuracy']:.4f}\")\n",
    "    print(f\"  F1-Score (Macro): {reddit_results['emotion']['f1_macro']:.4f}\")\n",
    "    print(f\"\")\n",
    "    print(f\"Combined Performance:\")\n",
    "    print(f\"  Average Accuracy: {reddit_results['combined']['average_accuracy']:.4f}\")\n",
    "    print(f\"  Average F1-Score: {reddit_results['combined']['average_f1']:.4f}\")\n",
    "    \n",
    "    # Save detailed results\n",
    "    results_file = os.path.join(output_dir, 'evaluation_results.json')\n",
    "    \n",
    "    # Convert numpy arrays to lists for JSON serialization\n",
    "    def convert_for_json(obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, dict):\n",
    "            return {key: convert_for_json(value) for key, value in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_for_json(item) for item in obj]\n",
    "        else:\n",
    "            return obj\n",
    "    \n",
    "    serializable_results = convert_for_json(reddit_results)\n",
    "    \n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ… Training completed successfully!\")\n",
    "    print(f\"ðŸ“ Output saved to: {output_dir}\")\n",
    "    print(f\"ðŸ“ Final model: {os.path.join(output_dir, 'final_model')}\")\n",
    "    print(f\"ðŸ“ Results: {results_file}\")\n",
    "    \n",
    "    return trainer.model, reddit_results\n",
    "\n",
    "# Example usage and testing function (updated)\n",
    "def test_multitask_model():\n",
    "    \"\"\"Test the multitask model with sample texts\"\"\"\n",
    "    print(\"\\nðŸ§ª Testing Multitask Model\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Sample test cases\n",
    "    test_texts = [\n",
    "        \"I absolutely love this product! It's amazing and makes me so happy! ðŸ˜\",\n",
    "        \"This is terrible... I hate it so much. It makes me really angry! ðŸ˜ \",\n",
    "        \"The service was okay, nothing special. Just neutral feelings about it.\",\n",
    "        \"I'm so excited about this! Can't wait to try it out! ðŸŽ‰\",\n",
    "        \"This is really scary and makes me worried about the future. ðŸ˜°\",\n",
    "        \"What a surprise! I never expected this to happen!\"\n",
    "    ]\n",
    "    \n",
    "    # Load trained model (update path as needed)\n",
    "    model_path = \"./multitask_model/final_model\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        predictor = MultiTaskPredictor(\n",
    "            model_path=model_path,\n",
    "            sentiment_encoder_path=os.path.join(model_path, 'sentiment_encoder.pkl'),\n",
    "            emotion_encoder_path=os.path.join(model_path, 'emotion_encoder.pkl'),\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        print(\"\\nðŸ”® Predictions:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for text in test_texts:\n",
    "            result = predictor.predict_single(text, return_probabilities=True)\n",
    "            \n",
    "            print(f\"Text: {text}\")\n",
    "            print(f\"Sentiment: {result['sentiment']['label']} \"\n",
    "                  f\"(confidence: {result['sentiment']['confidence']:.3f})\")\n",
    "            print(f\"Emotion: {result['emotion']['label']} \"\n",
    "                  f\"(confidence: {result['emotion']['confidence']:.3f})\")\n",
    "            print(\"-\" * 60)\n",
    "    \n",
    "    else:\n",
    "        print(f\"âš ï¸ Model not found at {model_path}\")\n",
    "        print(\"Please run training first!\")\n",
    "\n",
    "print(\"âœ… Updated main execution functions defined!\")\n",
    "print(\"\\nðŸŽ¯ Ready to start multitask learning!\")\n",
    "print(\"\\nTo begin training with DeBERTa on external datasets:\")\n",
    "print(\"model, results = run_multitask_training(model_name='microsoft/deberta-base')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0507cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hyperparameter tuning functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Hyperparameter Tuning with Optuna (Updated)\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "class MultiTaskHyperparameterTuner:\n",
    "    \"\"\"\n",
    "    Hyperparameter tuning for multitask learning using Optuna\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        n_trials: int = 20,\n",
    "        cv_folds: int = 3,\n",
    "        model_name: str = \"microsoft/deberta-base\"\n",
    "    ):\n",
    "        self.data_path = data_path\n",
    "        self.n_trials = n_trials\n",
    "        self.cv_folds = cv_folds\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        # Validate model choice\n",
    "        if model_name not in [config[\"name\"] for config in MODEL_CONFIGS.values()]:\n",
    "            available_models = [config[\"name\"] for config in MODEL_CONFIGS.values()]\n",
    "            raise ValueError(f\"Model must be one of: {available_models}\")\n",
    "        \n",
    "        # Load and prepare data\n",
    "        df = pd.read_csv(data_path)\n",
    "        self.data_splits, self.sentiment_encoder, self.emotion_encoder = prepare_multitask_data(df)\n",
    "        \n",
    "        print(f\"âœ… Hyperparameter tuner initialized\")\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Data: {len(df)} samples\")\n",
    "        print(f\"Trials: {n_trials}\")\n",
    "        print(f\"CV Folds: {cv_folds}\")\n",
    "    \n",
    "    def objective(self, trial):\n",
    "        \"\"\"Optuna objective function\"\"\"\n",
    "        \n",
    "        # Sample hyperparameters\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-4, log=True)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
    "        alpha = trial.suggest_float('alpha', 0.3, 0.7)\n",
    "        hidden_dropout = trial.suggest_float('hidden_dropout_prob', 0.05, 0.3)\n",
    "        classifier_dropout = trial.suggest_float('classifier_dropout', 0.1, 0.5)\n",
    "        weight_decay = trial.suggest_float('weight_decay', 0.01, 0.3)\n",
    "        warmup_ratio = trial.suggest_float('warmup_ratio', 0.05, 0.2)\n",
    "        num_epochs = trial.suggest_int('num_epochs', 3, 8)\n",
    "        \n",
    "        # Create configuration\n",
    "        config = TrainingConfig(\n",
    "            model_name=self.model_name,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            num_epochs=num_epochs,\n",
    "            warmup_ratio=warmup_ratio,\n",
    "            weight_decay=weight_decay,\n",
    "            alpha=alpha,\n",
    "            hidden_dropout_prob=hidden_dropout,\n",
    "            classifier_dropout=classifier_dropout,\n",
    "            adaptive_alpha=False,  # Disable for consistent comparison\n",
    "            output_dir=f\"./temp_trial_{trial.number}\",\n",
    "            save_strategy=\"no\"  # Don't save during tuning\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # Initialize trainer\n",
    "            trainer = MultiTaskTrainer(\n",
    "                config=config,\n",
    "                sentiment_num_classes=len(self.sentiment_encoder.classes_),\n",
    "                emotion_num_classes=len(self.emotion_encoder.classes_)\n",
    "            )\n",
    "            \n",
    "            # Setup with reduced data for faster tuning\n",
    "            trainer.setup(self.data_splits, self.sentiment_encoder, self.emotion_encoder)\n",
    "            \n",
    "            # Train model\n",
    "            history = trainer.train()\n",
    "            \n",
    "            # Calculate final combined score\n",
    "            final_sentiment_acc = history['val_sentiment_accuracy'][-1]\n",
    "            final_emotion_acc = history['val_emotion_accuracy'][-1]\n",
    "            combined_score = (final_sentiment_acc + final_emotion_acc) / 2\n",
    "            \n",
    "            # Clean up\n",
    "            del trainer\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            return combined_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Trial {trial.number} failed: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def tune(self) -> optuna.Study:\n",
    "        \"\"\"Run hyperparameter optimization\"\"\"\n",
    "        \n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            sampler=TPESampler(seed=42),\n",
    "            pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=3)\n",
    "        )\n",
    "        \n",
    "        print(f\"ðŸ” Starting hyperparameter optimization...\")\n",
    "        study.optimize(self.objective, n_trials=self.n_trials)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nðŸ† Optimization completed!\")\n",
    "        print(f\"Best trial: {study.best_trial.number}\")\n",
    "        print(f\"Best score: {study.best_value:.4f}\")\n",
    "        print(f\"Best parameters:\")\n",
    "        for key, value in study.best_params.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "        return study\n",
    "\n",
    "def run_hyperparameter_tuning(\n",
    "    data_path: str = \"annotated_reddit_posts.csv\",\n",
    "    n_trials: int = 20,\n",
    "    model_name: str = \"microsoft/deberta-base\"\n",
    "):\n",
    "    \"\"\"Run hyperparameter tuning and train final model with best params\"\"\"\n",
    "    \n",
    "    # Run tuning\n",
    "    tuner = MultiTaskHyperparameterTuner(\n",
    "        data_path=data_path,\n",
    "        n_trials=n_trials,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    \n",
    "    study = tuner.tune()\n",
    "    \n",
    "    # Train final model with best parameters\n",
    "    print(f\"\\nðŸš€ Training final model with best hyperparameters...\")\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    model, results = run_multitask_training(\n",
    "        data_path=data_path,\n",
    "        model_name=model_name,\n",
    "        output_dir=\"./multitask_model_optimized\",\n",
    "        config_overrides=best_params\n",
    "    )\n",
    "    \n",
    "    # Save tuning results\n",
    "    import pickle\n",
    "    with open(\"./multitask_model_optimized/hyperparameter_study.pkl\", 'wb') as f:\n",
    "        pickle.dump(study, f)\n",
    "    \n",
    "    return model, results, study\n",
    "\n",
    "print(\"âœ… Hyperparameter tuning functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376e4a5e",
   "metadata": {},
   "source": [
    "# DeBERTa Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ce169c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Multitask Training with DeBERTa on External Datasets...\n",
      "ðŸš€ Starting Multitask Learning Pipeline\n",
      "============================================================\n",
      "ðŸ“‹ Training Strategy:\n",
      "  â€¢ Train on: SST-2 (sentiment) + GoEmotions (emotion)\n",
      "  â€¢ Evaluate on: Reddit Note 7 data\n",
      "============================================================\n",
      "\n",
      "1ï¸âƒ£ Loading external datasets for training...\n",
      "ðŸ“ Loading external datasets for training...\n",
      "âœ… SST-2 dataset loaded: 67349 train, 872 val\n",
      "âœ… GoEmotions dataset loaded: 43410 train, 5426 val\n",
      "\n",
      "2ï¸âƒ£ Preparing external data for multitask training...\n",
      "ðŸ”„ Preparing external datasets for multitask training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43410/43410 [00:00<00:00, 199127.19 examples/s]\n",
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5426/5426 [00:00<00:00, 175026.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… External data prepared:\n",
      "  Train samples: 10896\n",
      "  Validation samples: 2725\n",
      "  Sentiment classes: [np.str_('Negative'), np.str_('Neutral'), np.str_('Positive')]\n",
      "  Emotion classes: [np.str_('Anger'), np.str_('Fear'), np.str_('Joy'), np.str_('No Emotion'), np.str_('Sadness'), np.str_('Surprise')]\n",
      "\n",
      "ðŸ“ˆ Training set class distribution:\n",
      "  Sentiment 'Negative': 4888 samples\n",
      "  Sentiment 'Neutral': 650 samples\n",
      "  Sentiment 'Positive': 5358 samples\n",
      "  Emotion 'Anger': 3279 samples\n",
      "  Emotion 'Fear': 1794 samples\n",
      "  Emotion 'Joy': 1238 samples\n",
      "  Emotion 'No Emotion': 1735 samples\n",
      "  Emotion 'Sadness': 2091 samples\n",
      "  Emotion 'Surprise': 759 samples\n",
      "\n",
      "3ï¸âƒ£ Loading Reddit data for evaluation...\n",
      "Loaded 95 Reddit samples for evaluation\n",
      "ðŸ”„ Preparing Reddit data for evaluation...\n",
      "âœ… Reddit evaluation data prepared: 95 samples\n",
      "\n",
      "4ï¸âƒ£ Initializing multitask trainer...\n",
      "\n",
      "5ï¸âƒ£ Setting up training...\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'classes' parameter of compute_class_weight must be an instance of 'numpy.ndarray'. Got ['2_0', '1_1', '1_5', '1_0', '0_2', '1_2', '0_0', '1_4', '1_3', '0_5', '0_4', '2_2', '2_1', '2_4', '2_3', '0_1', '0_3', '2_5'] instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidParameterError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 11: Run Training\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Now let's run the multitask training on your data!\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting Multitask Training with DeBERTa on External Datasets...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model_deberta, results_deberta = \u001b[43mrun_multitask_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreddit_data_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mannotated_reddit_posts.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmicrosoft/deberta-base\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./multitask_model_deberta_external\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_external_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15000\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use more external data for better training\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mrun_multitask_training\u001b[39m\u001b[34m(reddit_data_path, model_name, output_dir, config_overrides, max_external_samples)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Setup training with external data\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m5ï¸âƒ£ Setting up training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexternal_data_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentiment_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memotion_encoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Train model on external data\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m6ï¸âƒ£ Training model on external datasets...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 102\u001b[39m, in \u001b[36mMultiTaskTrainer.setup\u001b[39m\u001b[34m(self, data_splits, sentiment_encoder, emotion_encoder)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28mself\u001b[39m.val_dataset = MultiTaskDataset(\n\u001b[32m     92\u001b[39m     texts=data_splits[\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtexts\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     93\u001b[39m     sentiment_labels=data_splits[\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33msentiment_labels\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     98\u001b[39m     emotion_label_encoder=emotion_encoder\n\u001b[32m     99\u001b[39m )\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# Create data loaders\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m train_sampler = \u001b[43mcreate_stratified_sampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_splits\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentiment_labels\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_splits\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43memotion_labels\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_splits[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtexts\u001b[39m\u001b[33m'\u001b[39m]) > \u001b[32m50\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28mself\u001b[39m.train_loader = DataLoader(\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mself\u001b[39m.train_dataset,\n\u001b[32m    109\u001b[39m     batch_size=\u001b[38;5;28mself\u001b[39m.config.batch_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    113\u001b[39m     pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    114\u001b[39m )\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m.val_loader = DataLoader(\n\u001b[32m    117\u001b[39m     \u001b[38;5;28mself\u001b[39m.val_dataset,\n\u001b[32m    118\u001b[39m     batch_size=\u001b[38;5;28mself\u001b[39m.config.batch_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m     pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    122\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 302\u001b[39m, in \u001b[36mcreate_stratified_sampler\u001b[39m\u001b[34m(sentiment_labels, emotion_labels)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;66;03m# Calculate class weights\u001b[39;00m\n\u001b[32m    301\u001b[39m unique_labels = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(compound_labels))\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m class_weights = \u001b[43mcompute_class_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbalanced\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43munique_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompound_labels\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Create weight dictionary\u001b[39;00m\n\u001b[32m    309\u001b[39m weight_dict = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(unique_labels, class_weights))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:208\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m to_ignore += [\u001b[33m\"\u001b[39m\u001b[33mself\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    206\u001b[39m params = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params.arguments.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__qualname__\u001b[39;49m\n\u001b[32m    210\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hankaixin\\Desktop\\multitask\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001b[39m, in \u001b[36mvalidate_parameter_constraints\u001b[39m\u001b[34m(parameter_constraints, params, caller_name)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m     constraints_str = (\n\u001b[32m     94\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:-\u001b[32m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[32m     99\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[31mInvalidParameterError\u001b[39m: The 'classes' parameter of compute_class_weight must be an instance of 'numpy.ndarray'. Got ['2_0', '1_1', '1_5', '1_0', '0_2', '1_2', '0_0', '1_4', '1_3', '0_5', '0_4', '2_2', '2_1', '2_4', '2_3', '0_1', '0_3', '2_5'] instead."
     ]
    }
   ],
   "source": [
    "# Cell 11: Run Training\n",
    "# Now let's run the multitask training on your data!\n",
    "print(\"Starting Multitask Training with DeBERTa on External Datasets...\")\n",
    "model_deberta, results_deberta = run_multitask_training(\n",
    "    reddit_data_path=\"annotated_reddit_posts.csv\",\n",
    "    model_name=\"microsoft/deberta-base\",\n",
    "    output_dir=\"./multitask_model_deberta_external\",\n",
    "    max_external_samples=15000  # Use more external data for better training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca866f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "print(\"\\nðŸ“Š Model Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"DeBERTa Results:\")\n",
    "print(f\"  Sentiment Accuracy: {results_deberta['sentiment']['accuracy']:.4f}\")\n",
    "print(f\"  Sentiment F1 (Macro): {results_deberta['sentiment']['f1_macro']:.4f}\")\n",
    "print(f\"  Emotion Accuracy: {results_deberta['emotion']['accuracy']:.4f}\")\n",
    "print(f\"  Emotion F1 (Macro): {results_deberta['emotion']['f1_macro']:.4f}\")\n",
    "print(f\"  Combined Score: {results_deberta['combined']['average_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16290871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "test_multitask_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with BERTweet (optimized for social media text)\n",
    "print(\"\\nðŸš€ Starting Multitask Training with BERTweet...\")\n",
    "model_bertweet, results_bertweet = run_multitask_training(\n",
    "    data_path=\"annotated_reddit_posts.csv\",\n",
    "    model_name=\"vinai/bertweet-base\", \n",
    "    output_dir=\"./multitask_model_bertweet\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nBERTweet Results:\")\n",
    "print(f\"  Sentiment Accuracy: {results_bertweet['sentiment']['accuracy']:.4f}\")\n",
    "print(f\"  Sentiment F1 (Macro): {results_bertweet['sentiment']['f1_macro']:.4f}\")\n",
    "print(f\"  Emotion Accuracy: {results_bertweet['emotion']['accuracy']:.4f}\")\n",
    "print(f\"  Emotion F1 (Macro): {results_bertweet['emotion']['f1_macro']:.4f}\")\n",
    "print(f\"  Combined Score: {results_bertweet['combined']['average_f1']:.4f}\")\n",
    "\n",
    "# Test the better performing model\n",
    "better_model = \"deberta\" if results_deberta['combined']['average_f1'] > results_bertweet['combined']['average_f1'] else \"bertweet\"\n",
    "print(f\"\\nðŸ† Better performing model: {better_model}\")\n",
    "\n",
    "# Test the trained model\n",
    "test_multitask_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1985e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Optional - Run Hyperparameter Tuning\n",
    "# Uncomment to run hyperparameter optimization for either model\n",
    "\n",
    "# # Tune DeBERTa\n",
    "# print(\"ðŸ” Starting Hyperparameter Optimization for DeBERTa...\")\n",
    "# optimized_model_deberta, optimized_results_deberta, study_deberta = run_hyperparameter_tuning(\n",
    "#     data_path=\"annotated_reddit_posts.csv\",\n",
    "#     n_trials=15,\n",
    "#     model_name=\"microsoft/deberta-base\"\n",
    "# )\n",
    "\n",
    "# # Tune BERTweet\n",
    "# print(\"ðŸ” Starting Hyperparameter Optimization for BERTweet...\")\n",
    "# optimized_model_bertweet, optimized_results_bertweet, study_bertweet = run_hyperparameter_tuning(\n",
    "#     data_path=\"annotated_reddit_posts.csv\",\n",
    "#     n_trials=15,\n",
    "#     model_name=\"vinai/bertweet-base\"\n",
    "# )\n",
    "\n",
    "print(\"âœ… Multitask Learning Framework Complete!\")\n",
    "print(\"\"\"\n",
    "ðŸŽ¯ What you can do now:\n",
    "1. Use the trained models for inference\n",
    "2. Compare DeBERTa vs BERTweet performance\n",
    "3. Fine-tune on additional data  \n",
    "4. Adjust loss weighting (alpha parameter)\n",
    "5. Try different attention mechanisms\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
