{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf2db3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4060\n",
      "GPU Memory: 8.0 GB\n",
      "All imports completed and GPU configured\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports for RoBERTa Pipeline\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "# Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModel,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "# ML utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Hyperparameter tuning\n",
    "import optuna\n",
    "\n",
    "# Dataset loading\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_random_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "# GPU setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "print(\"All imports completed and GPU configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb27104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration classes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration Classes for distilroBERTa\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    model_name: str = \"distilroberta-base\" \n",
    "    learning_rate: float = 2e-5\n",
    "    batch_size: int = 16\n",
    "    num_epochs: int = 3\n",
    "    max_length: int = 128\n",
    "    warmup_ratio: float = 0.1\n",
    "    weight_decay: float = 0.01\n",
    "    max_grad_norm: float = 1.0\n",
    "    hidden_dropout_prob: float = 0.1\n",
    "    attention_dropout_prob: float = 0.1\n",
    "    classifier_dropout: float = 0.1\n",
    "    alpha: float = 0.5  # For multitask loss weighting\n",
    "    task_type: str = \"sentiment\"  # \"sentiment\", \"emotion\", or \"multitask\"\n",
    "    output_dir: str = \"./roberta_model\"\n",
    "\n",
    "class distilroBERTaModelConfig:\n",
    "    def __init__(self):\n",
    "        self.sentiment_classes = ['Negative', 'Neutral', 'Positive']\n",
    "        self.emotion_classes = ['Anger', 'Fear', 'Joy', 'No Emotion', 'Sadness', 'Surprise']\n",
    "        self.sentiment_num_classes = len(self.sentiment_classes)\n",
    "        self.emotion_num_classes = len(self.emotion_classes)\n",
    "\n",
    "roberta_model_config = distilroBERTaModelConfig()\n",
    "print(\"Configuration classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "441fbea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilroBERTa Dataset classes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Dataset Classes for distilroBERTa\n",
    "class distilroBERTaSingleTaskDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: List[int],\n",
    "        tokenizer,\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        assert len(texts) == len(labels), \"Texts and labels must have same length\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # RoBERTa tokenization\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "class distilroBERTaMultiTaskDataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        sentiment_labels: List[int],\n",
    "        emotion_labels: List[int],\n",
    "        tokenizer,\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        self.texts = texts\n",
    "        self.sentiment_labels = sentiment_labels\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        assert len(texts) == len(sentiment_labels) == len(emotion_labels), \\\n",
    "            \"All inputs must have same length\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        sentiment_label = self.sentiment_labels[idx]\n",
    "        emotion_label = self.emotion_labels[idx]\n",
    "        \n",
    "        # RoBERTa tokenization\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'sentiment_labels': torch.tensor(sentiment_label, dtype=torch.long),\n",
    "            'emotion_labels': torch.tensor(emotion_label, dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "print(\"distilroBERTa Dataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca8375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilroBERTa Model architectures defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Model Architectures\n",
    "class distilroBERTaSingleTaskTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"distilroberta-base\",\n",
    "        num_classes: int = 3,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load RoBERTa model\n",
    "        self.roberta = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_dropout_prob\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(self.roberta.config.hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get RoBERTa outputs\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return {'logits': logits}\n",
    "\n",
    "class distilroBERTaMultiTaskTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"distilroberta-base\",\n",
    "        sentiment_num_classes: int = 3,\n",
    "        emotion_num_classes: int = 6,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "        attention_dropout_prob: float = 0.1,\n",
    "        classifier_dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sentiment_num_classes = sentiment_num_classes\n",
    "        self.emotion_num_classes = emotion_num_classes\n",
    "        \n",
    "        # Shared RoBERTa encoder\n",
    "        self.roberta = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_dropout_prob\n",
    "        )\n",
    "        \n",
    "        # Task-specific heads\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        \n",
    "        # Sentiment classification head\n",
    "        self.sentiment_classifier = nn.Linear(\n",
    "            self.roberta.config.hidden_size, \n",
    "            sentiment_num_classes\n",
    "        )\n",
    "        \n",
    "        # Emotion classification head\n",
    "        self.emotion_classifier = nn.Linear(\n",
    "            self.roberta.config.hidden_size, \n",
    "            emotion_num_classes\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get shared RoBERTa representations\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # Task-specific predictions\n",
    "        sentiment_logits = self.sentiment_classifier(pooled_output)\n",
    "        emotion_logits = self.emotion_classifier(pooled_output)\n",
    "        \n",
    "        return {\n",
    "            'sentiment_logits': sentiment_logits,\n",
    "            'emotion_logits': emotion_logits\n",
    "        }\n",
    "\n",
    "print(\"distilroBERTa Model architectures defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f19424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RoBERTa data processing functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Data Loading and Processing Functions for RoBERTa\n",
    "def aggressive_memory_cleanup():\n",
    "    \"\"\"Aggressive memory cleanup for GPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print(\"üßπ Memory cleaned!\")\n",
    "\n",
    "def load_and_process_datasets_roberta():\n",
    "    \"\"\"Load and process datasets for RoBERTa training\"\"\"\n",
    "    print(\"üì• Loading external datasets for RoBERTa...\")\n",
    "    \n",
    "    # Load SST-2 for sentiment\n",
    "    try:\n",
    "        sst2_dataset = load_dataset(\"sst2\")\n",
    "        print(f\"‚úÖ SST-2 dataset loaded: {len(sst2_dataset['train'])} train samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading SST-2: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Load GoEmotions for emotion\n",
    "    try:\n",
    "        emotions_dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "        print(f\"‚úÖ GoEmotions dataset loaded: {len(emotions_dataset['train'])} train samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading GoEmotions: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Process sentiment data\n",
    "    sentiment_data = process_sentiment_data_roberta(sst2_dataset)\n",
    "    \n",
    "    # Process emotion data  \n",
    "    emotion_data = process_emotion_data_roberta(emotions_dataset)\n",
    "    \n",
    "    return sentiment_data, emotion_data\n",
    "\n",
    "def process_sentiment_data_roberta(sst2_dataset, max_samples=10000):\n",
    "    \"\"\"Process SST-2 dataset for RoBERTa sentiment classification\"\"\"\n",
    "    \n",
    "    print(\"üîÑ Processing sentiment data for RoBERTa...\")\n",
    "    \n",
    "    # Extract texts and labels\n",
    "    train_texts = sst2_dataset['train']['sentence'][:max_samples]\n",
    "    train_labels = sst2_dataset['train']['label'][:max_samples]\n",
    "    \n",
    "    # Map SST-2 labels to 3 classes: 0->Negative, 1->Positive\n",
    "    # Add some neutral examples by random assignment\n",
    "    expanded_labels = []\n",
    "    expanded_texts = []\n",
    "    \n",
    "    for text, label in zip(train_texts, train_labels):\n",
    "        if label == 0:  # Negative\n",
    "            expanded_labels.append(0)\n",
    "            expanded_texts.append(text)\n",
    "        elif label == 1:  # Positive\n",
    "            # Sometimes assign as positive, sometimes as neutral\n",
    "            if np.random.random() < 0.15:  # 15% chance to be neutral\n",
    "                expanded_labels.append(1)  # Neutral\n",
    "            else:\n",
    "                expanded_labels.append(2)  # Positive\n",
    "            expanded_texts.append(text)\n",
    "    \n",
    "    # Ensure we have all 3 classes\n",
    "    if 1 not in expanded_labels:\n",
    "        # Force some examples to be neutral\n",
    "        neutral_indices = np.random.choice(len(expanded_labels), size=100, replace=False)\n",
    "        for idx in neutral_indices:\n",
    "            expanded_labels[idx] = 1\n",
    "    \n",
    "    # Create train/val/test splits\n",
    "    train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "        expanded_texts, expanded_labels, test_size=0.3, random_state=42, stratify=expanded_labels\n",
    "    )\n",
    "    \n",
    "    val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "        temp_texts, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
    "    )\n",
    "    \n",
    "    sentiment_data = {\n",
    "        'train': {'texts': train_texts, 'labels': train_labels},\n",
    "        'val': {'texts': val_texts, 'labels': val_labels},\n",
    "        'test': {'texts': test_texts, 'labels': test_labels}\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ RoBERTa Sentiment data processed:\")\n",
    "    print(f\"  Train: {len(train_texts)} samples\")\n",
    "    print(f\"  Val: {len(val_texts)} samples\")\n",
    "    print(f\"  Test: {len(test_texts)} samples\")\n",
    "    \n",
    "    return sentiment_data\n",
    "\n",
    "def process_emotion_data_roberta(emotion_dataset, max_samples=10000):\n",
    "    \"\"\"Process GoEmotion dataset for RoBERTa emotion classification\"\"\"\n",
    "    \n",
    "    print(\"üîÑ Processing emotion data for RoBERTa...\")\n",
    "    \n",
    "    # Filter to first 6 emotions only\n",
    "    def filter_emotions(example):\n",
    "        if isinstance(example['labels'], list):\n",
    "            return example['labels'] and example['labels'][0] in range(6)\n",
    "        else:\n",
    "            return example['labels'] in range(6)\n",
    "    \n",
    "    filtered_train = emotion_dataset['train'].filter(filter_emotions)\n",
    "    filtered_val = emotion_dataset['validation'].filter(filter_emotions)\n",
    "    \n",
    "    # Extract texts and labels\n",
    "    train_texts = filtered_train['text'][:max_samples]\n",
    "    train_labels_raw = filtered_train['labels'][:max_samples]\n",
    "    \n",
    "    # Handle multi-label to single-label conversion\n",
    "    train_labels = []\n",
    "    for label in train_labels_raw:\n",
    "        if isinstance(label, list):\n",
    "            train_labels.append(label[0] if label else 0)\n",
    "        else:\n",
    "            train_labels.append(label)\n",
    "    \n",
    "    # Create train/val/test splits\n",
    "    train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "        train_texts, train_labels, test_size=0.3, random_state=42, stratify=train_labels\n",
    "    )\n",
    "    \n",
    "    val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "        temp_texts, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
    "    )\n",
    "    \n",
    "    emotion_data = {\n",
    "        'train': {'texts': train_texts, 'labels': train_labels},\n",
    "        'val': {'texts': val_texts, 'labels': val_labels},\n",
    "        'test': {'texts': test_texts, 'labels': test_labels}\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ RoBERTa Emotion data processed:\")\n",
    "    print(f\"  Train: {len(train_texts)} samples\")\n",
    "    print(f\"  Val: {len(val_texts)} samples\")\n",
    "    print(f\"  Test: {len(test_texts)} samples\")\n",
    "    \n",
    "    return emotion_data\n",
    "\n",
    "def create_multitask_data_roberta(sentiment_data, emotion_data):\n",
    "    \"\"\"Create combined dataset for multi-task learning with RoBERTa\"\"\"\n",
    "    \n",
    "    print(\"üîÑ Creating multi-task dataset for RoBERTa...\")\n",
    "    \n",
    "    # Take minimum length to balance datasets\n",
    "    min_train_len = min(len(sentiment_data['train']['texts']), len(emotion_data['train']['texts']))\n",
    "    min_val_len = min(len(sentiment_data['val']['texts']), len(emotion_data['val']['texts']))\n",
    "    min_test_len = min(len(sentiment_data['test']['texts']), len(emotion_data['test']['texts']))\n",
    "    \n",
    "    multitask_data = {\n",
    "        'train': {\n",
    "            'texts': sentiment_data['train']['texts'][:min_train_len],\n",
    "            'sentiment_labels': sentiment_data['train']['labels'][:min_train_len],\n",
    "            'emotion_labels': emotion_data['train']['labels'][:min_train_len]\n",
    "        },\n",
    "        'val': {\n",
    "            'texts': sentiment_data['val']['texts'][:min_val_len],\n",
    "            'sentiment_labels': sentiment_data['val']['labels'][:min_val_len],\n",
    "            'emotion_labels': emotion_data['val']['labels'][:min_val_len]\n",
    "        },\n",
    "        'test': {\n",
    "            'texts': sentiment_data['test']['texts'][:min_test_len],\n",
    "            'sentiment_labels': sentiment_data['test']['labels'][:min_test_len],\n",
    "            'emotion_labels': emotion_data['test']['labels'][:min_test_len]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ RoBERTa Multi-task data created:\")\n",
    "    print(f\"  Train: {len(multitask_data['train']['texts'])} samples\")\n",
    "    print(f\"  Val: {len(multitask_data['val']['texts'])} samples\")\n",
    "    print(f\"  Test: {len(multitask_data['test']['texts'])} samples\")\n",
    "    \n",
    "    return multitask_data\n",
    "\n",
    "print(\"‚úÖ RoBERTa data processing functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d1443e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilroBERTa Training classes defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: distilroBERTa Training Classes\n",
    "class distilroBERTaSingleTaskTrainer:\n",
    "    \n",
    "    def __init__(self, config: TrainingConfig, num_classes: int):\n",
    "        self.config = config\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize distilroBERTa tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Initialize distilroBERTa model\n",
    "        self.model = distilroBERTaSingleTaskTransformer(\n",
    "            model_name=config.model_name,\n",
    "            num_classes=num_classes,\n",
    "            hidden_dropout_prob=config.hidden_dropout_prob,\n",
    "            attention_dropout_prob=config.attention_dropout_prob,\n",
    "            classifier_dropout=config.classifier_dropout\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Initialize tracking\n",
    "        self.training_history = {\n",
    "            'train_loss': [],\n",
    "            'train_accuracy': [],\n",
    "            'val_loss': [],\n",
    "            'val_accuracy': [],\n",
    "            'val_f1_macro': []\n",
    "        }\n",
    "    \n",
    "    def create_data_loaders(self, data_splits: Dict):\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = distilroBERTaSingleTaskDataset(\n",
    "            texts=data_splits['train']['texts'],\n",
    "            labels=data_splits['train']['labels'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        \n",
    "        val_dataset = distilroBERTaSingleTaskDataset(\n",
    "            texts=data_splits['val']['texts'],\n",
    "            labels=data_splits['val']['labels'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Setup optimizer and scheduler\n",
    "        total_steps = len(self.train_loader) * self.config.num_epochs\n",
    "        \n",
    "        self.optimizer = AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config.learning_rate,\n",
    "            weight_decay=self.config.weight_decay\n",
    "        )\n",
    "        \n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=int(total_steps * self.config.warmup_ratio),\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        for batch in self.train_loader:\n",
    "            # Move to device\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            labels = batch['labels'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = self.loss_fn(outputs['logits'], labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            total_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        \n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "                \n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = self.loss_fn(outputs['logits'], labels)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "                \n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        f1_macro = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "        \n",
    "        return avg_loss, accuracy, f1_macro\n",
    "    \n",
    "    def train(self, data_splits: Dict):\n",
    "        print(f\"Starting distilroBERTa single-task training ({self.config.task_type})...\")\n",
    "        \n",
    "        # Setup data loaders\n",
    "        self.create_data_loaders(data_splits)\n",
    "        \n",
    "        best_f1 = 0.0\n",
    "        \n",
    "        for epoch in range(self.config.num_epochs):\n",
    "            print(f\"\\nüìç Epoch {epoch + 1}/{self.config.num_epochs}\")\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_accuracy = self.train_epoch()\n",
    "            \n",
    "            # Evaluate\n",
    "            val_loss, val_accuracy, val_f1_macro = self.evaluate()\n",
    "            \n",
    "            # Track metrics\n",
    "            self.training_history['train_loss'].append(train_loss)\n",
    "            self.training_history['train_accuracy'].append(train_accuracy)\n",
    "            self.training_history['val_loss'].append(val_loss)\n",
    "            self.training_history['val_accuracy'].append(val_accuracy)\n",
    "            self.training_history['val_f1_macro'].append(val_f1_macro)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, Val F1: {val_f1_macro:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_f1_macro > best_f1:\n",
    "                best_f1 = val_f1_macro\n",
    "                self.save_model(is_best=True)\n",
    "        \n",
    "        print(f\"\\ndistilroBERTa training completed! Best F1: {best_f1:.4f}\")\n",
    "        return self.training_history\n",
    "    \n",
    "    def save_model(self, is_best=False):\n",
    "        suffix = \"_best\" if is_best else \"\"\n",
    "        model_dir = os.path.join(self.config.output_dir, f\"model{suffix}\")\n",
    "        \n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        self.model.roberta.save_pretrained(model_dir)\n",
    "        self.tokenizer.save_pretrained(model_dir)\n",
    "        \n",
    "        # Save custom components\n",
    "        torch.save({\n",
    "            'classifier_state_dict': self.model.classifier.state_dict(),\n",
    "            'num_classes': self.num_classes,\n",
    "            'config': self.config\n",
    "        }, os.path.join(model_dir, 'custom_components.pt'))\n",
    "        \n",
    "        if is_best:\n",
    "            print(f\"Best distilroBERTa model saved to {model_dir}\")\n",
    "\n",
    "class distilroBERTaMultiTaskTrainer:\n",
    "    \n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize RoBERTa tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Initialize RoBERTa multi-task model\n",
    "        self.model = distilroBERTaMultiTaskTransformer(\n",
    "            model_name=config.model_name,\n",
    "            sentiment_num_classes=roberta_model_config.sentiment_num_classes,\n",
    "            emotion_num_classes=roberta_model_config.emotion_num_classes,\n",
    "            hidden_dropout_prob=config.hidden_dropout_prob,\n",
    "            attention_dropout_prob=config.attention_dropout_prob,\n",
    "            classifier_dropout=config.classifier_dropout\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Initialize tracking\n",
    "        self.training_history = {\n",
    "            'train_loss': [],\n",
    "            'train_sentiment_accuracy': [],\n",
    "            'train_emotion_accuracy': [],\n",
    "            'val_loss': [],\n",
    "            'val_sentiment_accuracy': [],\n",
    "            'val_emotion_accuracy': [],\n",
    "            'val_sentiment_f1_macro': [],\n",
    "            'val_emotion_f1_macro': []\n",
    "        }\n",
    "    \n",
    "    def create_data_loaders(self, data_splits: Dict):\n",
    "        \"\"\"Create data loaders for RoBERTa multi-task training\"\"\"\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = distilroBERTaMultiTaskDataset(\n",
    "            texts=data_splits['train']['texts'],\n",
    "            sentiment_labels=data_splits['train']['sentiment_labels'],\n",
    "            emotion_labels=data_splits['train']['emotion_labels'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        \n",
    "        val_dataset = distilroBERTaMultiTaskDataset(\n",
    "            texts=data_splits['val']['texts'],\n",
    "            sentiment_labels=data_splits['val']['sentiment_labels'],\n",
    "            emotion_labels=data_splits['val']['emotion_labels'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Setup optimizer and scheduler\n",
    "        total_steps = len(self.train_loader) * self.config.num_epochs\n",
    "        \n",
    "        self.optimizer = AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config.learning_rate,\n",
    "            weight_decay=self.config.weight_decay\n",
    "        )\n",
    "        \n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=int(total_steps * self.config.warmup_ratio),\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        sentiment_correct = 0\n",
    "        emotion_correct = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        for batch in self.train_loader:\n",
    "            # Move to device\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            sentiment_labels = batch['sentiment_labels'].to(self.device)\n",
    "            emotion_labels = batch['emotion_labels'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Calculate losses\n",
    "            sentiment_loss = self.loss_fn(outputs['sentiment_logits'], sentiment_labels)\n",
    "            emotion_loss = self.loss_fn(outputs['emotion_logits'], emotion_labels)\n",
    "            \n",
    "            # Combined loss with alpha weighting\n",
    "            loss = self.config.alpha * sentiment_loss + (1 - self.config.alpha) * emotion_loss\n",
    "            \n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            sentiment_preds = torch.argmax(outputs['sentiment_logits'], dim=-1)\n",
    "            emotion_preds = torch.argmax(outputs['emotion_logits'], dim=-1)\n",
    "            \n",
    "            sentiment_correct += (sentiment_preds == sentiment_labels).sum().item()\n",
    "            emotion_correct += (emotion_preds == emotion_labels).sum().item()\n",
    "            total_predictions += sentiment_labels.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        sentiment_accuracy = sentiment_correct / total_predictions\n",
    "        emotion_accuracy = emotion_correct / total_predictions\n",
    "        \n",
    "        return avg_loss, sentiment_accuracy, emotion_accuracy\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        sentiment_predictions = []\n",
    "        emotion_predictions = []\n",
    "        sentiment_labels = []\n",
    "        emotion_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                sentiment_true = batch['sentiment_labels'].to(self.device)\n",
    "                emotion_true = batch['emotion_labels'].to(self.device)\n",
    "                \n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                \n",
    "                # Calculate combined loss\n",
    "                sentiment_loss = self.loss_fn(outputs['sentiment_logits'], sentiment_true)\n",
    "                emotion_loss = self.loss_fn(outputs['emotion_logits'], emotion_true)\n",
    "                loss = self.config.alpha * sentiment_loss + (1 - self.config.alpha) * emotion_loss\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                sentiment_preds = torch.argmax(outputs['sentiment_logits'], dim=-1)\n",
    "                emotion_preds = torch.argmax(outputs['emotion_logits'], dim=-1)\n",
    "                \n",
    "                sentiment_predictions.extend(sentiment_preds.cpu().numpy())\n",
    "                emotion_predictions.extend(emotion_preds.cpu().numpy())\n",
    "                sentiment_labels.extend(sentiment_true.cpu().numpy())\n",
    "                emotion_labels.extend(emotion_true.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sentiment_accuracy = accuracy_score(sentiment_labels, sentiment_predictions)\n",
    "        emotion_accuracy = accuracy_score(emotion_labels, emotion_predictions)\n",
    "        sentiment_f1_macro = f1_score(sentiment_labels, sentiment_predictions, average='macro', zero_division=0)\n",
    "        emotion_f1_macro = f1_score(emotion_labels, emotion_predictions, average='macro', zero_division=0)\n",
    "        \n",
    "        return avg_loss, sentiment_accuracy, emotion_accuracy, sentiment_f1_macro, emotion_f1_macro\n",
    "    \n",
    "    def train(self, data_splits: Dict):\n",
    "        print(f\"üöÄ Starting distilroBERTa multi-task training...\")\n",
    "        \n",
    "        # Setup data loaders\n",
    "        self.create_data_loaders(data_splits)\n",
    "        \n",
    "        best_combined_f1 = 0.0\n",
    "        \n",
    "        for epoch in range(self.config.num_epochs):\n",
    "            print(f\"\\nüìç Epoch {epoch + 1}/{self.config.num_epochs}\")\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_sent_acc, train_emo_acc = self.train_epoch()\n",
    "            \n",
    "            # Evaluate\n",
    "            val_loss, val_sent_acc, val_emo_acc, val_sent_f1, val_emo_f1 = self.evaluate()\n",
    "            \n",
    "            # Track metrics\n",
    "            self.training_history['train_loss'].append(train_loss)\n",
    "            self.training_history['train_sentiment_accuracy'].append(train_sent_acc)\n",
    "            self.training_history['train_emotion_accuracy'].append(train_emo_acc)\n",
    "            self.training_history['val_loss'].append(val_loss)\n",
    "            self.training_history['val_sentiment_accuracy'].append(val_sent_acc)\n",
    "            self.training_history['val_emotion_accuracy'].append(val_emo_acc)\n",
    "            self.training_history['val_sentiment_f1_macro'].append(val_sent_f1)\n",
    "            self.training_history['val_emotion_f1_macro'].append(val_emo_f1)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"  Train Sentiment Acc: {train_sent_acc:.4f}, Train Emotion Acc: {train_emo_acc:.4f}\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"  Val Sentiment Acc: {val_sent_acc:.4f}, F1: {val_sent_f1:.4f}\")\n",
    "            print(f\"  Val Emotion Acc: {val_emo_acc:.4f}, F1: {val_emo_f1:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            combined_f1 = (val_sent_f1 + val_emo_f1) / 2\n",
    "            if combined_f1 > best_combined_f1:\n",
    "                best_combined_f1 = combined_f1\n",
    "                self.save_model(is_best=True)\n",
    "        \n",
    "        print(f\"\\ndistilroBERTa training completed! Best Combined F1: {best_combined_f1:.4f}\")\n",
    "        return self.training_history\n",
    "    \n",
    "    def save_model(self, is_best=False):\n",
    "        suffix = \"_best\" if is_best else \"\"\n",
    "        model_dir = os.path.join(self.config.output_dir, f\"model{suffix}\")\n",
    "        \n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        self.model.roberta.save_pretrained(model_dir)\n",
    "        self.tokenizer.save_pretrained(model_dir)\n",
    "        \n",
    "        # Save custom components\n",
    "        torch.save({\n",
    "            'sentiment_classifier_state_dict': self.model.sentiment_classifier.state_dict(),\n",
    "            'emotion_classifier_state_dict': self.model.emotion_classifier.state_dict(),\n",
    "            'sentiment_num_classes': self.model.sentiment_num_classes,\n",
    "            'emotion_num_classes': self.model.emotion_num_classes,\n",
    "            'config': self.config\n",
    "        }, os.path.join(model_dir, 'custom_components.pt'))\n",
    "        \n",
    "        if is_best:\n",
    "            print(f\"Best distilroBERTa model saved to {model_dir}\")\n",
    "\n",
    "print(\"distilroBERTa Training classes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a89274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilroBERTa evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Evaluation Functions for distilroBERTa\n",
    "def evaluate_distilroBERTa_model(model_path: str, model_type: str, test_data: Dict, model_name: str = \"distilroberta-base\"):\n",
    "    \n",
    "    print(f\"üîç Evaluating distilroBERTa {model_type} model...\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Load custom components\n",
    "    custom_components = torch.load(os.path.join(model_path, 'custom_components.pt'))\n",
    "    \n",
    "    if model_type == \"multitask\":\n",
    "        # Load multi-task model\n",
    "        model = distilroBERTaMultiTaskTransformer(\n",
    "            model_name=model_name,\n",
    "            sentiment_num_classes=custom_components['sentiment_num_classes'],\n",
    "            emotion_num_classes=custom_components['emotion_num_classes']\n",
    "        ).to(device)\n",
    "        \n",
    "        # Load weights\n",
    "        model.roberta = AutoModel.from_pretrained(model_path)\n",
    "        model.sentiment_classifier.load_state_dict(custom_components['sentiment_classifier_state_dict'])\n",
    "        model.emotion_classifier.load_state_dict(custom_components['emotion_classifier_state_dict'])\n",
    "        \n",
    "        # Create test dataset\n",
    "        test_dataset = distilroBERTaMultiTaskDataset(\n",
    "            texts=test_data['texts'],\n",
    "            sentiment_labels=test_data['sentiment_labels'],\n",
    "            emotion_labels=test_data['emotion_labels'],\n",
    "            tokenizer=tokenizer,\n",
    "            max_length=128\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        # Load single-task model\n",
    "        model = distilroBERTaSingleTaskTransformer(\n",
    "            model_name=model_name,\n",
    "            num_classes=custom_components['num_classes']\n",
    "        ).to(device)\n",
    "        \n",
    "        # Load weights\n",
    "        model.roberta = AutoModel.from_pretrained(model_path)\n",
    "        model.classifier.load_state_dict(custom_components['classifier_state_dict'])\n",
    "        \n",
    "        # Create test dataset\n",
    "        test_dataset = distilroBERTaSingleTaskDataset(\n",
    "            texts=test_data['texts'],\n",
    "            labels=test_data['labels'],\n",
    "            tokenizer=tokenizer,\n",
    "            max_length=128\n",
    "        )\n",
    "    \n",
    "    # Create test loader\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    all_predictions = {'sentiment': [], 'emotion': []} if model_type == \"multitask\" else []\n",
    "    all_labels = {'sentiment': [], 'emotion': []} if model_type == \"multitask\" else []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            if model_type == \"multitask\":\n",
    "                # Multi-task predictions\n",
    "                sentiment_preds = torch.argmax(outputs['sentiment_logits'], dim=-1)\n",
    "                emotion_preds = torch.argmax(outputs['emotion_logits'], dim=-1)\n",
    "                \n",
    "                all_predictions['sentiment'].extend(sentiment_preds.cpu().numpy())\n",
    "                all_predictions['emotion'].extend(emotion_preds.cpu().numpy())\n",
    "                all_labels['sentiment'].extend(batch['sentiment_labels'].numpy())\n",
    "                all_labels['emotion'].extend(batch['emotion_labels'].numpy())\n",
    "            else:\n",
    "                # Single-task predictions\n",
    "                predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(batch['labels'].numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    if model_type == \"multitask\":\n",
    "        sentiment_accuracy = accuracy_score(all_labels['sentiment'], all_predictions['sentiment'])\n",
    "        emotion_accuracy = accuracy_score(all_labels['emotion'], all_predictions['emotion'])\n",
    "        sentiment_f1_macro = f1_score(all_labels['sentiment'], all_predictions['sentiment'], average='macro', zero_division=0)\n",
    "        emotion_f1_macro = f1_score(all_labels['emotion'], all_predictions['emotion'], average='macro', zero_division=0)\n",
    "        \n",
    "        results = {\n",
    "            'sentiment_accuracy': sentiment_accuracy,\n",
    "            'emotion_accuracy': emotion_accuracy,\n",
    "            'sentiment_f1_macro': sentiment_f1_macro,\n",
    "            'emotion_f1_macro': emotion_f1_macro,\n",
    "            'combined_accuracy': (sentiment_accuracy + emotion_accuracy) / 2,\n",
    "            'combined_f1_macro': (sentiment_f1_macro + emotion_f1_macro) / 2\n",
    "        }\n",
    "        \n",
    "        print(f\"distilroBERTa Multi-task Results:\")\n",
    "        print(f\"  Sentiment - Accuracy: {sentiment_accuracy:.4f}, F1: {sentiment_f1_macro:.4f}\")\n",
    "        print(f\"  Emotion - Accuracy: {emotion_accuracy:.4f}, F1: {emotion_f1_macro:.4f}\")\n",
    "        print(f\"  Combined - Accuracy: {results['combined_accuracy']:.4f}, F1: {results['combined_f1_macro']:.4f}\")\n",
    "        \n",
    "    else:\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        f1_macro = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'f1_macro': f1_macro\n",
    "        }\n",
    "        \n",
    "        print(f\"distilroBERTa {model_type.title()} Results:\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  F1 Macro: {f1_macro:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"distilroBERTa evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb93e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UltraFastdistilroBERTaHyperparameterTuner class defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Ultra-Fast Hyperparameter Tuning Classes for distilroBERTa \n",
    "def create_tuning_subset(data_splits, subset_ratio=0.01):  # Even smaller: 1%\n",
    "    print(f\"üî™ Creating {subset_ratio*100:.0f}% subset for hyperparameter tuning...\")\n",
    "    \n",
    "    def sample_split(split_data, ratio):\n",
    "        n_samples = int(len(split_data['texts']) * ratio)\n",
    "        if n_samples < 20:  # Minimum 20 samples\n",
    "            n_samples = min(20, len(split_data['texts']))\n",
    "        indices = np.random.choice(len(split_data['texts']), n_samples, replace=False)\n",
    "        \n",
    "        return {\n",
    "            'texts': [split_data['texts'][i] for i in indices],\n",
    "            'labels': [split_data['labels'][i] for i in indices]\n",
    "        }\n",
    "    \n",
    "    val_key = 'val' if 'val' in data_splits else ('validation' if 'validation' in data_splits else 'test')\n",
    "    \n",
    "    tuning_data = {\n",
    "        'train': sample_split(data_splits['train'], subset_ratio),\n",
    "        'val': sample_split(data_splits[val_key], subset_ratio),\n",
    "        'test': sample_split(data_splits['test'], subset_ratio) if 'test' in data_splits else sample_split(data_splits[val_key], subset_ratio)\n",
    "    }\n",
    "    \n",
    "    print(f\"üìä Tuning subset created:\")\n",
    "    print(f\"  Train: {len(tuning_data['train']['texts'])} samples\")\n",
    "    print(f\"  Val: {len(tuning_data['val']['texts'])} samples\")\n",
    "    \n",
    "    return tuning_data\n",
    "\n",
    "def create_multitask_tuning_subset(data_splits, subset_ratio=0.01):\n",
    "    print(f\"üî™ Creating {subset_ratio*100:.0f}% multitask subset for hyperparameter tuning...\")\n",
    "    \n",
    "    def sample_multitask_split(split_data, ratio):\n",
    "        n_samples = int(len(split_data['texts']) * ratio)\n",
    "        if n_samples < 20:\n",
    "            n_samples = min(20, len(split_data['texts']))\n",
    "        indices = np.random.choice(len(split_data['texts']), n_samples, replace=False)\n",
    "        \n",
    "        return {\n",
    "            'texts': [split_data['texts'][i] for i in indices],\n",
    "            'sentiment_labels': [split_data['sentiment_labels'][i] for i in indices],\n",
    "            'emotion_labels': [split_data['emotion_labels'][i] for i in indices]\n",
    "        }\n",
    "    \n",
    "    val_key = 'val' if 'val' in data_splits else ('validation' if 'validation' in data_splits else 'test')\n",
    "    \n",
    "    tuning_data = {\n",
    "        'train': sample_multitask_split(data_splits['train'], subset_ratio),\n",
    "        'val': sample_multitask_split(data_splits[val_key], subset_ratio),\n",
    "        'test': sample_multitask_split(data_splits['test'], subset_ratio) if 'test' in data_splits else sample_multitask_split(data_splits[val_key], subset_ratio)\n",
    "    }\n",
    "    \n",
    "    print(f\"Multitask tuning subset created:\")\n",
    "    print(f\"  Train: {len(tuning_data['train']['texts'])} samples\")\n",
    "    print(f\"  Val: {len(tuning_data['val']['texts'])} samples\")\n",
    "    \n",
    "    return tuning_data\n",
    "\n",
    "class UltraFastdistilroBERTaHyperparameterTuner:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_type: str,\n",
    "        data_splits: Dict,\n",
    "        n_trials: int = 5, \n",
    "        model_name: str = \"distilroberta-base\",\n",
    "        subset_ratio: float = 0.01,  \n",
    "        max_epochs_per_trial: int = 1  \n",
    "    ):\n",
    "        self.model_type = model_type\n",
    "        self.n_trials = n_trials\n",
    "        self.model_name = model_name\n",
    "        self.max_epochs_per_trial = max_epochs_per_trial\n",
    "        \n",
    "        print(f\"Creating ultra-fast tuning setup for {model_type}\")\n",
    "        \n",
    "        if model_type == \"multitask\":\n",
    "            self.tuning_data = create_multitask_tuning_subset(data_splits, subset_ratio)\n",
    "        else:\n",
    "            self.tuning_data = create_tuning_subset(data_splits, subset_ratio)\n",
    "        \n",
    "        print(f\"‚ö° EXTREME Speed optimizations:\")\n",
    "        print(f\"  - Using {subset_ratio*100:.0f}% of data ({len(self.tuning_data['train']['texts'])} samples)\")\n",
    "        print(f\"  - Only {max_epochs_per_trial} epoch per trial\")\n",
    "        print(f\"  - {n_trials} total trials\")\n",
    "        print(f\"  - Small batch sizes (4-8)\")\n",
    "        print(f\"  - No multiprocessing\")\n",
    "        print(f\"  - Estimated time: {n_trials * max_epochs_per_trial * 1:.0f}-{n_trials * max_epochs_per_trial * 3:.0f} minutes\")\n",
    "    \n",
    "    def objective(self, trial):\n",
    "        \n",
    "        # Very fast hyperparameter suggestions\n",
    "        learning_rate = trial.suggest_float('learning_rate', 2e-5, 1e-4, log=True)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [4, 8])  # Small batches for speed\n",
    "        num_epochs = self.max_epochs_per_trial  # Only 1 epoch\n",
    "        warmup_ratio = 0.1  # Fixed for speed\n",
    "        weight_decay = trial.suggest_float('weight_decay', 0.01, 0.1)\n",
    "        hidden_dropout = trial.suggest_float('hidden_dropout_prob', 0.1, 0.2)\n",
    "        classifier_dropout = trial.suggest_float('classifier_dropout', 0.1, 0.2)\n",
    "        max_length = 64  # Shorter sequences for speed\n",
    "        \n",
    "        alpha = trial.suggest_float('alpha', 0.4, 0.6) if self.model_type == \"multitask\" else 0.5\n",
    "        \n",
    "        # Create ultra-speed config\n",
    "        config = TrainingConfig(\n",
    "            model_name=self.model_name,\n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=num_epochs,\n",
    "            warmup_ratio=warmup_ratio,\n",
    "            weight_decay=weight_decay,\n",
    "            hidden_dropout_prob=hidden_dropout,\n",
    "            classifier_dropout=classifier_dropout,\n",
    "            max_length=max_length,\n",
    "            alpha=alpha,\n",
    "            task_type=self.model_type,\n",
    "            output_dir=f\"./ultra_fast_trial_{trial.number}\"\n",
    "        )\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Aggressive memory cleanup\n",
    "            aggressive_memory_cleanup()\n",
    "            \n",
    "            if self.model_type == \"multitask\":\n",
    "                trainer = UltraFastRoBERTaMultiTaskTrainer(config)\n",
    "                history = trainer.train(self.tuning_data)\n",
    "                \n",
    "                best_sentiment_f1 = max(history['val_sentiment_f1_macro']) if history['val_sentiment_f1_macro'] else 0.0\n",
    "                best_emotion_f1 = max(history['val_emotion_f1_macro']) if history['val_emotion_f1_macro'] else 0.0\n",
    "                score = (best_sentiment_f1 + best_emotion_f1) / 2\n",
    "                \n",
    "            else:\n",
    "                if self.model_type == \"sentiment\":\n",
    "                    num_classes = roberta_model_config.sentiment_num_classes\n",
    "                else:\n",
    "                    num_classes = roberta_model_config.emotion_num_classes\n",
    "                \n",
    "                trainer = UltraFastRoBERTaSingleTaskTrainer(config, num_classes)\n",
    "                history = trainer.train(self.tuning_data)\n",
    "                \n",
    "                score = max(history['val_f1_macro']) if history['val_f1_macro'] else 0.0\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"‚ö° Trial {trial.number}: Score={score:.4f}, Time={elapsed/60:.1f}min\")\n",
    "            \n",
    "            return score\n",
    "            \n",
    "        except Exception as e:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"‚ùå Trial {trial.number} failed after {elapsed/60:.1f}min: {str(e)[:100]}...\")\n",
    "            return 0.0\n",
    "            \n",
    "        finally:\n",
    "            # Aggressive cleanup\n",
    "            if 'trainer' in locals():\n",
    "                del trainer\n",
    "            aggressive_memory_cleanup()\n",
    "    \n",
    "    def tune(self):\n",
    "        \"\"\"Run ultra-fast hyperparameter optimization\"\"\"\n",
    "        \n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            sampler=optuna.samplers.RandomSampler(seed=42)\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüöÄ Starting ULTRA-FAST hyperparameter tuning for {self.model_type}...\")\n",
    "        print(f\"‚ö° Target: Find good hyperparameters in ~{self.n_trials * 2:.0f} minutes\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        study.optimize(self.objective, n_trials=self.n_trials)\n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nüèÜ Ultra-fast tuning completed in {total_time/60:.1f} minutes!\")\n",
    "        print(f\"üéØ Best score: {study.best_value:.4f}\")\n",
    "        print(f\"üìã Best parameters:\")\n",
    "        for key, value in study.best_params.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "        return study\n",
    "\n",
    "print(\"UltraFastdistilroBERTaHyperparameterTuner class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0e31cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultra-fast trainers defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 8B: Ultra-Fast Trainers for Speed\n",
    "class UltraFastdistilroBERTaSingleTaskTrainer:\n",
    "    \n",
    "    def __init__(self, config: TrainingConfig, num_classes: int):\n",
    "        self.config = config\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize tokenizer (reuse if possible)\n",
    "        if not hasattr(self, '_tokenizer_cache'):\n",
    "            UltraFastdistilroBERTaSingleTaskTrainer._tokenizer_cache = AutoTokenizer.from_pretrained(config.model_name)\n",
    "            if UltraFastdistilroBERTaSingleTaskTrainer._tokenizer_cache.pad_token is None:\n",
    "                UltraFastdistilroBERTaSingleTaskTrainer._tokenizer_cache.pad_token = UltraFastdistilroBERTaSingleTaskTrainer._tokenizer_cache.eos_token\n",
    "        \n",
    "        self.tokenizer = UltraFastdistilroBERTaSingleTaskTrainer._tokenizer_cache\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = distilroBERTaSingleTaskTransformer(\n",
    "            model_name=config.model_name,\n",
    "            num_classes=num_classes,\n",
    "            hidden_dropout_prob=config.hidden_dropout_prob,\n",
    "            attention_dropout_prob=config.attention_dropout_prob,\n",
    "            classifier_dropout=config.classifier_dropout\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.training_history = {\n",
    "            'train_loss': [], 'train_accuracy': [], 'val_loss': [], 'val_accuracy': [], 'val_f1_macro': []\n",
    "        }\n",
    "    \n",
    "    def create_data_loaders(self, data_splits: Dict):\n",
    "        train_dataset = distilroBERTaSingleTaskDataset(\n",
    "            texts=data_splits['train']['texts'],\n",
    "            labels=data_splits['train']['labels'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        \n",
    "        val_dataset = distilroBERTaSingleTaskDataset(\n",
    "            texts=data_splits['val']['texts'],\n",
    "            labels=data_splits['val']['labels'],\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        \n",
    "        # Speed-optimized data loaders\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,  # No multiprocessing for speed\n",
    "            pin_memory=False  # Disable pin_memory\n",
    "        )\n",
    "        \n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        \n",
    "        # Simple optimizer setup\n",
    "        self.optimizer = AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config.learning_rate,\n",
    "            weight_decay=self.config.weight_decay\n",
    "        )\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(self.train_loader):\n",
    "            input_ids = batch['input_ids'].to(self.device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(self.device, non_blocking=True)\n",
    "            labels = batch['labels'].to(self.device, non_blocking=True)\n",
    "            \n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = self.loss_fn(outputs['logits'], labels)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            total_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "            \n",
    "            # Print progress for very small datasets\n",
    "            if batch_idx % max(1, len(self.train_loader) // 4) == 0:\n",
    "                print(f\"    Batch {batch_idx + 1}/{len(self.train_loader)}\")\n",
    "        \n",
    "        return total_loss / len(self.train_loader), correct_predictions / total_predictions\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                input_ids = batch['input_ids'].to(self.device, non_blocking=True)\n",
    "                attention_mask = batch['attention_mask'].to(self.device, non_blocking=True)\n",
    "                labels = batch['labels'].to(self.device, non_blocking=True)\n",
    "                \n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = self.loss_fn(outputs['logits'], labels)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "                \n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        f1_macro = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "        \n",
    "        return total_loss / len(self.val_loader), accuracy, f1_macro\n",
    "    \n",
    "    def train(self, data_splits: Dict):\n",
    "        print(f\"üöÄ Starting ultra-fast distilroBERTa training ({self.config.task_type})...\")\n",
    "        \n",
    "        self.create_data_loaders(data_splits)\n",
    "        \n",
    "        best_f1 = 0.0\n",
    "        \n",
    "        for epoch in range(self.config.num_epochs):\n",
    "            print(f\"  üìç Epoch {epoch + 1}/{self.config.num_epochs}\")\n",
    "            \n",
    "            train_loss, train_accuracy = self.train_epoch()\n",
    "            val_loss, val_accuracy, val_f1_macro = self.evaluate()\n",
    "            \n",
    "            self.training_history['train_loss'].append(train_loss)\n",
    "            self.training_history['train_accuracy'].append(train_accuracy)\n",
    "            self.training_history['val_loss'].append(val_loss)\n",
    "            self.training_history['val_accuracy'].append(val_accuracy)\n",
    "            self.training_history['val_f1_macro'].append(val_f1_macro)\n",
    "            \n",
    "            print(f\"    Loss: {train_loss:.4f}, Acc: {train_accuracy:.4f}, Val F1: {val_f1_macro:.4f}\")\n",
    "            \n",
    "            if val_f1_macro > best_f1:\n",
    "                best_f1 = val_f1_macro\n",
    "        \n",
    "        print(f\"‚úÖ Training completed! Best F1: {best_f1:.4f}\")\n",
    "        return self.training_history\n",
    "\n",
    "class UltraFastRoBERTaMultiTaskTrainer:\n",
    "    # Similar structure but for multitask...\n",
    "    pass  # Implement if needed\n",
    "\n",
    "print(\"Ultra-fast trainers defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "187a96e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING ROBERTA TRAINING PIPELINE\n",
      "================================================================================\n",
      "üßπ Memory cleaned!\n",
      "\n",
      "1Ô∏è‚É£ Loading and processing datasets for distilroBERTa...\n",
      "üì• Loading external datasets for RoBERTa...\n",
      "‚úÖ SST-2 dataset loaded: 67349 train samples\n",
      "‚úÖ GoEmotions dataset loaded: 43410 train samples\n",
      "üîÑ Processing sentiment data for RoBERTa...\n",
      "‚úÖ RoBERTa Sentiment data processed:\n",
      "  Train: 7000 samples\n",
      "  Val: 1500 samples\n",
      "  Test: 1500 samples\n",
      "üîÑ Processing emotion data for RoBERTa...\n",
      "‚úÖ RoBERTa Emotion data processed:\n",
      "  Train: 7000 samples\n",
      "  Val: 1500 samples\n",
      "  Test: 1500 samples\n",
      "üîÑ Creating multi-task dataset for RoBERTa...\n",
      "‚úÖ RoBERTa Multi-task data created:\n",
      "  Train: 7000 samples\n",
      "  Val: 1500 samples\n",
      "  Test: 1500 samples\n",
      "Data loading completed!\n",
      "Sentiment data: 7000 train samples\n",
      "Emotion data: 7000 train samples\n",
      "Multitask data: 7000 train samples\n",
      "Model: distilroberta-base\n",
      "Hyperparameter trials per model: 8\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Data Loading and Initial Setup for distilroBERTa\n",
    "print(\"üöÄ STARTING ROBERTA TRAINING PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Clear memory before starting\n",
    "aggressive_memory_cleanup()\n",
    "\n",
    "# Load and process datasets for distilroBERTa\n",
    "print(\"\\n1Ô∏è‚É£ Loading and processing datasets for distilroBERTa...\")\n",
    "sentiment_data, emotion_data = load_and_process_datasets_roberta()\n",
    "multitask_data = create_multitask_data_roberta(sentiment_data, emotion_data)\n",
    "\n",
    "# Model configurations\n",
    "model_name = \"distilroberta-base\"\n",
    "n_trials = 8  # Number of hyperparameter tuning trials\n",
    "\n",
    "print(\"Data loading completed!\")\n",
    "print(f\"Sentiment data: {len(sentiment_data['train']['texts'])} train samples\")\n",
    "print(f\"Emotion data: {len(emotion_data['train']['texts'])} train samples\")\n",
    "print(f\"Multitask data: {len(multitask_data['train']['texts'])} train samples\")\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Hyperparameter trials per model: {n_trials}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069be7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìç PHASE 1: FAST INITIAL distilroberta TRAINING - SENTIMENT MODEL\n",
      "================================================================================\n",
      "üî™ Creating 10% subset for fast initial training...\n",
      "üî™ Creating 10% subset for hyperparameter tuning...\n",
      "üìä Tuning subset created:\n",
      "  Train: 700 samples\n",
      "  Val: 150 samples\n",
      "\n",
      "2Ô∏è‚É£ Training Fast Initial DistilRoBERTa Sentiment Model...\n",
      "============================================================\n",
      "Starting distilroBERTa single-task training (sentiment)...\n",
      "\n",
      "üìç Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Fast Initial Sentiment Model Training\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìç PHASE 1: FAST INITIAL distilroberta TRAINING - SENTIMENT MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create smaller subset for initial training too\n",
    "print(\"üî™ Creating 10% subset for fast initial training...\")\n",
    "initial_sentiment_data = create_tuning_subset(sentiment_data, subset_ratio=0.1)\n",
    "\n",
    "# Faster configuration for initial training\n",
    "fast_initial_config_sentiment = TrainingConfig(\n",
    "    model_name=model_name,\n",
    "    batch_size=16,  # Larger batch size\n",
    "    learning_rate=2e-5,\n",
    "    num_epochs=2,  # Fewer epochs\n",
    "    max_length=64,  # Shorter sequences\n",
    "    task_type=\"sentiment\",\n",
    "    output_dir=\"./initial_distilroberta_sentiment_model\"\n",
    ")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Training Fast Initial DistilRoBERTa Sentiment Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train initial sentiment model on subset\n",
    "initial_sentiment_trainer = distilroBERTaSingleTaskTrainer(\n",
    "    config=fast_initial_config_sentiment,\n",
    "    num_classes=roberta_model_config.sentiment_num_classes\n",
    ")\n",
    "initial_sentiment_history = initial_sentiment_trainer.train(initial_sentiment_data)\n",
    "\n",
    "# Evaluate on full test set\n",
    "initial_sentiment_results = evaluate_distilroBERTa_model(\n",
    "    model_path=\"./initial_distilroberta_sentiment_model/model_best\",\n",
    "    model_type=\"sentiment\",\n",
    "    test_data=sentiment_data['test'],\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Initial Sentiment Model Results:\")\n",
    "print(f\"  Accuracy: {initial_sentiment_results['accuracy']:.4f}\")\n",
    "print(f\"  F1 Macro: {initial_sentiment_results['f1_macro']:.4f}\")\n",
    "print(f\"  (Note: Trained on 10% subset for speed)\")\n",
    "\n",
    "# Clean up memory\n",
    "aggressive_memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug Cell: Check what model is actually being used\n",
    "print(\"üîç DEBUGGING MODEL LOADING...\")\n",
    "\n",
    "# Check the current model_name variable\n",
    "print(f\"Current model_name variable: {model_name}\")\n",
    "\n",
    "# Test loading the model directly\n",
    "import time\n",
    "print(f\"\\n‚è±Ô∏è Testing direct model loading...\")\n",
    "\n",
    "start_time = time.time()\n",
    "test_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "load_time_tokenizer = time.time() - start_time\n",
    "print(f\"Tokenizer loaded in: {load_time_tokenizer:.1f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "test_model = AutoModel.from_pretrained(model_name)\n",
    "load_time_model = time.time() - start_time\n",
    "print(f\"Model loaded in: {load_time_model:.1f} seconds\")\n",
    "\n",
    "# Check model size\n",
    "total_params = sum(p.numel() for p in test_model.parameters())\n",
    "print(f\"Model parameters: {total_params:,} ({total_params/1e6:.1f}M)\")\n",
    "\n",
    "# Check model type\n",
    "print(f\"Model type: {type(test_model)}\")\n",
    "print(f\"Model config: {test_model.config.model_type}\")\n",
    "\n",
    "# Expected sizes:\n",
    "# distilroberta-base: ~82M parameters  \n",
    "# bert-tiny: ~4M parameters\n",
    "\n",
    "if total_params > 100e6:\n",
    "    print(\"‚ö†Ô∏è WARNING: This is still a large model (>100M params)\")\n",
    "elif total_params > 50e6:\n",
    "    print(\"‚úÖ Medium-sized model (50-100M params)\")\n",
    "else:\n",
    "    print(\"‚úÖ Small model (<50M params)\")\n",
    "\n",
    "# Clean up\n",
    "del test_tokenizer, test_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Initial Emotion Model Training\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìç PHASE 1: INITIAL distilroBERTa TRAINING - EMOTION MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Default configuration for RoBERTa emotion\n",
    "default_config_emotion = TrainingConfig(\n",
    "    model_name=model_name,\n",
    "    batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    num_epochs=3,\n",
    "    max_length=128,\n",
    "    task_type=\"emotion\",\n",
    "    output_dir=\"./initial_roberta_emotion_model\"\n",
    ")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Training Initial distilroBERTa Emotion Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train initial emotion model\n",
    "initial_emotion_trainer = distilroBERTaSingleTaskTrainer(\n",
    "    config=default_config_emotion,\n",
    "    num_classes=roberta_model_config.emotion_num_classes\n",
    ")\n",
    "initial_emotion_history = initial_emotion_trainer.train(emotion_data)\n",
    "\n",
    "# Evaluate initial emotion model\n",
    "initial_emotion_results = evaluate_distilroBERTa_model(\n",
    "    model_path=\"./initial_distilroBERTa_emotion_model/model_best\",\n",
    "    model_type=\"emotion\",\n",
    "    test_data=emotion_data['test'],\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Initial Emotion Model Results:\")\n",
    "print(f\"  Accuracy: {initial_emotion_results['accuracy']:.4f}\")\n",
    "print(f\"  F1 Macro: {initial_emotion_results['f1_macro']:.4f}\")\n",
    "\n",
    "# Clean up memory\n",
    "aggressive_memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef65183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Initial Multitask Model Training\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìç PHASE 1: INITIAL ROBERTA TRAINING - MULTITASK MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Default configuration for RoBERTa multitask\n",
    "default_config_multitask = TrainingConfig(\n",
    "    model_name=model_name,\n",
    "    batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    num_epochs=3,\n",
    "    max_length=128,\n",
    "    alpha=0.5,\n",
    "    task_type=\"multitask\",\n",
    "    output_dir=\"./initial_roberta_multitask_model\"\n",
    ")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ Training Initial RoBERTa Multi-task Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train initial multitask model\n",
    "initial_multitask_trainer = distilroBERTaMultiTaskTrainer(config=default_config_multitask)\n",
    "initial_multitask_history = initial_multitask_trainer.train(multitask_data)\n",
    "\n",
    "# Evaluate initial multitask model\n",
    "initial_multitask_results = evaluate_distilroBERTa_model(\n",
    "    model_path=\"./initial_roberta_multitask_model/model_best\",\n",
    "    model_type=\"multitask\",\n",
    "    test_data=multitask_data['test'],\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Initial Multitask Model Results:\")\n",
    "print(f\"  Sentiment - Accuracy: {initial_multitask_results['sentiment_accuracy']:.4f}, F1: {initial_multitask_results['sentiment_f1_macro']:.4f}\")\n",
    "print(f\"  Emotion - Accuracy: {initial_multitask_results['emotion_accuracy']:.4f}, F1: {initial_multitask_results['emotion_f1_macro']:.4f}\")\n",
    "print(f\"  Combined - Accuracy: {initial_multitask_results['combined_accuracy']:.4f}, F1: {initial_multitask_results['combined_f1_macro']:.4f}\")\n",
    "\n",
    "# Clean up memory\n",
    "aggressive_memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2704229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Initial Results Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìç INITIAL ROBERTA RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä INITIAL ROBERTA MODEL PERFORMANCE:\")\n",
    "print(f\"  Sentiment Model:\")\n",
    "print(f\"    Accuracy: {initial_sentiment_results['accuracy']:.4f}\")\n",
    "print(f\"    F1 Macro: {initial_sentiment_results['f1_macro']:.4f}\")\n",
    "\n",
    "print(f\"\\n  Emotion Model:\")\n",
    "print(f\"    Accuracy: {initial_emotion_results['accuracy']:.4f}\")\n",
    "print(f\"    F1 Macro: {initial_emotion_results['f1_macro']:.4f}\")\n",
    "\n",
    "print(f\"\\n  Multitask Model:\")\n",
    "print(f\"    Sentiment - Accuracy: {initial_multitask_results['sentiment_accuracy']:.4f}, F1: {initial_multitask_results['sentiment_f1_macro']:.4f}\")\n",
    "print(f\"    Emotion - Accuracy: {initial_multitask_results['emotion_accuracy']:.4f}, F1: {initial_multitask_results['emotion_f1_macro']:.4f}\")\n",
    "print(f\"    Combined - Accuracy: {initial_multitask_results['combined_accuracy']:.4f}, F1: {initial_multitask_results['combined_f1_macro']:.4f}\")\n",
    "\n",
    "# Store results for later comparison\n",
    "all_results = {\n",
    "    'initial_sentiment': initial_sentiment_results,\n",
    "    'initial_emotion': initial_emotion_results,\n",
    "    'initial_multitask': initial_multitask_results\n",
    "}\n",
    "\n",
    "print(f\"\\nüí° These are RoBERTa baseline results. Now proceeding to hyperparameter tuning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Ultra-Fast Hyperparameter Tuning - Sentiment (Updated)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìç PHASE 2: ULTRA-FAST HYPERPARAMETER TUNING - SENTIMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n6Ô∏è‚É£ ULTRA-Fast Hyperparameter Tuning for RoBERTa Sentiment Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create ULTRA-FAST tuner for sentiment\n",
    "sentiment_tuner = UltraFastdistilroBERTaHyperparameterTuner(\n",
    "    model_type=\"sentiment\",\n",
    "    data_splits=sentiment_data,\n",
    "    n_trials=5,  # Only 5 trials\n",
    "    model_name=model_name,\n",
    "    subset_ratio=0.005,  # Only 0.5% of data!\n",
    "    max_epochs_per_trial=1  # Only 1 epoch per trial!\n",
    ")\n",
    "\n",
    "# Run hyperparameter tuning\n",
    "sentiment_study = sentiment_tuner.tune()\n",
    "\n",
    "print(f\"\\n‚úÖ Sentiment Hyperparameter Tuning Completed!\")\n",
    "print(f\"üèÜ Best F1 Score: {sentiment_study.best_value:.4f}\")\n",
    "print(f\"üìã Best Parameters:\")\n",
    "for key, value in sentiment_study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Clean up memory\n",
    "aggressive_memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c350bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Ultra-Fast Hyperparameter Tuning - Emotion\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìç PHASE 2: ULTRA-FAST HYPERPARAMETER TUNING - EMOTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n7Ô∏è‚É£ Fast Hyperparameter Tuning for RoBERTa Emotion Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create FAST tuner for emotion\n",
    "emotion_tuner = FastRoBERTaHyperparameterTuner(\n",
    "    model_type=\"emotion\",\n",
    "    data_splits=emotion_data,\n",
    "    n_trials=n_trials,\n",
    "    model_name=model_name,\n",
    "    subset_ratio=0.02,  # Only 2% of data!\n",
    "    max_epochs_per_trial=2  # Only 2 epochs per trial!\n",
    ")\n",
    "\n",
    "# Run hyperparameter tuning\n",
    "emotion_study = emotion_tuner.tune()\n",
    "\n",
    "print(f\"\\n‚úÖ Emotion Hyperparameter Tuning Completed!\")\n",
    "print(f\"üèÜ Best F1 Score: {emotion_study.best_value:.4f}\")\n",
    "print(f\"üìã Best Parameters:\")\n",
    "for key, value in emotion_study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Clean up memory\n",
    "aggressive_memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03207f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Ultra-Fast Hyperparameter Tuning - Multitask\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìç PHASE 2: ULTRA-FAST HYPERPARAMETER TUNING - MULTITASK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n8Ô∏è‚É£ Fast Hyperparameter Tuning for RoBERTa Multi-task Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create FAST tuner for multitask\n",
    "multitask_tuner = FastRoBERTaHyperparameterTuner(\n",
    "    model_type=\"multitask\",\n",
    "    data_splits=multitask_data,\n",
    "    n_trials=n_trials,\n",
    "    model_name=model_name,\n",
    "    subset_ratio=0.02,  # Only 2% of data!\n",
    "    max_epochs_per_trial=2  # Only 2 epochs per trial!\n",
    ")\n",
    "\n",
    "# Run hyperparameter tuning\n",
    "multitask_study = multitask_tuner.tune()\n",
    "\n",
    "print(f\"\\n‚úÖ Multitask Hyperparameter Tuning Completed!\")\n",
    "print(f\"üèÜ Best Combined F1 Score: {multitask_study.best_value:.4f}\")\n",
    "print(f\"üìã Best Parameters:\")\n",
    "for key, value in multitask_study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Clean up memory\n",
    "aggressive_memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3c20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Final Sentiment Model Training with Best Parameters\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìç PHASE 3: FINAL TRAINING - OPTIMIZED SENTIMENT MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n9Ô∏è‚É£ Training Final RoBERTa Sentiment Model with Best Parameters...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get best parameters from sentiment tuning\n",
    "best_sentiment_params = sentiment_study.best_params\n",
    "print(f\"üéØ Using best hyperparameters:\")\n",
    "for key, value in best_sentiment_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create optimized config for final training (full dataset, more epochs)\n",
    "final_sentiment_config = TrainingConfig(\n",
    "    model_name=model_name,\n",
    "    learning_rate=best_sentiment_params['learning_rate'],\n",
    "    batch_size=best_sentiment_params['batch_size'],\n",
    "    num_epochs=5,  # Increase epochs for final training\n",
    "    warmup_ratio=best_sentiment_params['warmup_ratio'],\n",
    "    weight_decay=best_sentiment_params['weight_decay'],\n",
    "    hidden_dropout_prob=best_sentiment_params['hidden_dropout_prob'],\n",
    "    classifier_dropout=best_sentiment_params['classifier_dropout'],\n",
    "    max_length=best_sentiment_params.get('max_length', 128),\n",
    "    task_type=\"sentiment\",\n",
    "    output_dir=\"./final_roberta_sentiment_model\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüöÄ Training final sentiment model:\")\n",
    "print(f\"  Dataset: Full sentiment data ({len(sentiment_data['train']['texts'])} train samples)\")\n",
    "print(f\"  Epochs: {final_sentiment_config.num_epochs}\")\n",
    "print(f\"  Batch size: {final_sentiment_config.batch_size}\")\n",
    "print(f\"  Learning rate: {final_sentiment_config.learning_rate:.2e}\")\n",
    "\n",
    "# Train final sentiment model\n",
    "final_sentiment_trainer = distilroBERTaSingleTaskTrainer(\n",
    "    config=final_sentiment_config,\n",
    "    num_classes=roberta_model_config.sentiment_num_classes\n",
    ")\n",
    "final_sentiment_history = final_sentiment_trainer.train(sentiment_data)\n",
    "\n",
    "# Evaluate final sentiment model\n",
    "final_sentiment_results = evaluate_distilroBERTa_model(\n",
    "    model_path=\"./final_roberta_sentiment_model/model_best\",\n",
    "    model_type=\"sentiment\",\n",
    "    test_data=sentiment_data['test'],\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Final Sentiment Model Results:\")\n",
    "print(f\"  Accuracy: {final_sentiment_results['accuracy']:.4f}\")\n",
    "print(f\"  F1 Macro: {final_sentiment_results['f1_macro']:.4f}\")\n",
    "\n",
    "# Compare with tuning results\n",
    "print(f\"\\nüìä Comparison:\")\n",
    "print(f\"  Tuning F1 (on subset): {sentiment_study.best_value:.4f}\")\n",
    "print(f\"  Final F1 (on full test): {final_sentiment_results['f1_macro']:.4f}\")\n",
    "\n",
    "# Clean up memory\n",
    "aggressive_memory_cleanup()\n",
    "print(f\"üíæ Final sentiment model saved to: ./final_roberta_sentiment_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Final Emotion Model Training with Best Parameters\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìç PHASE 3: FINAL TRAINING - OPTIMIZED EMOTION MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüîü Training Final RoBERTa Emotion Model with Best Parameters...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get best parameters from emotion tuning\n",
    "best_emotion_params = emotion_study.best_params\n",
    "print(f\"üéØ Using best hyperparameters:\")\n",
    "for key, value in best_emotion_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create optimized config for final training (full dataset, more epochs)\n",
    "final_emotion_config = TrainingConfig(\n",
    "    model_name=model_name,\n",
    "    learning_rate=best_emotion_params['learning_rate'],\n",
    "    batch_size=best_emotion_params['batch_size'],\n",
    "    num_epochs=5,  # Increase epochs for final training\n",
    "    warmup_ratio=best_emotion_params['warmup_ratio'],\n",
    "    weight_decay=best_emotion_params['weight_decay'],\n",
    "    hidden_dropout_prob=best_emotion_params['hidden_dropout_prob'],\n",
    "    classifier_dropout=best_emotion_params['classifier_dropout'],\n",
    "    max_length=best_emotion_params.get('max_length', 128),\n",
    "    task_type=\"emotion\",\n",
    "    output_dir=\"./final_roberta_emotion_model\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüöÄ Training final emotion model:\")\n",
    "print(f\"  Dataset: Full emotion data ({len(emotion_data['train']['texts'])} train samples)\")\n",
    "print(f\"  Epochs: {final_emotion_config.num_epochs}\")\n",
    "print(f\"  Batch size: {final_emotion_config.batch_size}\")\n",
    "print(f\"  Learning rate: {final_emotion_config.learning_rate:.2e}\")\n",
    "\n",
    "# Train final emotion model\n",
    "final_emotion_trainer = RoBERTaSingleTaskTrainer(\n",
    "    config=final_emotion_config,\n",
    "    num_classes=roberta_model_config.emotion_num_classes\n",
    ")\n",
    "final_emotion_history = final_emotion_trainer.train(emotion_data)\n",
    "\n",
    "# Evaluate final emotion model\n",
    "final_emotion_results = evaluate_roberta_model(\n",
    "    model_path=\"./final_roberta_emotion_model/model_best\",\n",
    "    model_type=\"emotion\",\n",
    "    test_data=emotion_data['test'],\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Final Emotion Model Results:\")\n",
    "print(f\"  Accuracy: {final_emotion_results['accuracy']:.4f}\")\n",
    "print(f\"  F1 Macro: {final_emotion_results['f1_macro']:.4f}\")\n",
    "\n",
    "# Compare with tuning results\n",
    "print(f\"\\nüìä Comparison:\")\n",
    "print(f\"  Tuning F1 (on subset): {emotion_study.best_value:.4f}\")\n",
    "print(f\"  Final F1 (on full test): {final_emotion_results['f1_macro']:.4f}\")\n",
    "\n",
    "# Clean up memory\n",
    "aggressive_memory_cleanup()\n",
    "print(f\"üíæ Final emotion model saved to: ./final_roberta_emotion_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Final Multitask Model Training with Best Parameters\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìç PHASE 3: FINAL TRAINING - OPTIMIZED MULTITASK MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£1Ô∏è‚É£ Training Final RoBERTa Multi-task Model with Best Parameters...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get best parameters from multitask tuning\n",
    "best_multitask_params = multitask_study.best_params\n",
    "print(f\"üéØ Using best hyperparameters:\")\n",
    "for key, value in best_multitask_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create optimized config for final training (full dataset, more epochs)\n",
    "final_multitask_config = TrainingConfig(\n",
    "    model_name=model_name,\n",
    "    learning_rate=best_multitask_params['learning_rate'],\n",
    "    batch_size=best_multitask_params['batch_size'],\n",
    "    num_epochs=5,  # Increase epochs for final training\n",
    "    warmup_ratio=best_multitask_params['warmup_ratio'],\n",
    "    weight_decay=best_multitask_params['weight_decay'],\n",
    "    hidden_dropout_prob=best_multitask_params['hidden_dropout_prob'],\n",
    "    classifier_dropout=best_multitask_params['classifier_dropout'],\n",
    "    max_length=best_multitask_params.get('max_length', 128),\n",
    "    alpha=best_multitask_params['alpha'],  # Multitask-specific parameter\n",
    "    task_type=\"multitask\",\n",
    "    output_dir=\"./final_roberta_multitask_model\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüöÄ Training final multitask model:\")\n",
    "print(f\"  Dataset: Full multitask data ({len(multitask_data['train']['texts'])} train samples)\")\n",
    "print(f\"  Epochs: {final_multitask_config.num_epochs}\")\n",
    "print(f\"  Batch size: {final_multitask_config.batch_size}\")\n",
    "print(f\"  Learning rate: {final_multitask_config.learning_rate:.2e}\")\n",
    "print(f\"  Alpha (loss weighting): {final_multitask_config.alpha:.3f}\")\n",
    "\n",
    "# Train final multitask model\n",
    "final_multitask_trainer = RoBERTaMultiTaskTrainer(config=final_multitask_config)\n",
    "final_multitask_history = final_multitask_trainer.train(multitask_data)\n",
    "\n",
    "# Evaluate final multitask model\n",
    "final_multitask_results = evaluate_roberta_model(\n",
    "    model_path=\"./final_roberta_multitask_model/model_best\",\n",
    "    model_type=\"multitask\",\n",
    "    test_data=multitask_data['test'],\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Final Multitask Model Results:\")\n",
    "print(f\"  Sentiment - Accuracy: {final_multitask_results['sentiment_accuracy']:.4f}, F1: {final_multitask_results['sentiment_f1_macro']:.4f}\")\n",
    "print(f\"  Emotion - Accuracy: {final_multitask_results['emotion_accuracy']:.4f}, F1: {final_multitask_results['emotion_f1_macro']:.4f}\")\n",
    "print(f\"  Combined - Accuracy: {final_multitask_results['combined_accuracy']:.4f}, F1: {final_multitask_results['combined_f1_macro']:.4f}\")\n",
    "\n",
    "# Compare with tuning results\n",
    "print(f\"\\nüìä Comparison:\")\n",
    "print(f\"  Tuning Combined F1 (on subset): {multitask_study.best_value:.4f}\")\n",
    "print(f\"  Final Combined F1 (on full test): {final_multitask_results['combined_f1_macro']:.4f}\")\n",
    "\n",
    "# Clean up memory\n",
    "aggressive_memory_cleanup()\n",
    "print(f\"üíæ Final multitask model saved to: ./final_roberta_multitask_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Final Results Comparison for RoBERTa (Updated with Initial Comparisons)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìç PHASE 4: COMPREHENSIVE RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä ROBERTA COMPLETE PIPELINE RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display initial results\n",
    "print(f\"\\nüìã INITIAL MODEL PERFORMANCE (baseline):\")\n",
    "print(f\"  Sentiment Model:\")\n",
    "print(f\"    Accuracy: {all_results['initial_sentiment']['accuracy']:.4f}\")\n",
    "print(f\"    F1 Macro: {all_results['initial_sentiment']['f1_macro']:.4f}\")\n",
    "\n",
    "print(f\"\\n  Emotion Model:\")\n",
    "print(f\"    Accuracy: {all_results['initial_emotion']['accuracy']:.4f}\")\n",
    "print(f\"    F1 Macro: {all_results['initial_emotion']['f1_macro']:.4f}\")\n",
    "\n",
    "print(f\"\\n  Multitask Model:\")\n",
    "print(f\"    Sentiment - Accuracy: {all_results['initial_multitask']['sentiment_accuracy']:.4f}, F1: {all_results['initial_multitask']['sentiment_f1_macro']:.4f}\")\n",
    "print(f\"    Emotion - Accuracy: {all_results['initial_multitask']['emotion_accuracy']:.4f}, F1: {all_results['initial_multitask']['emotion_f1_macro']:.4f}\")\n",
    "print(f\"    Combined - Accuracy: {all_results['initial_multitask']['combined_accuracy']:.4f}, F1: {all_results['initial_multitask']['combined_f1_macro']:.4f}\")\n",
    "\n",
    "# Display hyperparameter tuning results\n",
    "print(f\"\\nüéØ HYPERPARAMETER TUNING PERFORMANCE (on small subsets):\")\n",
    "print(f\"  Sentiment Best F1: {sentiment_study.best_value:.4f}\")\n",
    "print(f\"  Emotion Best F1: {emotion_study.best_value:.4f}\")\n",
    "print(f\"  Multitask Best Combined F1: {multitask_study.best_value:.4f}\")\n",
    "\n",
    "# Display final optimized results\n",
    "print(f\"\\nüèÜ FINAL OPTIMIZED MODEL PERFORMANCE:\")\n",
    "print(f\"  Sentiment Model:\")\n",
    "print(f\"    Accuracy: {final_sentiment_results['accuracy']:.4f}\")\n",
    "print(f\"    F1 Macro: {final_sentiment_results['f1_macro']:.4f}\")\n",
    "\n",
    "print(f\"\\n  Emotion Model:\")\n",
    "print(f\"    Accuracy: {final_emotion_results['accuracy']:.4f}\")\n",
    "print(f\"    F1 Macro: {final_emotion_results['f1_macro']:.4f}\")\n",
    "\n",
    "print(f\"\\n  Multitask Model:\")\n",
    "print(f\"    Sentiment - Accuracy: {final_multitask_results['sentiment_accuracy']:.4f}, F1: {final_multitask_results['sentiment_f1_macro']:.4f}\")\n",
    "print(f\"    Emotion - Accuracy: {final_multitask_results['emotion_accuracy']:.4f}, F1: {final_multitask_results['emotion_f1_macro']:.4f}\")\n",
    "print(f\"    Combined - Accuracy: {final_multitask_results['combined_accuracy']:.4f}, F1: {final_multitask_results['combined_f1_macro']:.4f}\")\n",
    "\n",
    "# Calculate improvements from initial to final\n",
    "print(f\"\\nüìà IMPROVEMENT FROM INITIAL TO OPTIMIZED:\")\n",
    "\n",
    "# Sentiment improvements\n",
    "sentiment_acc_improvement = final_sentiment_results['accuracy'] - all_results['initial_sentiment']['accuracy']\n",
    "sentiment_f1_improvement = final_sentiment_results['f1_macro'] - all_results['initial_sentiment']['f1_macro']\n",
    "\n",
    "print(f\"  Sentiment:\")\n",
    "print(f\"    Accuracy: {all_results['initial_sentiment']['accuracy']:.4f} ‚Üí {final_sentiment_results['accuracy']:.4f} ({sentiment_acc_improvement:+.4f})\")\n",
    "print(f\"    F1 Macro: {all_results['initial_sentiment']['f1_macro']:.4f} ‚Üí {final_sentiment_results['f1_macro']:.4f} ({sentiment_f1_improvement:+.4f}) {'‚úÖ' if sentiment_f1_improvement > 0 else '‚ö†Ô∏è'}\")\n",
    "\n",
    "# Emotion improvements\n",
    "emotion_acc_improvement = final_emotion_results['accuracy'] - all_results['initial_emotion']['accuracy']\n",
    "emotion_f1_improvement = final_emotion_results['f1_macro'] - all_results['initial_emotion']['f1_macro']\n",
    "\n",
    "print(f\"\\n  Emotion:\")\n",
    "print(f\"    Accuracy: {all_results['initial_emotion']['accuracy']:.4f} ‚Üí {final_emotion_results['accuracy']:.4f} ({emotion_acc_improvement:+.4f})\")\n",
    "print(f\"    F1 Macro: {all_results['initial_emotion']['f1_macro']:.4f} ‚Üí {final_emotion_results['f1_macro']:.4f} ({emotion_f1_improvement:+.4f}) {'‚úÖ' if emotion_f1_improvement > 0 else '‚ö†Ô∏è'}\")\n",
    "\n",
    "# Multitask improvements\n",
    "multitask_sent_acc_improvement = final_multitask_results['sentiment_accuracy'] - all_results['initial_multitask']['sentiment_accuracy']\n",
    "multitask_emo_acc_improvement = final_multitask_results['emotion_accuracy'] - all_results['initial_multitask']['emotion_accuracy']\n",
    "multitask_combined_f1_improvement = final_multitask_results['combined_f1_macro'] - all_results['initial_multitask']['combined_f1_macro']\n",
    "\n",
    "print(f\"\\n  Multitask:\")\n",
    "print(f\"    Sentiment Accuracy: {all_results['initial_multitask']['sentiment_accuracy']:.4f} ‚Üí {final_multitask_results['sentiment_accuracy']:.4f} ({multitask_sent_acc_improvement:+.4f})\")\n",
    "print(f\"    Emotion Accuracy: {all_results['initial_multitask']['emotion_accuracy']:.4f} ‚Üí {final_multitask_results['emotion_accuracy']:.4f} ({multitask_emo_acc_improvement:+.4f})\")\n",
    "print(f\"    Combined F1: {all_results['initial_multitask']['combined_f1_macro']:.4f} ‚Üí {final_multitask_results['combined_f1_macro']:.4f} ({multitask_combined_f1_improvement:+.4f}) {'‚úÖ' if multitask_combined_f1_improvement > 0 else '‚ö†Ô∏è'}\")\n",
    "\n",
    "# Create comprehensive results summary\n",
    "results_summary = {\n",
    "    'model_type': 'RoBERTa',\n",
    "    'model_name': model_name,\n",
    "    'pipeline_type': 'Complete: Initial + Hyperparameter Tuning + Final Training',\n",
    "    'initial_models': {\n",
    "        'sentiment': all_results['initial_sentiment'],\n",
    "        'emotion': all_results['initial_emotion'],\n",
    "        'multitask': all_results['initial_multitask']\n",
    "    },\n",
    "    'hyperparameter_tuning': {\n",
    "        'method': 'Fast Random Search',\n",
    "        'subset_ratio': 0.02,\n",
    "        'trials_per_model': n_trials,\n",
    "        'epochs_per_trial': 2,\n",
    "        'sentiment_best_f1': float(sentiment_study.best_value),\n",
    "        'emotion_best_f1': float(emotion_study.best_value),\n",
    "        'multitask_best_f1': float(multitask_study.best_value)\n",
    "    },\n",
    "    'final_models': {\n",
    "        'sentiment': final_sentiment_results,\n",
    "        'emotion': final_emotion_results,\n",
    "        'multitask': final_multitask_results\n",
    "    },\n",
    "    'improvements': {\n",
    "        'sentiment': {\n",
    "            'accuracy_improvement': float(sentiment_acc_improvement),\n",
    "            'f1_improvement': float(sentiment_f1_improvement)\n",
    "        },\n",
    "        'emotion': {\n",
    "            'accuracy_improvement': float(emotion_acc_improvement),\n",
    "            'f1_improvement': float(emotion_f1_improvement)\n",
    "        },\n",
    "        'multitask': {\n",
    "            'sentiment_accuracy_improvement': float(multitask_sent_acc_improvement),\n",
    "            'emotion_accuracy_improvement': float(multitask_emo_acc_improvement),\n",
    "            'combined_f1_improvement': float(multitask_combined_f1_improvement)\n",
    "        }\n",
    "    },\n",
    "    'best_hyperparameters': {\n",
    "        'sentiment': sentiment_study.best_params,\n",
    "        'emotion': emotion_study.best_params,\n",
    "        'multitask': multitask_study.best_params\n",
    "    },\n",
    "    'model_locations': {\n",
    "        'initial_sentiment': './initial_roberta_sentiment_model/',\n",
    "        'initial_emotion': './initial_roberta_emotion_model/',\n",
    "        'initial_multitask': './initial_roberta_multitask_model/',\n",
    "        'final_sentiment': './final_roberta_sentiment_model/',\n",
    "        'final_emotion': './final_roberta_emotion_model/',\n",
    "        'final_multitask': './final_roberta_multitask_model/'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "with open('comprehensive_roberta_results_summary.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nüìÅ MODEL LOCATIONS:\")\n",
    "print(f\"  üì¶ Initial models: ./initial_roberta_*_model/\")\n",
    "print(f\"  üì¶ Final models: ./final_roberta_*_model/\")\n",
    "\n",
    "print(f\"\\nüìÑ RESULTS SAVED:\")\n",
    "print(f\"  üìä Comprehensive summary: ./comprehensive_roberta_results_summary.json\")\n",
    "\n",
    "print(f\"\\nüéâ COMPLETE ROBERTA PIPELINE FINISHED!\")\n",
    "print(f\"‚úÖ Initial training + Fast hyperparameter tuning + Optimized final training!\")\n",
    "print(f\"üöÄ Now you can compare baseline vs optimized performance!\")\n",
    "\n",
    "# Display final summary table\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"üìã BASELINE vs OPTIMIZED PERFORMANCE SUMMARY\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"{'Model':<12} {'Initial F1':<12} {'Final F1':<12} {'Improvement':<12} {'Status':<10}\")\n",
    "print(f\"-\" * 70)\n",
    "print(f\"{'Sentiment':<12} {all_results['initial_sentiment']['f1_macro']:<12.4f} {final_sentiment_results['f1_macro']:<12.4f} {sentiment_f1_improvement:+12.4f} {'‚úÖ Better' if sentiment_f1_improvement > 0 else '‚ö†Ô∏è Worse':<10}\")\n",
    "print(f\"{'Emotion':<12} {all_results['initial_emotion']['f1_macro']:<12.4f} {final_emotion_results['f1_macro']:<12.4f} {emotion_f1_improvement:+12.4f} {'‚úÖ Better' if emotion_f1_improvement > 0 else '‚ö†Ô∏è Worse':<10}\")\n",
    "print(f\"{'Multitask':<12} {all_results['initial_multitask']['combined_f1_macro']:<12.4f} {final_multitask_results['combined_f1_macro']:<12.4f} {multitask_combined_f1_improvement:+12.4f} {'‚úÖ Better' if multitask_combined_f1_improvement > 0 else '‚ö†Ô∏è Worse':<10}\")\n",
    "print(f\"=\"*80)\n",
    "\n",
    "print(f\"\\nü§ñ RoBERTa pipeline complete with baseline comparisons!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
